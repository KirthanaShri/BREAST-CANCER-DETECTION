2023-12-04_02-37-36: config: {'n_epochs': 10, 'batch_size': 32, 'h': 224, 'w': 224, 'lr': 1e-05, 'optimizer': 'adam', 'momentum': 0.9, 'weight_decay': 0, 'device': 'cuda:1', 'n_gpus': 1, 'kernel_size': 3, 'model': 'CNN', 'use_pooling': False, 'num_kernel_conv_list': [32, 64, 64, 64]}
2023-12-04_02-37-36: conv1.weight: torch.Size([32, 3, 3, 3])
2023-12-04_02-37-36: conv1.bias: torch.Size([32])
2023-12-04_02-37-36: conv_layers.0.weight: torch.Size([64, 32, 3, 3])
2023-12-04_02-37-36: conv_layers.0.bias: torch.Size([64])
2023-12-04_02-37-36: conv_layers.2.weight: torch.Size([64, 64, 3, 3])
2023-12-04_02-37-36: conv_layers.2.bias: torch.Size([64])
2023-12-04_02-37-36: conv_layers.4.weight: torch.Size([64, 64, 3, 3])
2023-12-04_02-37-36: conv_layers.4.bias: torch.Size([64])
2023-12-04_02-37-36: linear.weight: torch.Size([2, 3211264])
2023-12-04_02-37-36: linear.bias: torch.Size([2])
2023-12-04_02-37-36: 
Total parameters: 6,515,778;	Trainable: 6,515,778
2023-12-04_02-38-45: Epoch: 1 | Train loss: 0.4438978355075862 | Train acc: {'40X': 78.24, '100X': 79.55, '200X': 83.06, '400X': 80.55, 'avg_acc': 80.35, 'all_acc': 80.34} | Valid loss: 0.3962007912993431 | Valid acc: {'40X': 82.46, '100X': 82.97, '200X': 85.57, '400X': 82.97, 'avg_acc': 83.49, 'all_acc': 83.5}| Runtime: 1.1 mins
2023-12-04_02-39-53: Epoch: 2 | Train loss: 0.3252612209400615 | Train acc: {'40X': 83.1, '100X': 85.15, '200X': 87.8, '400X': 87.52, 'avg_acc': 85.89, 'all_acc': 85.85} | Valid loss: 0.3305845272541046 | Valid acc: {'40X': 82.96, '100X': 83.93, '200X': 87.56, '400X': 84.89, 'avg_acc': 84.84, 'all_acc': 84.83}| Runtime: 1.1 mins
2023-12-04_02-41-01: Epoch: 3 | Train loss: 0.2753011666842409 | Train acc: {'40X': 85.61, '100X': 87.69, '200X': 89.73, '400X': 89.46, 'avg_acc': 88.12, 'all_acc': 88.09} | Valid loss: 0.3197230586409569 | Valid acc: {'40X': 84.96, '100X': 86.09, '200X': 87.81, '400X': 85.99, 'avg_acc': 86.21, 'all_acc': 86.22}| Runtime: 1.1 mins
2023-12-04_02-42-10: Epoch: 4 | Train loss: 0.2387630329341502 | Train acc: {'40X': 87.37, '100X': 89.64, '200X': 91.78, '400X': 90.38, 'avg_acc': 89.79, 'all_acc': 89.78} | Valid loss: 0.45502396434545517 | Valid acc: {'40X': 80.7, '100X': 81.77, '200X': 85.07, '400X': 78.85, 'avg_acc': 81.6, 'all_acc': 81.67}| Runtime: 1.2 mins
2023-12-04_02-43-18: Epoch: 5 | Train loss: 0.20996177916389866 | Train acc: {'40X': 89.69, '100X': 92.13, '200X': 92.7, '400X': 92.39, 'avg_acc': 91.73, 'all_acc': 91.72} | Valid loss: 0.33990339502692224 | Valid acc: {'40X': 83.71, '100X': 84.89, '200X': 86.32, '400X': 83.24, 'avg_acc': 84.54, 'all_acc': 84.58}| Runtime: 1.1 mins
2023-12-04_02-44-26: Epoch: 6 | Train loss: 0.16110098721912583 | Train acc: {'40X': 91.7, '100X': 94.87, '200X': 95.77, '400X': 95.22, 'avg_acc': 94.39, 'all_acc': 94.38} | Valid loss: 0.3276969328522682 | Valid acc: {'40X': 85.21, '100X': 85.13, '200X': 87.56, '400X': 85.44, 'avg_acc': 85.84, 'all_acc': 85.84}| Runtime: 1.1 mins
2023-12-04_02-45-35: Epoch: 7 | Train loss: 0.1304550480751975 | Train acc: {'40X': 94.56, '100X': 96.78, '200X': 97.01, '400X': 97.07, 'avg_acc': 96.36, 'all_acc': 96.35} | Valid loss: 0.39682483360171317 | Valid acc: {'40X': 85.21, '100X': 85.13, '200X': 86.82, '400X': 81.87, 'avg_acc': 84.76, 'all_acc': 84.83}| Runtime: 1.2 mins
2023-12-04_02-46-45: Epoch: 8 | Train loss: 0.10394170303904526 | Train acc: {'40X': 95.23, '100X': 98.47, '200X': 97.84, '400X': 97.62, 'avg_acc': 97.29, 'all_acc': 97.3} | Valid loss: 0.360126288831234 | Valid acc: {'40X': 84.96, '100X': 85.37, '200X': 86.57, '400X': 84.34, 'avg_acc': 85.31, 'all_acc': 85.34}| Runtime: 1.2 mins
2023-12-04_02-47-55: Epoch: 9 | Train loss: 0.08183525766975977 | Train acc: {'40X': 97.07, '100X': 98.56, '200X': 98.59, '400X': 98.72, 'avg_acc': 98.24, 'all_acc': 98.23} | Valid loss: 0.3647703470289707 | Valid acc: {'40X': 84.46, '100X': 86.09, '200X': 87.56, '400X': 83.79, 'avg_acc': 85.48, 'all_acc': 85.52}| Runtime: 1.2 mins
2023-12-04_02-49-04: Epoch: 10 | Train loss: 0.06585422884421172 | Train acc: {'40X': 97.99, '100X': 99.2, '200X': 99.34, '400X': 99.27, 'avg_acc': 98.95, 'all_acc': 98.94} | Valid loss: 0.4034544152021408 | Valid acc: {'40X': 84.96, '100X': 84.89, '200X': 87.06, '400X': 83.79, 'avg_acc': 85.18, 'all_acc': 85.21}| Runtime: 1.2 mins
2023-12-04_02-49-04: Train summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  78.24  79.55  83.06  80.55    80.35    80.34
1      2  83.10  85.15  87.80  87.52    85.89    85.85
2      3  85.61  87.69  89.73  89.46    88.12    88.09
3      4  87.37  89.64  91.78  90.38    89.79    89.78
4      5  89.69  92.13  92.70  92.39    91.73    91.72
5      6  91.70  94.87  95.77  95.22    94.39    94.38
6      7  94.56  96.78  97.01  97.07    96.36    96.35
7      8  95.23  98.47  97.84  97.62    97.29    97.30
8      9  97.07  98.56  98.59  98.72    98.24    98.23
9     10  97.99  99.20  99.34  99.27    98.95    98.94
2023-12-04_02-49-04: Eval summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  82.46  82.97  85.57  82.97    83.49    83.50
1      2  82.96  83.93  87.56  84.89    84.84    84.83
2      3  84.96  86.09  87.81  85.99    86.21    86.22
3      4  80.70  81.77  85.07  78.85    81.60    81.67
4      5  83.71  84.89  86.32  83.24    84.54    84.58
5      6  85.21  85.13  87.56  85.44    85.84    85.84
6      7  85.21  85.13  86.82  81.87    84.76    84.83
7      8  84.96  85.37  86.57  84.34    85.31    85.34
8      9  84.46  86.09  87.56  83.79    85.48    85.52
9     10  84.96  84.89  87.06  83.79    85.18    85.21
2023-12-04_02-49-04: Final test accuracy: {'40X': 83.46, '100X': 83.65, '200X': 92.06, '400X': 87.64, 'avg_acc': 86.7, 'all_acc': 86.66}
