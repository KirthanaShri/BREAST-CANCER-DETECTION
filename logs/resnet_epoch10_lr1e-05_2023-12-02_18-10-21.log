2023-12-02_18-10-21: config: {'n_epochs': 10, 'batch_size': 32, 'h': 224, 'w': 224, 'lr': 1e-05, 'optimizer': 'adam', 'momentum': 0.9, 'device': 'cuda', 'n_gpus': 2, 'kernel_size': 3, 'flatten': False, 'model': 'resnet', 'num_blocks_list': [3, 4, 6, 3], 'is_batchnorm': True}
2023-12-02_18-10-21: conv1.0.weight: torch.Size([64, 3, 3, 3])
2023-12-02_18-10-21: conv1.1.weight: torch.Size([64])
2023-12-02_18-10-21: conv1.1.bias: torch.Size([64])
2023-12-02_18-10-21: conv2_x.0.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_18-10-21: conv2_x.0.sequence.1.weight: torch.Size([64])
2023-12-02_18-10-21: conv2_x.0.sequence.1.bias: torch.Size([64])
2023-12-02_18-10-21: conv2_x.0.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_18-10-21: conv2_x.0.sequence.4.weight: torch.Size([64])
2023-12-02_18-10-21: conv2_x.0.sequence.4.bias: torch.Size([64])
2023-12-02_18-10-21: conv2_x.1.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_18-10-21: conv2_x.1.sequence.1.weight: torch.Size([64])
2023-12-02_18-10-21: conv2_x.1.sequence.1.bias: torch.Size([64])
2023-12-02_18-10-21: conv2_x.1.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_18-10-21: conv2_x.1.sequence.4.weight: torch.Size([64])
2023-12-02_18-10-21: conv2_x.1.sequence.4.bias: torch.Size([64])
2023-12-02_18-10-21: conv2_x.2.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_18-10-21: conv2_x.2.sequence.1.weight: torch.Size([64])
2023-12-02_18-10-21: conv2_x.2.sequence.1.bias: torch.Size([64])
2023-12-02_18-10-21: conv2_x.2.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_18-10-21: conv2_x.2.sequence.4.weight: torch.Size([64])
2023-12-02_18-10-21: conv2_x.2.sequence.4.bias: torch.Size([64])
2023-12-02_18-10-21: conv3_x.0.sequence.0.weight: torch.Size([128, 64, 3, 3])
2023-12-02_18-10-21: conv3_x.0.sequence.1.weight: torch.Size([128])
2023-12-02_18-10-21: conv3_x.0.sequence.1.bias: torch.Size([128])
2023-12-02_18-10-21: conv3_x.0.sequence.3.weight: torch.Size([128, 128, 3, 3])
2023-12-02_18-10-21: conv3_x.0.sequence.4.weight: torch.Size([128])
2023-12-02_18-10-21: conv3_x.0.sequence.4.bias: torch.Size([128])
2023-12-02_18-10-21: conv3_x.0.shortcut.0.weight: torch.Size([128, 64, 1, 1])
2023-12-02_18-10-21: conv3_x.0.shortcut.1.weight: torch.Size([128])
2023-12-02_18-10-21: conv3_x.0.shortcut.1.bias: torch.Size([128])
2023-12-02_18-10-21: conv3_x.1.sequence.0.weight: torch.Size([128, 128, 3, 3])
2023-12-02_18-10-21: conv3_x.1.sequence.1.weight: torch.Size([128])
2023-12-02_18-10-21: conv3_x.1.sequence.1.bias: torch.Size([128])
2023-12-02_18-10-21: conv3_x.1.sequence.3.weight: torch.Size([128, 128, 3, 3])
2023-12-02_18-10-21: conv3_x.1.sequence.4.weight: torch.Size([128])
2023-12-02_18-10-21: conv3_x.1.sequence.4.bias: torch.Size([128])
2023-12-02_18-10-21: conv3_x.2.sequence.0.weight: torch.Size([128, 128, 3, 3])
2023-12-02_18-10-21: conv3_x.2.sequence.1.weight: torch.Size([128])
2023-12-02_18-10-21: conv3_x.2.sequence.1.bias: torch.Size([128])
2023-12-02_18-10-21: conv3_x.2.sequence.3.weight: torch.Size([128, 128, 3, 3])
2023-12-02_18-10-21: conv3_x.2.sequence.4.weight: torch.Size([128])
2023-12-02_18-10-21: conv3_x.2.sequence.4.bias: torch.Size([128])
2023-12-02_18-10-21: conv3_x.3.sequence.0.weight: torch.Size([128, 128, 3, 3])
2023-12-02_18-10-21: conv3_x.3.sequence.1.weight: torch.Size([128])
2023-12-02_18-10-21: conv3_x.3.sequence.1.bias: torch.Size([128])
2023-12-02_18-10-21: conv3_x.3.sequence.3.weight: torch.Size([128, 128, 3, 3])
2023-12-02_18-10-21: conv3_x.3.sequence.4.weight: torch.Size([128])
2023-12-02_18-10-21: conv3_x.3.sequence.4.bias: torch.Size([128])
2023-12-02_18-10-21: conv4_x.0.sequence.0.weight: torch.Size([256, 128, 3, 3])
2023-12-02_18-10-21: conv4_x.0.sequence.1.weight: torch.Size([256])
2023-12-02_18-10-21: conv4_x.0.sequence.1.bias: torch.Size([256])
2023-12-02_18-10-21: conv4_x.0.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_18-10-21: conv4_x.0.sequence.4.weight: torch.Size([256])
2023-12-02_18-10-21: conv4_x.0.sequence.4.bias: torch.Size([256])
2023-12-02_18-10-21: conv4_x.0.shortcut.0.weight: torch.Size([256, 128, 1, 1])
2023-12-02_18-10-21: conv4_x.0.shortcut.1.weight: torch.Size([256])
2023-12-02_18-10-21: conv4_x.0.shortcut.1.bias: torch.Size([256])
2023-12-02_18-10-21: conv4_x.1.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_18-10-21: conv4_x.1.sequence.1.weight: torch.Size([256])
2023-12-02_18-10-21: conv4_x.1.sequence.1.bias: torch.Size([256])
2023-12-02_18-10-21: conv4_x.1.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_18-10-21: conv4_x.1.sequence.4.weight: torch.Size([256])
2023-12-02_18-10-21: conv4_x.1.sequence.4.bias: torch.Size([256])
2023-12-02_18-10-21: conv4_x.2.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_18-10-21: conv4_x.2.sequence.1.weight: torch.Size([256])
2023-12-02_18-10-21: conv4_x.2.sequence.1.bias: torch.Size([256])
2023-12-02_18-10-21: conv4_x.2.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_18-10-21: conv4_x.2.sequence.4.weight: torch.Size([256])
2023-12-02_18-10-21: conv4_x.2.sequence.4.bias: torch.Size([256])
2023-12-02_18-10-21: conv4_x.3.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_18-10-21: conv4_x.3.sequence.1.weight: torch.Size([256])
2023-12-02_18-10-21: conv4_x.3.sequence.1.bias: torch.Size([256])
2023-12-02_18-10-21: conv4_x.3.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_18-10-21: conv4_x.3.sequence.4.weight: torch.Size([256])
2023-12-02_18-10-21: conv4_x.3.sequence.4.bias: torch.Size([256])
2023-12-02_18-10-21: conv4_x.4.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_18-10-21: conv4_x.4.sequence.1.weight: torch.Size([256])
2023-12-02_18-10-21: conv4_x.4.sequence.1.bias: torch.Size([256])
2023-12-02_18-10-21: conv4_x.4.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_18-10-21: conv4_x.4.sequence.4.weight: torch.Size([256])
2023-12-02_18-10-21: conv4_x.4.sequence.4.bias: torch.Size([256])
2023-12-02_18-10-21: conv4_x.5.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_18-10-21: conv4_x.5.sequence.1.weight: torch.Size([256])
2023-12-02_18-10-21: conv4_x.5.sequence.1.bias: torch.Size([256])
2023-12-02_18-10-21: conv4_x.5.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_18-10-21: conv4_x.5.sequence.4.weight: torch.Size([256])
2023-12-02_18-10-21: conv4_x.5.sequence.4.bias: torch.Size([256])
2023-12-02_18-10-21: conv5_x.0.sequence.0.weight: torch.Size([512, 256, 3, 3])
2023-12-02_18-10-21: conv5_x.0.sequence.1.weight: torch.Size([512])
2023-12-02_18-10-21: conv5_x.0.sequence.1.bias: torch.Size([512])
2023-12-02_18-10-21: conv5_x.0.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_18-10-21: conv5_x.0.sequence.4.weight: torch.Size([512])
2023-12-02_18-10-21: conv5_x.0.sequence.4.bias: torch.Size([512])
2023-12-02_18-10-21: conv5_x.0.shortcut.0.weight: torch.Size([512, 256, 1, 1])
2023-12-02_18-10-21: conv5_x.0.shortcut.1.weight: torch.Size([512])
2023-12-02_18-10-21: conv5_x.0.shortcut.1.bias: torch.Size([512])
2023-12-02_18-10-21: conv5_x.1.sequence.0.weight: torch.Size([512, 512, 3, 3])
2023-12-02_18-10-21: conv5_x.1.sequence.1.weight: torch.Size([512])
2023-12-02_18-10-21: conv5_x.1.sequence.1.bias: torch.Size([512])
2023-12-02_18-10-21: conv5_x.1.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_18-10-21: conv5_x.1.sequence.4.weight: torch.Size([512])
2023-12-02_18-10-21: conv5_x.1.sequence.4.bias: torch.Size([512])
2023-12-02_18-10-21: conv5_x.2.sequence.0.weight: torch.Size([512, 512, 3, 3])
2023-12-02_18-10-21: conv5_x.2.sequence.1.weight: torch.Size([512])
2023-12-02_18-10-21: conv5_x.2.sequence.1.bias: torch.Size([512])
2023-12-02_18-10-21: conv5_x.2.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_18-10-21: conv5_x.2.sequence.4.weight: torch.Size([512])
2023-12-02_18-10-21: conv5_x.2.sequence.4.bias: torch.Size([512])
2023-12-02_18-10-21: fc.weight: torch.Size([2, 512])
2023-12-02_18-10-21: fc.bias: torch.Size([2])
2023-12-02_18-10-21: 
Total parameters: 21,278,018;	Trainable: 21,278,018
2023-12-02_18-12-01: Epoch: 2 | Train loss: 0.44856150901398145 | Train acc: {'40X': 74.9, '100X': 76.97, '200X': 80.22, '400X': 79.3, 'avg_acc': 77.85, 'all_acc': 77.81} | Valid loss: 0.40288068771362306 | Valid acc: {'40X': 79.7, '100X': 80.1, '200X': 85.32, '400X': 81.59, 'avg_acc': 81.68, 'all_acc': 81.67}| Runtime: 1.7 mins
2023-12-02_18-13-40: Epoch: 3 | Train loss: 0.3615722291775652 | Train acc: {'40X': 81.22, '100X': 82.26, '200X': 86.73, '400X': 83.87, 'avg_acc': 83.52, 'all_acc': 83.51} | Valid loss: 0.41498077034950254 | Valid acc: {'40X': 84.96, '100X': 85.13, '200X': 86.57, '400X': 84.89, 'avg_acc': 85.39, 'all_acc': 85.4}| Runtime: 1.7 mins
2023-12-02_18-15-20: Epoch: 4 | Train loss: 0.35256648194548246 | Train acc: {'40X': 81.99, '100X': 82.65, '200X': 85.83, '400X': 86.88, 'avg_acc': 84.34, 'all_acc': 84.27} | Valid loss: 0.37293623059988024 | Valid acc: {'40X': 81.2, '100X': 83.69, '200X': 87.56, '400X': 82.14, 'avg_acc': 83.65, 'all_acc': 83.69}| Runtime: 1.7 mins
2023-12-02_18-17-00: Epoch: 5 | Train loss: 0.3258686405984131 | Train acc: {'40X': 81.63, '100X': 85.96, '200X': 87.17, '400X': 88.35, 'avg_acc': 85.78, 'all_acc': 85.73} | Valid loss: 0.29287526711821554 | Valid acc: {'40X': 84.21, '100X': 89.45, '200X': 91.04, '400X': 86.54, 'avg_acc': 87.81, 'all_acc': 87.86}| Runtime: 1.7 mins
2023-12-02_18-18-40: Epoch: 6 | Train loss: 0.3153768110315542 | Train acc: {'40X': 83.42, '100X': 86.13, '200X': 87.72, '400X': 87.61, 'avg_acc': 86.22, 'all_acc': 86.19} | Valid loss: 0.2745631362497807 | Valid acc: {'40X': 84.96, '100X': 89.45, '200X': 90.8, '400X': 87.91, 'avg_acc': 88.28, 'all_acc': 88.31}| Runtime: 1.7 mins
2023-12-02_18-20-20: Epoch: 7 | Train loss: 0.296556175057147 | Train acc: {'40X': 85.62, '100X': 87.0, '200X': 89.29, '400X': 88.71, 'avg_acc': 87.66, 'all_acc': 87.63} | Valid loss: 0.259290854036808 | Valid acc: {'40X': 87.22, '100X': 88.01, '200X': 90.05, '400X': 89.01, 'avg_acc': 88.57, 'all_acc': 88.56}| Runtime: 1.7 mins
2023-12-02_18-22-00: Epoch: 8 | Train loss: 0.2933691786350431 | Train acc: {'40X': 85.71, '100X': 86.04, '200X': 88.71, '400X': 89.25, 'avg_acc': 87.43, 'all_acc': 87.37} | Valid loss: 0.26139539092779157 | Valid acc: {'40X': 86.22, '100X': 89.93, '200X': 91.29, '400X': 87.64, 'avg_acc': 88.77, 'all_acc': 88.81}| Runtime: 1.7 mins
2023-12-02_18-23-43: Epoch: 9 | Train loss: 0.2825608557543239 | Train acc: {'40X': 85.91, '100X': 86.53, '200X': 90.06, '400X': 88.72, 'avg_acc': 87.8, 'all_acc': 87.77} | Valid loss: 0.3925592263042927 | Valid acc: {'40X': 82.46, '100X': 84.89, '200X': 87.56, '400X': 87.64, 'avg_acc': 85.64, 'all_acc': 85.59}| Runtime: 1.7 mins
2023-12-02_18-25-23: Epoch: 10 | Train loss: 0.2708729250306213 | Train acc: {'40X': 86.54, '100X': 87.07, '200X': 90.56, '400X': 88.42, 'avg_acc': 88.15, 'all_acc': 88.13} | Valid loss: 0.2628083348274231 | Valid acc: {'40X': 88.22, '100X': 90.17, '200X': 92.04, '400X': 87.64, 'avg_acc': 89.52, 'all_acc': 89.57}| Runtime: 1.7 mins
2023-12-02_18-27-04: Epoch: 11 | Train loss: 0.2639507795809894 | Train acc: {'40X': 86.85, '100X': 88.61, '200X': 89.89, '400X': 88.97, 'avg_acc': 88.58, 'all_acc': 88.58} | Valid loss: 0.23350889340043068 | Valid acc: {'40X': 87.72, '100X': 91.37, '200X': 91.54, '400X': 89.56, 'avg_acc': 90.05, 'all_acc': 90.08}| Runtime: 1.7 mins
2023-12-02_18-27-04: Train summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  74.90  76.97  80.22  79.30    77.85    77.81
1      2  81.22  82.26  86.73  83.87    83.52    83.51
2      3  81.99  82.65  85.83  86.88    84.34    84.27
3      4  81.63  85.96  87.17  88.35    85.78    85.73
4      5  83.42  86.13  87.72  87.61    86.22    86.19
5      6  85.62  87.00  89.29  88.71    87.66    87.63
6      7  85.71  86.04  88.71  89.25    87.43    87.37
7      8  85.91  86.53  90.06  88.72    87.80    87.77
8      9  86.54  87.07  90.56  88.42    88.15    88.13
9     10  86.85  88.61  89.89  88.97    88.58    88.58
2023-12-02_18-27-04: Eval summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  79.70  80.10  85.32  81.59    81.68    81.67
1      2  84.96  85.13  86.57  84.89    85.39    85.40
2      3  81.20  83.69  87.56  82.14    83.65    83.69
3      4  84.21  89.45  91.04  86.54    87.81    87.86
4      5  84.96  89.45  90.80  87.91    88.28    88.31
5      6  87.22  88.01  90.05  89.01    88.57    88.56
6      7  86.22  89.93  91.29  87.64    88.77    88.81
7      8  82.46  84.89  87.56  87.64    85.64    85.59
8      9  88.22  90.17  92.04  87.64    89.52    89.57
9     10  87.72  91.37  91.54  89.56    90.05    90.08
2023-12-02_18-27-04: Final test accuracy: {'40X': 88.72, '100X': 88.22, '200X': 93.55, '400X': 88.74, 'avg_acc': 89.81, 'all_acc': 89.82}
