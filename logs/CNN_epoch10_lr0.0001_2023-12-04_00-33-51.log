2023-12-04_00-33-51: config: {'n_epochs': 10, 'batch_size': 32, 'h': 224, 'w': 224, 'lr': 0.0001, 'optimizer': 'adam', 'momentum': 0.9, 'weight_decay': 0, 'device': 'cuda:1', 'n_gpus': 1, 'kernel_size': 3, 'model': 'CNN', 'use_pooling': True, 'num_kernel_conv_list': [32, 64, 64, 64]}
2023-12-04_00-33-51: conv1.weight: torch.Size([32, 3, 3, 3])
2023-12-04_00-33-51: conv1.bias: torch.Size([32])
2023-12-04_00-33-51: conv_layers.0.weight: torch.Size([64, 32, 3, 3])
2023-12-04_00-33-51: conv_layers.0.bias: torch.Size([64])
2023-12-04_00-33-51: conv_layers.3.weight: torch.Size([64, 64, 3, 3])
2023-12-04_00-33-51: conv_layers.3.bias: torch.Size([64])
2023-12-04_00-33-51: conv_layers.6.weight: torch.Size([64, 64, 3, 3])
2023-12-04_00-33-51: conv_layers.6.bias: torch.Size([64])
2023-12-04_00-33-51: linear.weight: torch.Size([2, 50176])
2023-12-04_00-33-51: linear.bias: torch.Size([2])
2023-12-04_00-33-51: 
Total parameters: 193,602;	Trainable: 193,602
2023-12-04_00-34-45: Epoch: 1 | Train loss: 0.41633333960497704 | Train acc: {'40X': 80.8, '100X': 81.2, '200X': 82.75, '400X': 84.71, 'avg_acc': 82.36, 'all_acc': 82.31} | Valid loss: 0.3746834850311279 | Valid acc: {'40X': 82.46, '100X': 82.25, '200X': 86.07, '400X': 83.79, 'avg_acc': 83.64, 'all_acc': 83.63}| Runtime: 0.9 mins
2023-12-04_00-35-40: Epoch: 2 | Train loss: 0.3383257504854653 | Train acc: {'40X': 84.11, '100X': 84.04, '200X': 87.47, '400X': 86.49, 'avg_acc': 85.53, 'all_acc': 85.49} | Valid loss: 0.31565989017486573 | Valid acc: {'40X': 85.96, '100X': 85.85, '200X': 86.57, '400X': 83.52, 'avg_acc': 85.48, 'all_acc': 85.52}| Runtime: 0.9 mins
2023-12-04_00-36-34: Epoch: 3 | Train loss: 0.30538031035983887 | Train acc: {'40X': 86.11, '100X': 85.86, '200X': 88.74, '400X': 87.96, 'avg_acc': 87.17, 'all_acc': 87.14} | Valid loss: 0.30271282851696013 | Valid acc: {'40X': 84.71, '100X': 86.81, '200X': 88.06, '400X': 88.19, 'avg_acc': 86.94, 'all_acc': 86.92}| Runtime: 0.9 mins
2023-12-04_00-37-28: Epoch: 4 | Train loss: 0.2740465563193366 | Train acc: {'40X': 87.27, '100X': 87.01, '200X': 89.21, '400X': 88.17, 'avg_acc': 87.92, 'all_acc': 87.9} | Valid loss: 0.29033713981509207 | Valid acc: {'40X': 86.47, '100X': 88.73, '200X': 88.56, '400X': 84.34, 'avg_acc': 87.02, 'all_acc': 87.1}| Runtime: 0.9 mins
2023-12-04_00-38-22: Epoch: 5 | Train loss: 0.24612649046891444 | Train acc: {'40X': 89.12, '100X': 89.09, '200X': 90.7, '400X': 89.72, 'avg_acc': 89.66, 'all_acc': 89.65} | Valid loss: 0.2934549757838249 | Valid acc: {'40X': 87.47, '100X': 87.53, '200X': 89.8, '400X': 83.24, 'avg_acc': 87.01, 'all_acc': 87.1}| Runtime: 0.9 mins
2023-12-04_00-39-16: Epoch: 6 | Train loss: 0.218600018956774 | Train acc: {'40X': 89.79, '100X': 89.72, '200X': 92.95, '400X': 92.3, 'avg_acc': 91.19, 'all_acc': 91.15} | Valid loss: 0.280161302536726 | Valid acc: {'40X': 86.22, '100X': 88.01, '200X': 89.8, '400X': 85.44, 'avg_acc': 87.37, 'all_acc': 87.42}| Runtime: 0.9 mins
2023-12-04_00-40-10: Epoch: 7 | Train loss: 0.1893067393653296 | Train acc: {'40X': 92.05, '100X': 91.47, '200X': 93.04, '400X': 93.5, 'avg_acc': 92.52, 'all_acc': 92.48} | Valid loss: 0.3206243148446083 | Valid acc: {'40X': 86.47, '100X': 87.77, '200X': 89.3, '400X': 84.89, 'avg_acc': 87.11, 'all_acc': 87.17}| Runtime: 0.9 mins
2023-12-04_00-41-04: Epoch: 8 | Train loss: 0.16845504536822037 | Train acc: {'40X': 92.54, '100X': 93.34, '200X': 94.28, '400X': 93.39, 'avg_acc': 93.39, 'all_acc': 93.39} | Valid loss: 0.2630282266438007 | Valid acc: {'40X': 89.97, '100X': 91.61, '200X': 90.3, '400X': 85.44, 'avg_acc': 89.33, 'all_acc': 89.44}| Runtime: 0.9 mins
2023-12-04_00-41-58: Epoch: 9 | Train loss: 0.14348760464958646 | Train acc: {'40X': 93.14, '100X': 93.98, '200X': 95.68, '400X': 94.5, 'avg_acc': 94.32, 'all_acc': 94.32} | Valid loss: 0.33336018279194835 | Valid acc: {'40X': 86.22, '100X': 86.33, '200X': 89.55, '400X': 84.07, 'avg_acc': 86.54, 'all_acc': 86.6}| Runtime: 0.9 mins
2023-12-04_00-42-52: Epoch: 10 | Train loss: 0.11789379313562971 | Train acc: {'40X': 93.97, '100X': 95.5, '200X': 96.77, '400X': 96.05, 'avg_acc': 95.57, 'all_acc': 95.57} | Valid loss: 0.3331748402118683 | Valid acc: {'40X': 88.47, '100X': 88.49, '200X': 88.06, '400X': 84.07, 'avg_acc': 87.27, 'all_acc': 87.36}| Runtime: 0.9 mins
2023-12-04_00-42-52: Train summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  80.80  81.20  82.75  84.71    82.36    82.31
1      2  84.11  84.04  87.47  86.49    85.53    85.49
2      3  86.11  85.86  88.74  87.96    87.17    87.14
3      4  87.27  87.01  89.21  88.17    87.92    87.90
4      5  89.12  89.09  90.70  89.72    89.66    89.65
5      6  89.79  89.72  92.95  92.30    91.19    91.15
6      7  92.05  91.47  93.04  93.50    92.52    92.48
7      8  92.54  93.34  94.28  93.39    93.39    93.39
8      9  93.14  93.98  95.68  94.50    94.32    94.32
9     10  93.97  95.50  96.77  96.05    95.57    95.57
2023-12-04_00-42-52: Eval summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  82.46  82.25  86.07  83.79    83.64    83.63
1      2  85.96  85.85  86.57  83.52    85.48    85.52
2      3  84.71  86.81  88.06  88.19    86.94    86.92
3      4  86.47  88.73  88.56  84.34    87.02    87.10
4      5  87.47  87.53  89.80  83.24    87.01    87.10
5      6  86.22  88.01  89.80  85.44    87.37    87.42
6      7  86.47  87.77  89.30  84.89    87.11    87.17
7      8  89.97  91.61  90.30  85.44    89.33    89.44
8      9  86.22  86.33  89.55  84.07    86.54    86.60
9     10  88.47  88.49  88.06  84.07    87.27    87.36
2023-12-04_00-42-52: Final test accuracy: {'40X': 86.47, '100X': 88.46, '200X': 92.06, '400X': 88.46, 'avg_acc': 88.86, 'all_acc': 88.87}
