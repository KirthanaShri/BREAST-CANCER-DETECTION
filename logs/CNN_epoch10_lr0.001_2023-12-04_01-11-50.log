2023-12-04_01-11-50: config: {'n_epochs': 10, 'batch_size': 32, 'h': 224, 'w': 224, 'lr': 0.001, 'optimizer': 'adam', 'momentum': 0.9, 'weight_decay': 0, 'device': 'cuda:1', 'n_gpus': 1, 'kernel_size': 3, 'model': 'CNN', 'use_pooling': True, 'num_kernel_conv_list': [32, 64, 64, 64]}
2023-12-04_01-11-50: conv1.weight: torch.Size([32, 3, 3, 3])
2023-12-04_01-11-50: conv1.bias: torch.Size([32])
2023-12-04_01-11-50: conv_layers.0.weight: torch.Size([64, 32, 3, 3])
2023-12-04_01-11-50: conv_layers.0.bias: torch.Size([64])
2023-12-04_01-11-50: conv_layers.3.weight: torch.Size([64, 64, 3, 3])
2023-12-04_01-11-50: conv_layers.3.bias: torch.Size([64])
2023-12-04_01-11-50: conv_layers.6.weight: torch.Size([64, 64, 3, 3])
2023-12-04_01-11-50: conv_layers.6.bias: torch.Size([64])
2023-12-04_01-11-50: linear.weight: torch.Size([2, 50176])
2023-12-04_01-11-50: linear.bias: torch.Size([2])
2023-12-04_01-11-50: 
Total parameters: 193,602;	Trainable: 193,602
2023-12-04_01-12-44: Epoch: 1 | Train loss: 0.4670069349577298 | Train acc: {'40X': 79.37, '100X': 81.66, '200X': 84.9, '400X': 81.39, 'avg_acc': 81.83, 'all_acc': 81.84} | Valid loss: 0.37155262678861617 | Valid acc: {'40X': 83.96, '100X': 84.65, '200X': 84.83, '400X': 80.77, 'avg_acc': 83.55, 'all_acc': 83.63}| Runtime: 0.9 mins
2023-12-04_01-13-38: Epoch: 2 | Train loss: 0.3672283149852946 | Train acc: {'40X': 82.69, '100X': 83.87, '200X': 86.72, '400X': 84.85, 'avg_acc': 84.53, 'all_acc': 84.52} | Valid loss: 0.36727298438549044 | Valid acc: {'40X': 84.21, '100X': 83.93, '200X': 85.57, '400X': 83.24, 'avg_acc': 84.24, 'all_acc': 84.26}| Runtime: 0.9 mins
2023-12-04_01-14-33: Epoch: 3 | Train loss: 0.3338535142105979 | Train acc: {'40X': 84.33, '100X': 85.71, '200X': 87.48, '400X': 85.33, 'avg_acc': 85.71, 'all_acc': 85.73} | Valid loss: 0.3502304536104202 | Valid acc: {'40X': 85.71, '100X': 88.97, '200X': 87.81, '400X': 86.54, 'avg_acc': 87.26, 'all_acc': 87.29}| Runtime: 0.9 mins
2023-12-04_01-15-27: Epoch: 4 | Train loss: 0.2969436642487307 | Train acc: {'40X': 86.86, '100X': 87.33, '200X': 87.72, '400X': 86.96, 'avg_acc': 87.22, 'all_acc': 87.23} | Valid loss: 0.3415792343020439 | Valid acc: {'40X': 82.21, '100X': 84.17, '200X': 86.82, '400X': 82.69, 'avg_acc': 83.97, 'all_acc': 84.01}| Runtime: 0.9 mins
2023-12-04_01-16-22: Epoch: 5 | Train loss: 0.24599357578601386 | Train acc: {'40X': 89.46, '100X': 88.76, '200X': 89.29, '400X': 88.73, 'avg_acc': 89.06, 'all_acc': 89.06} | Valid loss: 0.2663393703103065 | Valid acc: {'40X': 89.72, '100X': 91.61, '200X': 90.05, '400X': 86.26, 'avg_acc': 89.41, 'all_acc': 89.51}| Runtime: 0.9 mins
2023-12-04_01-17-16: Epoch: 6 | Train loss: 0.17616267230462385 | Train acc: {'40X': 91.79, '100X': 92.29, '200X': 94.04, '400X': 92.93, 'avg_acc': 92.76, 'all_acc': 92.76} | Valid loss: 0.28527591228485105 | Valid acc: {'40X': 89.22, '100X': 89.93, '200X': 91.04, '400X': 85.44, 'avg_acc': 88.91, 'all_acc': 89.0}| Runtime: 0.9 mins
2023-12-04_01-18-10: Epoch: 7 | Train loss: 0.13529766053968184 | Train acc: {'40X': 94.98, '100X': 94.38, '200X': 94.87, '400X': 93.93, 'avg_acc': 94.54, 'all_acc': 94.55} | Valid loss: 0.6081368923187256 | Valid acc: {'40X': 83.46, '100X': 83.21, '200X': 86.07, '400X': 80.22, 'avg_acc': 83.24, 'all_acc': 83.31}| Runtime: 0.9 mins
2023-12-04_01-19-04: Epoch: 8 | Train loss: 0.09271561043223718 | Train acc: {'40X': 95.31, '100X': 96.47, '200X': 97.35, '400X': 96.61, 'avg_acc': 96.44, 'all_acc': 96.43} | Valid loss: 0.3837751334905624 | Valid acc: {'40X': 87.97, '100X': 88.01, '200X': 89.55, '400X': 87.91, 'avg_acc': 88.36, 'all_acc': 88.37}| Runtime: 0.9 mins
2023-12-04_01-19-59: Epoch: 9 | Train loss: 0.05405445407086518 | Train acc: {'40X': 97.74, '100X': 98.31, '200X': 98.09, '400X': 98.35, 'avg_acc': 98.12, 'all_acc': 98.12} | Valid loss: 0.618085800036788 | Valid acc: {'40X': 86.47, '100X': 86.09, '200X': 87.06, '400X': 85.16, 'avg_acc': 86.2, 'all_acc': 86.22}| Runtime: 0.9 mins
2023-12-04_01-20-53: Epoch: 10 | Train loss: 0.05039202150018773 | Train acc: {'40X': 97.82, '100X': 98.64, '200X': 98.51, '400X': 97.71, 'avg_acc': 98.17, 'all_acc': 98.18} | Valid loss: 0.6686129301786423 | Valid acc: {'40X': 87.22, '100X': 88.97, '200X': 89.3, '400X': 85.44, 'avg_acc': 87.73, 'all_acc': 87.8}| Runtime: 0.9 mins
2023-12-04_01-20-53: Train summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  79.37  81.66  84.90  81.39    81.83    81.84
1      2  82.69  83.87  86.72  84.85    84.53    84.52
2      3  84.33  85.71  87.48  85.33    85.71    85.73
3      4  86.86  87.33  87.72  86.96    87.22    87.23
4      5  89.46  88.76  89.29  88.73    89.06    89.06
5      6  91.79  92.29  94.04  92.93    92.76    92.76
6      7  94.98  94.38  94.87  93.93    94.54    94.55
7      8  95.31  96.47  97.35  96.61    96.44    96.43
8      9  97.74  98.31  98.09  98.35    98.12    98.12
9     10  97.82  98.64  98.51  97.71    98.17    98.18
2023-12-04_01-20-53: Eval summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  83.96  84.65  84.83  80.77    83.55    83.63
1      2  84.21  83.93  85.57  83.24    84.24    84.26
2      3  85.71  88.97  87.81  86.54    87.26    87.29
3      4  82.21  84.17  86.82  82.69    83.97    84.01
4      5  89.72  91.61  90.05  86.26    89.41    89.51
5      6  89.22  89.93  91.04  85.44    88.91    89.00
6      7  83.46  83.21  86.07  80.22    83.24    83.31
7      8  87.97  88.01  89.55  87.91    88.36    88.37
8      9  86.47  86.09  87.06  85.16    86.20    86.22
9     10  87.22  88.97  89.30  85.44    87.73    87.80
2023-12-04_01-20-53: Final test accuracy: {'40X': 88.22, '100X': 90.14, '200X': 91.07, '400X': 87.09, 'avg_acc': 89.13, 'all_acc': 89.19}
