2023-12-04_01-20-41: config: {'n_epochs': 10, 'batch_size': 32, 'h': 224, 'w': 224, 'lr': 0.001, 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0, 'device': 'cuda:1', 'n_gpus': 1, 'kernel_size': 3, 'model': 'CNN', 'use_pooling': False, 'num_kernel_conv_list': [32, 64, 64, 64]}
2023-12-04_01-20-41: conv1.weight: torch.Size([32, 3, 3, 3])
2023-12-04_01-20-41: conv1.bias: torch.Size([32])
2023-12-04_01-20-41: conv_layers.0.weight: torch.Size([64, 32, 3, 3])
2023-12-04_01-20-41: conv_layers.0.bias: torch.Size([64])
2023-12-04_01-20-41: conv_layers.2.weight: torch.Size([64, 64, 3, 3])
2023-12-04_01-20-41: conv_layers.2.bias: torch.Size([64])
2023-12-04_01-20-41: conv_layers.4.weight: torch.Size([64, 64, 3, 3])
2023-12-04_01-20-41: conv_layers.4.bias: torch.Size([64])
2023-12-04_01-20-41: linear.weight: torch.Size([2, 3211264])
2023-12-04_01-20-41: linear.bias: torch.Size([2])
2023-12-04_01-20-41: 
Total parameters: 6,515,778;	Trainable: 6,515,778
2023-12-04_01-21-44: Epoch: 1 | Train loss: 0.45650498468328166 | Train acc: {'40X': 78.21, '100X': 80.35, '200X': 83.25, '400X': 82.48, 'avg_acc': 81.07, 'all_acc': 81.04} | Valid loss: 0.35714850679039956 | Valid acc: {'40X': 84.21, '100X': 85.85, '200X': 85.07, '400X': 85.44, 'avg_acc': 85.14, 'all_acc': 85.15}| Runtime: 1.0 mins
2023-12-04_01-22-45: Epoch: 2 | Train loss: 0.33560856260560656 | Train acc: {'40X': 83.93, '100X': 85.39, '200X': 87.79, '400X': 85.43, 'avg_acc': 85.64, 'all_acc': 85.64} | Valid loss: 0.3411088863015175 | Valid acc: {'40X': 84.46, '100X': 87.53, '200X': 86.82, '400X': 83.52, 'avg_acc': 85.58, 'all_acc': 85.65}| Runtime: 1.0 mins
2023-12-04_01-23-49: Epoch: 3 | Train loss: 0.28252046905155925 | Train acc: {'40X': 87.01, '100X': 87.32, '200X': 89.55, '400X': 88.45, 'avg_acc': 88.08, 'all_acc': 88.07} | Valid loss: 0.4908780819177628 | Valid acc: {'40X': 81.45, '100X': 88.25, '200X': 86.07, '400X': 84.89, 'avg_acc': 85.16, 'all_acc': 85.21}| Runtime: 1.1 mins
2023-12-04_01-24-52: Epoch: 4 | Train loss: 0.2141387567830247 | Train acc: {'40X': 90.79, '100X': 91.01, '200X': 93.03, '400X': 92.75, 'avg_acc': 91.9, 'all_acc': 91.87} | Valid loss: 0.395617396235466 | Valid acc: {'40X': 82.21, '100X': 84.17, '200X': 85.32, '400X': 76.92, 'avg_acc': 82.16, 'all_acc': 82.3}| Runtime: 1.0 mins
2023-12-04_01-25-55: Epoch: 5 | Train loss: 0.1494802102647923 | Train acc: {'40X': 93.98, '100X': 94.37, '200X': 96.18, '400X': 94.78, 'avg_acc': 94.83, 'all_acc': 94.83} | Valid loss: 0.38966540321707727 | Valid acc: {'40X': 85.71, '100X': 87.53, '200X': 86.07, '400X': 84.07, 'avg_acc': 85.84, 'all_acc': 85.9}| Runtime: 1.1 mins
2023-12-04_01-26-58: Epoch: 6 | Train loss: 0.06138881655863008 | Train acc: {'40X': 97.57, '100X': 98.72, '200X': 98.26, '400X': 98.07, 'avg_acc': 98.16, 'all_acc': 98.16} | Valid loss: 0.6053244069218635 | Valid acc: {'40X': 83.71, '100X': 84.65, '200X': 85.57, '400X': 81.04, 'avg_acc': 83.74, 'all_acc': 83.82}| Runtime: 1.1 mins
2023-12-04_01-28-01: Epoch: 7 | Train loss: 0.028217111705531796 | Train acc: {'40X': 99.08, '100X': 99.6, '200X': 99.42, '400X': 98.99, 'avg_acc': 99.27, 'all_acc': 99.28} | Valid loss: 0.660396952778101 | Valid acc: {'40X': 86.22, '100X': 86.57, '200X': 86.32, '400X': 84.07, 'avg_acc': 85.8, 'all_acc': 85.84}| Runtime: 1.0 mins
2023-12-04_01-29-05: Epoch: 8 | Train loss: 0.016666445039476997 | Train acc: {'40X': 99.41, '100X': 99.84, '200X': 99.75, '400X': 99.54, 'avg_acc': 99.64, 'all_acc': 99.64} | Valid loss: 0.8755060434341431 | Valid acc: {'40X': 82.96, '100X': 84.41, '200X': 86.57, '400X': 82.69, 'avg_acc': 84.16, 'all_acc': 84.2}| Runtime: 1.1 mins
2023-12-04_01-30-09: Epoch: 9 | Train loss: 0.0071177030124975295 | Train acc: {'40X': 99.83, '100X': 99.92, '200X': 99.92, '400X': 99.82, 'avg_acc': 99.87, 'all_acc': 99.87} | Valid loss: 0.7622034654580057 | Valid acc: {'40X': 83.71, '100X': 85.61, '200X': 87.06, '400X': 82.69, 'avg_acc': 84.77, 'all_acc': 84.83}| Runtime: 1.1 mins
2023-12-04_01-31-12: Epoch: 10 | Train loss: 0.0016710789025858725 | Train acc: {'40X': 100.0, '100X': 100.0, '200X': 100.0, '400X': 100.0, 'avg_acc': 100.0, 'all_acc': 100.0} | Valid loss: 0.7236165671050548 | Valid acc: {'40X': 84.46, '100X': 86.09, '200X': 87.31, '400X': 82.97, 'avg_acc': 85.21, 'all_acc': 85.27}| Runtime: 1.1 mins
2023-12-04_01-31-12: Train summary:    epoch     40X    100X    200X    400X  avg_acc  all_acc
0      1   78.21   80.35   83.25   82.48    81.07    81.04
1      2   83.93   85.39   87.79   85.43    85.64    85.64
2      3   87.01   87.32   89.55   88.45    88.08    88.07
3      4   90.79   91.01   93.03   92.75    91.90    91.87
4      5   93.98   94.37   96.18   94.78    94.83    94.83
5      6   97.57   98.72   98.26   98.07    98.16    98.16
6      7   99.08   99.60   99.42   98.99    99.27    99.28
7      8   99.41   99.84   99.75   99.54    99.64    99.64
8      9   99.83   99.92   99.92   99.82    99.87    99.87
9     10  100.00  100.00  100.00  100.00   100.00   100.00
2023-12-04_01-31-12: Eval summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  84.21  85.85  85.07  85.44    85.14    85.15
1      2  84.46  87.53  86.82  83.52    85.58    85.65
2      3  81.45  88.25  86.07  84.89    85.16    85.21
3      4  82.21  84.17  85.32  76.92    82.16    82.30
4      5  85.71  87.53  86.07  84.07    85.84    85.90
5      6  83.71  84.65  85.57  81.04    83.74    83.82
6      7  86.22  86.57  86.32  84.07    85.80    85.84
7      8  82.96  84.41  86.57  82.69    84.16    84.20
8      9  83.71  85.61  87.06  82.69    84.77    84.83
9     10  84.46  86.09  87.31  82.97    85.21    85.27
2023-12-04_01-31-12: Final test accuracy: {'40X': 84.96, '100X': 84.13, '200X': 91.32, '400X': 84.07, 'avg_acc': 86.12, 'all_acc': 86.16}
