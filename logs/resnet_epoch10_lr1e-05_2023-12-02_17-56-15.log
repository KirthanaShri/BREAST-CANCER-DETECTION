2023-12-02_17-56-15: config: {'n_epochs': 10, 'batch_size': 32, 'h': 224, 'w': 224, 'lr': 1e-05, 'optimizer': 'adam', 'momentum': 0.9, 'device': 'cuda', 'n_gpus': 2, 'kernel_size': 3, 'flatten': False, 'model': 'resnet', 'num_blocks_list': [3, 2, 3, 4], 'is_batchnorm': False}
2023-12-02_17-56-15: conv1.0.weight: torch.Size([64, 3, 3, 3])
2023-12-02_17-56-15: conv1.1.weight: torch.Size([64])
2023-12-02_17-56-15: conv1.1.bias: torch.Size([64])
2023-12-02_17-56-15: conv2_x.0.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_17-56-15: conv2_x.0.sequence.1.weight: torch.Size([64])
2023-12-02_17-56-15: conv2_x.0.sequence.1.bias: torch.Size([64])
2023-12-02_17-56-15: conv2_x.0.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_17-56-15: conv2_x.0.sequence.4.weight: torch.Size([64])
2023-12-02_17-56-15: conv2_x.0.sequence.4.bias: torch.Size([64])
2023-12-02_17-56-15: conv2_x.1.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_17-56-15: conv2_x.1.sequence.1.weight: torch.Size([64])
2023-12-02_17-56-15: conv2_x.1.sequence.1.bias: torch.Size([64])
2023-12-02_17-56-15: conv2_x.1.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_17-56-15: conv2_x.1.sequence.4.weight: torch.Size([64])
2023-12-02_17-56-15: conv2_x.1.sequence.4.bias: torch.Size([64])
2023-12-02_17-56-15: conv2_x.2.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_17-56-15: conv2_x.2.sequence.1.weight: torch.Size([64])
2023-12-02_17-56-15: conv2_x.2.sequence.1.bias: torch.Size([64])
2023-12-02_17-56-15: conv2_x.2.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_17-56-15: conv2_x.2.sequence.4.weight: torch.Size([64])
2023-12-02_17-56-15: conv2_x.2.sequence.4.bias: torch.Size([64])
2023-12-02_17-56-15: conv3_x.0.sequence.0.weight: torch.Size([128, 64, 3, 3])
2023-12-02_17-56-15: conv3_x.0.sequence.1.weight: torch.Size([128])
2023-12-02_17-56-15: conv3_x.0.sequence.1.bias: torch.Size([128])
2023-12-02_17-56-15: conv3_x.0.sequence.3.weight: torch.Size([128, 128, 3, 3])
2023-12-02_17-56-15: conv3_x.0.sequence.4.weight: torch.Size([128])
2023-12-02_17-56-15: conv3_x.0.sequence.4.bias: torch.Size([128])
2023-12-02_17-56-15: conv3_x.0.shortcut.0.weight: torch.Size([128, 64, 1, 1])
2023-12-02_17-56-15: conv3_x.0.shortcut.1.weight: torch.Size([128])
2023-12-02_17-56-15: conv3_x.0.shortcut.1.bias: torch.Size([128])
2023-12-02_17-56-15: conv3_x.1.sequence.0.weight: torch.Size([128, 128, 3, 3])
2023-12-02_17-56-15: conv3_x.1.sequence.1.weight: torch.Size([128])
2023-12-02_17-56-15: conv3_x.1.sequence.1.bias: torch.Size([128])
2023-12-02_17-56-15: conv3_x.1.sequence.3.weight: torch.Size([128, 128, 3, 3])
2023-12-02_17-56-15: conv3_x.1.sequence.4.weight: torch.Size([128])
2023-12-02_17-56-15: conv3_x.1.sequence.4.bias: torch.Size([128])
2023-12-02_17-56-15: conv4_x.0.sequence.0.weight: torch.Size([256, 128, 3, 3])
2023-12-02_17-56-15: conv4_x.0.sequence.1.weight: torch.Size([256])
2023-12-02_17-56-15: conv4_x.0.sequence.1.bias: torch.Size([256])
2023-12-02_17-56-15: conv4_x.0.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_17-56-15: conv4_x.0.sequence.4.weight: torch.Size([256])
2023-12-02_17-56-15: conv4_x.0.sequence.4.bias: torch.Size([256])
2023-12-02_17-56-15: conv4_x.0.shortcut.0.weight: torch.Size([256, 128, 1, 1])
2023-12-02_17-56-15: conv4_x.0.shortcut.1.weight: torch.Size([256])
2023-12-02_17-56-15: conv4_x.0.shortcut.1.bias: torch.Size([256])
2023-12-02_17-56-15: conv4_x.1.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_17-56-15: conv4_x.1.sequence.1.weight: torch.Size([256])
2023-12-02_17-56-15: conv4_x.1.sequence.1.bias: torch.Size([256])
2023-12-02_17-56-15: conv4_x.1.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_17-56-15: conv4_x.1.sequence.4.weight: torch.Size([256])
2023-12-02_17-56-15: conv4_x.1.sequence.4.bias: torch.Size([256])
2023-12-02_17-56-15: conv4_x.2.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_17-56-15: conv4_x.2.sequence.1.weight: torch.Size([256])
2023-12-02_17-56-15: conv4_x.2.sequence.1.bias: torch.Size([256])
2023-12-02_17-56-15: conv4_x.2.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_17-56-15: conv4_x.2.sequence.4.weight: torch.Size([256])
2023-12-02_17-56-15: conv4_x.2.sequence.4.bias: torch.Size([256])
2023-12-02_17-56-15: conv5_x.0.sequence.0.weight: torch.Size([512, 256, 3, 3])
2023-12-02_17-56-15: conv5_x.0.sequence.1.weight: torch.Size([512])
2023-12-02_17-56-15: conv5_x.0.sequence.1.bias: torch.Size([512])
2023-12-02_17-56-15: conv5_x.0.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_17-56-15: conv5_x.0.sequence.4.weight: torch.Size([512])
2023-12-02_17-56-15: conv5_x.0.sequence.4.bias: torch.Size([512])
2023-12-02_17-56-15: conv5_x.0.shortcut.0.weight: torch.Size([512, 256, 1, 1])
2023-12-02_17-56-15: conv5_x.0.shortcut.1.weight: torch.Size([512])
2023-12-02_17-56-15: conv5_x.0.shortcut.1.bias: torch.Size([512])
2023-12-02_17-56-15: conv5_x.1.sequence.0.weight: torch.Size([512, 512, 3, 3])
2023-12-02_17-56-15: conv5_x.1.sequence.1.weight: torch.Size([512])
2023-12-02_17-56-15: conv5_x.1.sequence.1.bias: torch.Size([512])
2023-12-02_17-56-15: conv5_x.1.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_17-56-15: conv5_x.1.sequence.4.weight: torch.Size([512])
2023-12-02_17-56-15: conv5_x.1.sequence.4.bias: torch.Size([512])
2023-12-02_17-56-15: conv5_x.2.sequence.0.weight: torch.Size([512, 512, 3, 3])
2023-12-02_17-56-15: conv5_x.2.sequence.1.weight: torch.Size([512])
2023-12-02_17-56-15: conv5_x.2.sequence.1.bias: torch.Size([512])
2023-12-02_17-56-15: conv5_x.2.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_17-56-15: conv5_x.2.sequence.4.weight: torch.Size([512])
2023-12-02_17-56-15: conv5_x.2.sequence.4.bias: torch.Size([512])
2023-12-02_17-56-15: conv5_x.3.sequence.0.weight: torch.Size([512, 512, 3, 3])
2023-12-02_17-56-15: conv5_x.3.sequence.1.weight: torch.Size([512])
2023-12-02_17-56-15: conv5_x.3.sequence.1.bias: torch.Size([512])
2023-12-02_17-56-15: conv5_x.3.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_17-56-15: conv5_x.3.sequence.4.weight: torch.Size([512])
2023-12-02_17-56-15: conv5_x.3.sequence.4.bias: torch.Size([512])
2023-12-02_17-56-15: fc.weight: torch.Size([2, 512])
2023-12-02_17-56-15: fc.bias: torch.Size([2])
2023-12-02_17-56-15: 
Total parameters: 21,865,794;	Trainable: 21,865,794
2023-12-02_17-57-40: Epoch: 2 | Train loss: 0.42695015407091863 | Train acc: {'40X': 77.41, '100X': 78.99, '200X': 83.82, '400X': 80.35, 'avg_acc': 80.14, 'all_acc': 80.13} | Valid loss: 0.3160268059372902 | Valid acc: {'40X': 83.46, '100X': 87.05, '200X': 87.81, '400X': 85.99, 'avg_acc': 86.08, 'all_acc': 86.09}| Runtime: 1.4 mins
2023-12-02_17-59-06: Epoch: 3 | Train loss: 0.35802084559927116 | Train acc: {'40X': 82.18, '100X': 84.02, '200X': 84.56, '400X': 86.25, 'avg_acc': 84.25, 'all_acc': 84.21} | Valid loss: 0.34300206422805785 | Valid acc: {'40X': 84.21, '100X': 85.85, '200X': 88.06, '400X': 84.34, 'avg_acc': 85.62, 'all_acc': 85.65}| Runtime: 1.4 mins
2023-12-02_18-00-30: Epoch: 4 | Train loss: 0.3311074306634632 | Train acc: {'40X': 82.66, '100X': 85.21, '200X': 86.25, '400X': 86.62, 'avg_acc': 85.18, 'all_acc': 85.16} | Valid loss: 0.4072814506292343 | Valid acc: {'40X': 80.2, '100X': 82.49, '200X': 86.07, '400X': 85.44, 'avg_acc': 83.55, 'all_acc': 83.5}| Runtime: 1.4 mins
2023-12-02_18-01-54: Epoch: 5 | Train loss: 0.32176308600685083 | Train acc: {'40X': 83.58, '100X': 85.81, '200X': 88.05, '400X': 87.61, 'avg_acc': 86.26, 'all_acc': 86.23} | Valid loss: 0.29545137941837313 | Valid acc: {'40X': 84.96, '100X': 88.97, '200X': 88.81, '400X': 86.26, 'avg_acc': 87.25, 'all_acc': 87.29}| Runtime: 1.4 mins
2023-12-02_18-03-19: Epoch: 6 | Train loss: 0.3067900813813951 | Train acc: {'40X': 84.17, '100X': 84.68, '200X': 88.0, '400X': 87.58, 'avg_acc': 86.11, 'all_acc': 86.06} | Valid loss: 0.25419128984212874 | Valid acc: {'40X': 87.22, '100X': 90.17, '200X': 89.3, '400X': 89.56, 'avg_acc': 89.06, 'all_acc': 89.06}| Runtime: 1.4 mins
2023-12-02_18-04-43: Epoch: 7 | Train loss: 0.28237669396440723 | Train acc: {'40X': 85.34, '100X': 86.76, '200X': 89.98, '400X': 89.53, 'avg_acc': 87.9, 'all_acc': 87.86} | Valid loss: 0.2720658945292234 | Valid acc: {'40X': 84.71, '100X': 90.17, '200X': 91.29, '400X': 89.29, 'avg_acc': 88.86, 'all_acc': 88.87}| Runtime: 1.4 mins
2023-12-02_18-06-07: Epoch: 8 | Train loss: 0.27540161747586084 | Train acc: {'40X': 86.88, '100X': 86.83, '200X': 88.79, '400X': 89.27, 'avg_acc': 87.94, 'all_acc': 87.9} | Valid loss: 0.2812038031220436 | Valid acc: {'40X': 87.47, '100X': 88.25, '200X': 89.8, '400X': 86.54, 'avg_acc': 88.02, 'all_acc': 88.05}| Runtime: 1.4 mins
2023-12-02_18-07-32: Epoch: 9 | Train loss: 0.26208765950758717 | Train acc: {'40X': 86.59, '100X': 87.97, '200X': 91.71, '400X': 90.64, 'avg_acc': 89.23, 'all_acc': 89.19} | Valid loss: 0.22348043859004973 | Valid acc: {'40X': 87.97, '100X': 91.37, '200X': 93.03, '400X': 89.84, 'avg_acc': 90.55, 'all_acc': 90.58}| Runtime: 1.4 mins
2023-12-02_18-08-57: Epoch: 10 | Train loss: 0.25801649513478214 | Train acc: {'40X': 84.36, '100X': 88.02, '200X': 91.29, '400X': 91.02, 'avg_acc': 88.67, 'all_acc': 88.62} | Valid loss: 0.23722747474908829 | Valid acc: {'40X': 89.97, '100X': 90.41, '200X': 91.79, '400X': 90.66, 'avg_acc': 90.71, 'all_acc': 90.71}| Runtime: 1.4 mins
2023-12-02_18-10-21: Epoch: 11 | Train loss: 0.2503467259072774 | Train acc: {'40X': 86.54, '100X': 88.52, '200X': 91.69, '400X': 90.28, 'avg_acc': 89.26, 'all_acc': 89.23} | Valid loss: 0.39453697204589844 | Valid acc: {'40X': 82.21, '100X': 82.49, '200X': 86.82, '400X': 84.07, 'avg_acc': 83.9, 'all_acc': 83.88}| Runtime: 1.4 mins
2023-12-02_18-10-21: Train summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  77.41  78.99  83.82  80.35    80.14    80.13
1      2  82.18  84.02  84.56  86.25    84.25    84.21
2      3  82.66  85.21  86.25  86.62    85.18    85.16
3      4  83.58  85.81  88.05  87.61    86.26    86.23
4      5  84.17  84.68  88.00  87.58    86.11    86.06
5      6  85.34  86.76  89.98  89.53    87.90    87.86
6      7  86.88  86.83  88.79  89.27    87.94    87.90
7      8  86.59  87.97  91.71  90.64    89.23    89.19
8      9  84.36  88.02  91.29  91.02    88.67    88.62
9     10  86.54  88.52  91.69  90.28    89.26    89.23
2023-12-02_18-10-21: Eval summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  83.46  87.05  87.81  85.99    86.08    86.09
1      2  84.21  85.85  88.06  84.34    85.62    85.65
2      3  80.20  82.49  86.07  85.44    83.55    83.50
3      4  84.96  88.97  88.81  86.26    87.25    87.29
4      5  87.22  90.17  89.30  89.56    89.06    89.06
5      6  84.71  90.17  91.29  89.29    88.86    88.87
6      7  87.47  88.25  89.80  86.54    88.02    88.05
7      8  87.97  91.37  93.03  89.84    90.55    90.58
8      9  89.97  90.41  91.79  90.66    90.71    90.71
9     10  82.21  82.49  86.82  84.07    83.90    83.88
2023-12-02_18-10-21: Final test accuracy: {'40X': 90.23, '100X': 86.78, '200X': 92.8, '400X': 89.56, 'avg_acc': 89.84, 'all_acc': 89.82}
