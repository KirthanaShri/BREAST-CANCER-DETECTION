2023-12-04_00-42-52: config: {'n_epochs': 10, 'batch_size': 32, 'h': 224, 'w': 224, 'lr': 0.0001, 'optimizer': 'adam', 'momentum': 0.9, 'weight_decay': 0, 'device': 'cuda:1', 'n_gpus': 1, 'kernel_size': 3, 'model': 'CNN', 'use_pooling': False, 'num_kernel_conv_list': [32, 64, 64, 64]}
2023-12-04_00-42-52: conv1.weight: torch.Size([32, 3, 3, 3])
2023-12-04_00-42-52: conv1.bias: torch.Size([32])
2023-12-04_00-42-52: conv_layers.0.weight: torch.Size([64, 32, 3, 3])
2023-12-04_00-42-52: conv_layers.0.bias: torch.Size([64])
2023-12-04_00-42-52: conv_layers.2.weight: torch.Size([64, 64, 3, 3])
2023-12-04_00-42-52: conv_layers.2.bias: torch.Size([64])
2023-12-04_00-42-52: conv_layers.4.weight: torch.Size([64, 64, 3, 3])
2023-12-04_00-42-52: conv_layers.4.bias: torch.Size([64])
2023-12-04_00-42-52: linear.weight: torch.Size([2, 3211264])
2023-12-04_00-42-52: linear.bias: torch.Size([2])
2023-12-04_00-42-52: 
Total parameters: 6,515,778;	Trainable: 6,515,778
2023-12-04_00-43-52: Epoch: 1 | Train loss: 0.6188570980888766 | Train acc: {'40X': 79.35, '100X': 81.26, '200X': 83.91, '400X': 81.67, 'avg_acc': 81.55, 'all_acc': 81.55} | Valid loss: 0.40637630492448806 | Valid acc: {'40X': 78.95, '100X': 83.69, '200X': 85.57, '400X': 84.34, 'avg_acc': 83.14, 'all_acc': 83.12}| Runtime: 1.0 mins
2023-12-04_00-44-50: Epoch: 2 | Train loss: 0.24875887966639287 | Train acc: {'40X': 88.87, '100X': 90.29, '200X': 90.8, '400X': 88.61, 'avg_acc': 89.64, 'all_acc': 89.67} | Valid loss: 0.3417096136510372 | Valid acc: {'40X': 84.46, '100X': 85.85, '200X': 87.06, '400X': 84.34, 'avg_acc': 85.43, 'all_acc': 85.46}| Runtime: 1.0 mins
2023-12-04_00-45-49: Epoch: 3 | Train loss: 0.09912751114146935 | Train acc: {'40X': 95.99, '100X': 97.83, '200X': 98.01, '400X': 96.61, 'avg_acc': 97.11, 'all_acc': 97.13} | Valid loss: 0.33690746754407885 | Valid acc: {'40X': 86.47, '100X': 85.13, '200X': 86.82, '400X': 84.34, 'avg_acc': 85.69, 'all_acc': 85.71}| Runtime: 1.0 mins
2023-12-04_00-46-49: Epoch: 4 | Train loss: 0.0356450627048223 | Train acc: {'40X': 99.16, '100X': 99.76, '200X': 99.25, '400X': 98.9, 'avg_acc': 99.27, 'all_acc': 99.28} | Valid loss: 0.4975277099013329 | Valid acc: {'40X': 85.71, '100X': 84.17, '200X': 87.31, '400X': 82.14, 'avg_acc': 84.83, 'all_acc': 84.89}| Runtime: 1.0 mins
2023-12-04_00-47-48: Epoch: 5 | Train loss: 0.012934048082349141 | Train acc: {'40X': 99.75, '100X': 100.0, '200X': 99.75, '400X': 99.36, 'avg_acc': 99.72, 'all_acc': 99.73} | Valid loss: 0.5111984223127365 | Valid acc: {'40X': 86.22, '100X': 85.13, '200X': 87.06, '400X': 84.07, 'avg_acc': 85.62, 'all_acc': 85.65}| Runtime: 1.0 mins
2023-12-04_00-48-47: Epoch: 6 | Train loss: 0.003123259379109997 | Train acc: {'40X': 100.0, '100X': 100.0, '200X': 100.0, '400X': 100.0, 'avg_acc': 100.0, 'all_acc': 100.0} | Valid loss: 0.592017103023827 | Valid acc: {'40X': 86.22, '100X': 85.13, '200X': 86.57, '400X': 83.24, 'avg_acc': 85.29, 'all_acc': 85.34}| Runtime: 1.0 mins
2023-12-04_00-49-47: Epoch: 7 | Train loss: 0.0009705106365160916 | Train acc: {'40X': 100.0, '100X': 100.0, '200X': 100.0, '400X': 100.0, 'avg_acc': 100.0, 'all_acc': 100.0} | Valid loss: 0.6421932112425566 | Valid acc: {'40X': 85.46, '100X': 83.45, '200X': 86.32, '400X': 84.07, 'avg_acc': 84.82, 'all_acc': 84.83}| Runtime: 1.0 mins
2023-12-04_00-50-48: Epoch: 8 | Train loss: 0.0005610249741408011 | Train acc: {'40X': 100.0, '100X': 100.0, '200X': 100.0, '400X': 100.0, 'avg_acc': 100.0, 'all_acc': 100.0} | Valid loss: 0.6673773235082626 | Valid acc: {'40X': 85.46, '100X': 84.65, '200X': 86.82, '400X': 84.89, 'avg_acc': 85.46, 'all_acc': 85.46}| Runtime: 1.0 mins
2023-12-04_00-51-50: Epoch: 9 | Train loss: 0.0003761236687972308 | Train acc: {'40X': 100.0, '100X': 100.0, '200X': 100.0, '400X': 100.0, 'avg_acc': 100.0, 'all_acc': 100.0} | Valid loss: 0.7073187363147736 | Valid acc: {'40X': 85.71, '100X': 84.41, '200X': 86.57, '400X': 84.34, 'avg_acc': 85.26, 'all_acc': 85.27}| Runtime: 1.0 mins
2023-12-04_00-52-51: Epoch: 10 | Train loss: 0.00027236595876791006 | Train acc: {'40X': 100.0, '100X': 100.0, '200X': 100.0, '400X': 100.0, 'avg_acc': 100.0, 'all_acc': 100.0} | Valid loss: 0.6992837972939014 | Valid acc: {'40X': 86.47, '100X': 85.37, '200X': 86.57, '400X': 84.07, 'avg_acc': 85.62, 'all_acc': 85.65}| Runtime: 1.0 mins
2023-12-04_00-52-51: Train summary:    epoch     40X    100X    200X    400X  avg_acc  all_acc
0      1   79.35   81.26   83.91   81.67    81.55    81.55
1      2   88.87   90.29   90.80   88.61    89.64    89.67
2      3   95.99   97.83   98.01   96.61    97.11    97.13
3      4   99.16   99.76   99.25   98.90    99.27    99.28
4      5   99.75  100.00   99.75   99.36    99.72    99.73
5      6  100.00  100.00  100.00  100.00   100.00   100.00
6      7  100.00  100.00  100.00  100.00   100.00   100.00
7      8  100.00  100.00  100.00  100.00   100.00   100.00
8      9  100.00  100.00  100.00  100.00   100.00   100.00
9     10  100.00  100.00  100.00  100.00   100.00   100.00
2023-12-04_00-52-51: Eval summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  78.95  83.69  85.57  84.34    83.14    83.12
1      2  84.46  85.85  87.06  84.34    85.43    85.46
2      3  86.47  85.13  86.82  84.34    85.69    85.71
3      4  85.71  84.17  87.31  82.14    84.83    84.89
4      5  86.22  85.13  87.06  84.07    85.62    85.65
5      6  86.22  85.13  86.57  83.24    85.29    85.34
6      7  85.46  83.45  86.32  84.07    84.82    84.83
7      8  85.46  84.65  86.82  84.89    85.46    85.46
8      9  85.71  84.41  86.57  84.34    85.26    85.27
9     10  86.47  85.37  86.57  84.07    85.62    85.65
2023-12-04_00-52-51: Final test accuracy: {'40X': 87.72, '100X': 82.69, '200X': 92.56, '400X': 84.34, 'avg_acc': 86.83, 'all_acc': 86.85}
