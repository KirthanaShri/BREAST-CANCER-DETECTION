2023-12-02_20-30-17: config: {'n_epochs': 10, 'batch_size': 32, 'h': 224, 'w': 224, 'lr': 0.0001, 'optimizer': 'sgd', 'momentum': 0.9, 'device': 'cuda', 'n_gpus': 2, 'kernel_size': 3, 'flatten': False, 'model': 'resnet', 'num_blocks_list': [3, 2, 3, 4], 'is_batchnorm': True}
2023-12-02_20-30-18: conv1.0.weight: torch.Size([64, 3, 3, 3])
2023-12-02_20-30-18: conv1.1.weight: torch.Size([64])
2023-12-02_20-30-18: conv1.1.bias: torch.Size([64])
2023-12-02_20-30-18: conv2_x.0.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_20-30-18: conv2_x.0.sequence.1.weight: torch.Size([64])
2023-12-02_20-30-18: conv2_x.0.sequence.1.bias: torch.Size([64])
2023-12-02_20-30-18: conv2_x.0.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_20-30-18: conv2_x.0.sequence.4.weight: torch.Size([64])
2023-12-02_20-30-18: conv2_x.0.sequence.4.bias: torch.Size([64])
2023-12-02_20-30-18: conv2_x.1.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_20-30-18: conv2_x.1.sequence.1.weight: torch.Size([64])
2023-12-02_20-30-18: conv2_x.1.sequence.1.bias: torch.Size([64])
2023-12-02_20-30-18: conv2_x.1.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_20-30-18: conv2_x.1.sequence.4.weight: torch.Size([64])
2023-12-02_20-30-18: conv2_x.1.sequence.4.bias: torch.Size([64])
2023-12-02_20-30-18: conv2_x.2.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_20-30-18: conv2_x.2.sequence.1.weight: torch.Size([64])
2023-12-02_20-30-18: conv2_x.2.sequence.1.bias: torch.Size([64])
2023-12-02_20-30-18: conv2_x.2.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_20-30-18: conv2_x.2.sequence.4.weight: torch.Size([64])
2023-12-02_20-30-18: conv2_x.2.sequence.4.bias: torch.Size([64])
2023-12-02_20-30-18: conv3_x.0.sequence.0.weight: torch.Size([128, 64, 3, 3])
2023-12-02_20-30-18: conv3_x.0.sequence.1.weight: torch.Size([128])
2023-12-02_20-30-18: conv3_x.0.sequence.1.bias: torch.Size([128])
2023-12-02_20-30-18: conv3_x.0.sequence.3.weight: torch.Size([128, 128, 3, 3])
2023-12-02_20-30-18: conv3_x.0.sequence.4.weight: torch.Size([128])
2023-12-02_20-30-18: conv3_x.0.sequence.4.bias: torch.Size([128])
2023-12-02_20-30-18: conv3_x.0.shortcut.0.weight: torch.Size([128, 64, 1, 1])
2023-12-02_20-30-18: conv3_x.0.shortcut.1.weight: torch.Size([128])
2023-12-02_20-30-18: conv3_x.0.shortcut.1.bias: torch.Size([128])
2023-12-02_20-30-18: conv3_x.1.sequence.0.weight: torch.Size([128, 128, 3, 3])
2023-12-02_20-30-18: conv3_x.1.sequence.1.weight: torch.Size([128])
2023-12-02_20-30-18: conv3_x.1.sequence.1.bias: torch.Size([128])
2023-12-02_20-30-18: conv3_x.1.sequence.3.weight: torch.Size([128, 128, 3, 3])
2023-12-02_20-30-18: conv3_x.1.sequence.4.weight: torch.Size([128])
2023-12-02_20-30-18: conv3_x.1.sequence.4.bias: torch.Size([128])
2023-12-02_20-30-18: conv4_x.0.sequence.0.weight: torch.Size([256, 128, 3, 3])
2023-12-02_20-30-18: conv4_x.0.sequence.1.weight: torch.Size([256])
2023-12-02_20-30-18: conv4_x.0.sequence.1.bias: torch.Size([256])
2023-12-02_20-30-18: conv4_x.0.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_20-30-18: conv4_x.0.sequence.4.weight: torch.Size([256])
2023-12-02_20-30-18: conv4_x.0.sequence.4.bias: torch.Size([256])
2023-12-02_20-30-18: conv4_x.0.shortcut.0.weight: torch.Size([256, 128, 1, 1])
2023-12-02_20-30-18: conv4_x.0.shortcut.1.weight: torch.Size([256])
2023-12-02_20-30-18: conv4_x.0.shortcut.1.bias: torch.Size([256])
2023-12-02_20-30-18: conv4_x.1.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_20-30-18: conv4_x.1.sequence.1.weight: torch.Size([256])
2023-12-02_20-30-18: conv4_x.1.sequence.1.bias: torch.Size([256])
2023-12-02_20-30-18: conv4_x.1.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_20-30-18: conv4_x.1.sequence.4.weight: torch.Size([256])
2023-12-02_20-30-18: conv4_x.1.sequence.4.bias: torch.Size([256])
2023-12-02_20-30-18: conv4_x.2.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_20-30-18: conv4_x.2.sequence.1.weight: torch.Size([256])
2023-12-02_20-30-18: conv4_x.2.sequence.1.bias: torch.Size([256])
2023-12-02_20-30-18: conv4_x.2.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_20-30-18: conv4_x.2.sequence.4.weight: torch.Size([256])
2023-12-02_20-30-18: conv4_x.2.sequence.4.bias: torch.Size([256])
2023-12-02_20-30-18: conv5_x.0.sequence.0.weight: torch.Size([512, 256, 3, 3])
2023-12-02_20-30-18: conv5_x.0.sequence.1.weight: torch.Size([512])
2023-12-02_20-30-18: conv5_x.0.sequence.1.bias: torch.Size([512])
2023-12-02_20-30-18: conv5_x.0.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_20-30-18: conv5_x.0.sequence.4.weight: torch.Size([512])
2023-12-02_20-30-18: conv5_x.0.sequence.4.bias: torch.Size([512])
2023-12-02_20-30-18: conv5_x.0.shortcut.0.weight: torch.Size([512, 256, 1, 1])
2023-12-02_20-30-18: conv5_x.0.shortcut.1.weight: torch.Size([512])
2023-12-02_20-30-18: conv5_x.0.shortcut.1.bias: torch.Size([512])
2023-12-02_20-30-18: conv5_x.1.sequence.0.weight: torch.Size([512, 512, 3, 3])
2023-12-02_20-30-18: conv5_x.1.sequence.1.weight: torch.Size([512])
2023-12-02_20-30-18: conv5_x.1.sequence.1.bias: torch.Size([512])
2023-12-02_20-30-18: conv5_x.1.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_20-30-18: conv5_x.1.sequence.4.weight: torch.Size([512])
2023-12-02_20-30-18: conv5_x.1.sequence.4.bias: torch.Size([512])
2023-12-02_20-30-18: conv5_x.2.sequence.0.weight: torch.Size([512, 512, 3, 3])
2023-12-02_20-30-18: conv5_x.2.sequence.1.weight: torch.Size([512])
2023-12-02_20-30-18: conv5_x.2.sequence.1.bias: torch.Size([512])
2023-12-02_20-30-18: conv5_x.2.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_20-30-18: conv5_x.2.sequence.4.weight: torch.Size([512])
2023-12-02_20-30-18: conv5_x.2.sequence.4.bias: torch.Size([512])
2023-12-02_20-30-18: conv5_x.3.sequence.0.weight: torch.Size([512, 512, 3, 3])
2023-12-02_20-30-18: conv5_x.3.sequence.1.weight: torch.Size([512])
2023-12-02_20-30-18: conv5_x.3.sequence.1.bias: torch.Size([512])
2023-12-02_20-30-18: conv5_x.3.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_20-30-18: conv5_x.3.sequence.4.weight: torch.Size([512])
2023-12-02_20-30-18: conv5_x.3.sequence.4.bias: torch.Size([512])
2023-12-02_20-30-18: fc.weight: torch.Size([2, 512])
2023-12-02_20-30-18: fc.bias: torch.Size([2])
2023-12-02_20-30-18: 
Total parameters: 21,865,794;	Trainable: 21,865,794
