2023-12-04_02-37-53: config: {'n_epochs': 10, 'batch_size': 32, 'h': 224, 'w': 224, 'lr': 1e-05, 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0, 'device': 'cuda:1', 'n_gpus': 1, 'kernel_size': 3, 'model': 'CNN', 'use_pooling': False, 'num_kernel_conv_list': [32, 64, 64, 64]}
2023-12-04_02-37-53: conv1.weight: torch.Size([32, 3, 3, 3])
2023-12-04_02-37-53: conv1.bias: torch.Size([32])
2023-12-04_02-37-53: conv_layers.0.weight: torch.Size([64, 32, 3, 3])
2023-12-04_02-37-53: conv_layers.0.bias: torch.Size([64])
2023-12-04_02-37-53: conv_layers.2.weight: torch.Size([64, 64, 3, 3])
2023-12-04_02-37-53: conv_layers.2.bias: torch.Size([64])
2023-12-04_02-37-53: conv_layers.4.weight: torch.Size([64, 64, 3, 3])
2023-12-04_02-37-53: conv_layers.4.bias: torch.Size([64])
2023-12-04_02-37-53: linear.weight: torch.Size([2, 3211264])
2023-12-04_02-37-53: linear.bias: torch.Size([2])
2023-12-04_02-37-53: 
Total parameters: 6,515,778;	Trainable: 6,515,778
2023-12-04_02-39-02: Epoch: 1 | Train loss: 0.5843403188360704 | Train acc: {'40X': 69.37, '100X': 69.56, '200X': 68.69, '400X': 69.23, 'avg_acc': 69.21, 'all_acc': 69.21} | Valid loss: 0.5388166904449463 | Valid acc: {'40X': 75.44, '100X': 74.1, '200X': 79.85, '400X': 73.35, 'avg_acc': 75.68, 'all_acc': 75.73}| Runtime: 1.2 mins
2023-12-04_02-40-10: Epoch: 2 | Train loss: 0.5086314368086893 | Train acc: {'40X': 77.87, '100X': 80.05, '200X': 83.58, '400X': 82.83, 'avg_acc': 81.08, 'all_acc': 81.04} | Valid loss: 0.484226256608963 | Valid acc: {'40X': 80.7, '100X': 80.82, '200X': 85.32, '400X': 84.07, 'avg_acc': 82.73, 'all_acc': 82.68}| Runtime: 1.1 mins
2023-12-04_02-41-17: Epoch: 3 | Train loss: 0.46798058820737376 | Train acc: {'40X': 80.79, '100X': 81.62, '200X': 86.0, '400X': 84.88, 'avg_acc': 83.32, 'all_acc': 83.28} | Valid loss: 0.45884954869747163 | Valid acc: {'40X': 82.21, '100X': 81.77, '200X': 85.32, '400X': 84.89, 'avg_acc': 83.55, 'all_acc': 83.5}| Runtime: 1.1 mins
2023-12-04_02-42-24: Epoch: 4 | Train loss: 0.44205703244015976 | Train acc: {'40X': 81.54, '100X': 82.8, '200X': 86.16, '400X': 85.2, 'avg_acc': 83.92, 'all_acc': 83.89} | Valid loss: 0.4477724540233612 | Valid acc: {'40X': 82.21, '100X': 82.01, '200X': 85.32, '400X': 84.34, 'avg_acc': 83.47, 'all_acc': 83.44}| Runtime: 1.1 mins
2023-12-04_02-43-33: Epoch: 5 | Train loss: 0.4238414496586129 | Train acc: {'40X': 81.32, '100X': 82.89, '200X': 86.5, '400X': 85.69, 'avg_acc': 84.1, 'all_acc': 84.06} | Valid loss: 0.42003213047981264 | Valid acc: {'40X': 84.46, '100X': 82.73, '200X': 84.33, '400X': 84.34, 'avg_acc': 83.96, 'all_acc': 83.94}| Runtime: 1.1 mins
2023-12-04_02-44-42: Epoch: 6 | Train loss: 0.4056684038526303 | Train acc: {'40X': 83.17, '100X': 83.07, '200X': 86.22, '400X': 86.53, 'avg_acc': 84.75, 'all_acc': 84.69} | Valid loss: 0.418760606944561 | Valid acc: {'40X': 82.46, '100X': 82.01, '200X': 85.57, '400X': 83.79, 'avg_acc': 83.46, 'all_acc': 83.44}| Runtime: 1.1 mins
2023-12-04_02-45-48: Epoch: 7 | Train loss: 0.3927740753703826 | Train acc: {'40X': 82.83, '100X': 82.77, '200X': 86.46, '400X': 86.51, 'avg_acc': 84.64, 'all_acc': 84.59} | Valid loss: 0.4014883750677109 | Valid acc: {'40X': 84.21, '100X': 82.49, '200X': 85.32, '400X': 82.97, 'avg_acc': 83.75, 'all_acc': 83.75}| Runtime: 1.1 mins
2023-12-04_02-46-56: Epoch: 8 | Train loss: 0.37956397104504946 | Train acc: {'40X': 83.03, '100X': 83.69, '200X': 86.56, '400X': 87.34, 'avg_acc': 85.16, 'all_acc': 85.09} | Valid loss: 0.3834052750468254 | Valid acc: {'40X': 84.71, '100X': 83.69, '200X': 84.58, '400X': 83.24, 'avg_acc': 84.06, 'all_acc': 84.07}| Runtime: 1.1 mins
2023-12-04_02-48-05: Epoch: 9 | Train loss: 0.37014303225520495 | Train acc: {'40X': 83.11, '100X': 83.4, '200X': 86.45, '400X': 87.43, 'avg_acc': 85.1, 'all_acc': 85.03} | Valid loss: 0.3779024523496628 | Valid acc: {'40X': 84.21, '100X': 82.73, '200X': 85.07, '400X': 82.69, 'avg_acc': 83.68, 'all_acc': 83.69}| Runtime: 1.2 mins
2023-12-04_02-49-13: Epoch: 10 | Train loss: 0.35990153414172094 | Train acc: {'40X': 82.96, '100X': 83.48, '200X': 86.74, '400X': 87.17, 'avg_acc': 85.09, 'all_acc': 85.03} | Valid loss: 0.3736876964569092 | Valid acc: {'40X': 84.46, '100X': 84.17, '200X': 84.83, '400X': 84.62, 'avg_acc': 84.52, 'all_acc': 84.51}| Runtime: 1.1 mins
2023-12-04_02-49-13: Train summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  69.37  69.56  68.69  69.23    69.21    69.21
1      2  77.87  80.05  83.58  82.83    81.08    81.04
2      3  80.79  81.62  86.00  84.88    83.32    83.28
3      4  81.54  82.80  86.16  85.20    83.92    83.89
4      5  81.32  82.89  86.50  85.69    84.10    84.06
5      6  83.17  83.07  86.22  86.53    84.75    84.69
6      7  82.83  82.77  86.46  86.51    84.64    84.59
7      8  83.03  83.69  86.56  87.34    85.16    85.09
8      9  83.11  83.40  86.45  87.43    85.10    85.03
9     10  82.96  83.48  86.74  87.17    85.09    85.03
2023-12-04_02-49-13: Eval summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  75.44  74.10  79.85  73.35    75.68    75.73
1      2  80.70  80.82  85.32  84.07    82.73    82.68
2      3  82.21  81.77  85.32  84.89    83.55    83.50
3      4  82.21  82.01  85.32  84.34    83.47    83.44
4      5  84.46  82.73  84.33  84.34    83.96    83.94
5      6  82.46  82.01  85.57  83.79    83.46    83.44
6      7  84.21  82.49  85.32  82.97    83.75    83.75
7      8  84.71  83.69  84.58  83.24    84.06    84.07
8      9  84.21  82.73  85.07  82.69    83.68    83.69
9     10  84.46  84.17  84.83  84.62    84.52    84.51
2023-12-04_02-49-13: Final test accuracy: {'40X': 82.71, '100X': 80.53, '200X': 88.59, '400X': 85.71, 'avg_acc': 84.38, 'all_acc': 84.32}
