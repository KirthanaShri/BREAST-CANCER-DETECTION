2023-12-02_19-06-08: config: {'n_epochs': 10, 'batch_size': 32, 'h': 224, 'w': 224, 'lr': 0.001, 'optimizer': 'sgd', 'momentum': 0.9, 'device': 'cuda', 'n_gpus': 2, 'kernel_size': 3, 'flatten': False, 'model': 'resnet', 'num_blocks_list': [3, 2, 3, 4], 'is_batchnorm': True}
2023-12-02_19-06-08: conv1.0.weight: torch.Size([64, 3, 3, 3])
2023-12-02_19-06-08: conv1.1.weight: torch.Size([64])
2023-12-02_19-06-08: conv1.1.bias: torch.Size([64])
2023-12-02_19-06-08: conv2_x.0.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_19-06-08: conv2_x.0.sequence.1.weight: torch.Size([64])
2023-12-02_19-06-08: conv2_x.0.sequence.1.bias: torch.Size([64])
2023-12-02_19-06-08: conv2_x.0.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_19-06-08: conv2_x.0.sequence.4.weight: torch.Size([64])
2023-12-02_19-06-08: conv2_x.0.sequence.4.bias: torch.Size([64])
2023-12-02_19-06-08: conv2_x.1.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_19-06-08: conv2_x.1.sequence.1.weight: torch.Size([64])
2023-12-02_19-06-08: conv2_x.1.sequence.1.bias: torch.Size([64])
2023-12-02_19-06-08: conv2_x.1.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_19-06-08: conv2_x.1.sequence.4.weight: torch.Size([64])
2023-12-02_19-06-08: conv2_x.1.sequence.4.bias: torch.Size([64])
2023-12-02_19-06-08: conv2_x.2.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_19-06-08: conv2_x.2.sequence.1.weight: torch.Size([64])
2023-12-02_19-06-08: conv2_x.2.sequence.1.bias: torch.Size([64])
2023-12-02_19-06-08: conv2_x.2.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_19-06-08: conv2_x.2.sequence.4.weight: torch.Size([64])
2023-12-02_19-06-08: conv2_x.2.sequence.4.bias: torch.Size([64])
2023-12-02_19-06-08: conv3_x.0.sequence.0.weight: torch.Size([128, 64, 3, 3])
2023-12-02_19-06-08: conv3_x.0.sequence.1.weight: torch.Size([128])
2023-12-02_19-06-08: conv3_x.0.sequence.1.bias: torch.Size([128])
2023-12-02_19-06-08: conv3_x.0.sequence.3.weight: torch.Size([128, 128, 3, 3])
2023-12-02_19-06-08: conv3_x.0.sequence.4.weight: torch.Size([128])
2023-12-02_19-06-08: conv3_x.0.sequence.4.bias: torch.Size([128])
2023-12-02_19-06-08: conv3_x.0.shortcut.0.weight: torch.Size([128, 64, 1, 1])
2023-12-02_19-06-08: conv3_x.0.shortcut.1.weight: torch.Size([128])
2023-12-02_19-06-08: conv3_x.0.shortcut.1.bias: torch.Size([128])
2023-12-02_19-06-08: conv3_x.1.sequence.0.weight: torch.Size([128, 128, 3, 3])
2023-12-02_19-06-08: conv3_x.1.sequence.1.weight: torch.Size([128])
2023-12-02_19-06-08: conv3_x.1.sequence.1.bias: torch.Size([128])
2023-12-02_19-06-08: conv3_x.1.sequence.3.weight: torch.Size([128, 128, 3, 3])
2023-12-02_19-06-08: conv3_x.1.sequence.4.weight: torch.Size([128])
2023-12-02_19-06-08: conv3_x.1.sequence.4.bias: torch.Size([128])
2023-12-02_19-06-08: conv4_x.0.sequence.0.weight: torch.Size([256, 128, 3, 3])
2023-12-02_19-06-08: conv4_x.0.sequence.1.weight: torch.Size([256])
2023-12-02_19-06-08: conv4_x.0.sequence.1.bias: torch.Size([256])
2023-12-02_19-06-08: conv4_x.0.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_19-06-08: conv4_x.0.sequence.4.weight: torch.Size([256])
2023-12-02_19-06-08: conv4_x.0.sequence.4.bias: torch.Size([256])
2023-12-02_19-06-08: conv4_x.0.shortcut.0.weight: torch.Size([256, 128, 1, 1])
2023-12-02_19-06-08: conv4_x.0.shortcut.1.weight: torch.Size([256])
2023-12-02_19-06-08: conv4_x.0.shortcut.1.bias: torch.Size([256])
2023-12-02_19-06-08: conv4_x.1.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_19-06-08: conv4_x.1.sequence.1.weight: torch.Size([256])
2023-12-02_19-06-08: conv4_x.1.sequence.1.bias: torch.Size([256])
2023-12-02_19-06-08: conv4_x.1.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_19-06-08: conv4_x.1.sequence.4.weight: torch.Size([256])
2023-12-02_19-06-08: conv4_x.1.sequence.4.bias: torch.Size([256])
2023-12-02_19-06-08: conv4_x.2.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_19-06-08: conv4_x.2.sequence.1.weight: torch.Size([256])
2023-12-02_19-06-08: conv4_x.2.sequence.1.bias: torch.Size([256])
2023-12-02_19-06-08: conv4_x.2.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_19-06-08: conv4_x.2.sequence.4.weight: torch.Size([256])
2023-12-02_19-06-08: conv4_x.2.sequence.4.bias: torch.Size([256])
2023-12-02_19-06-08: conv5_x.0.sequence.0.weight: torch.Size([512, 256, 3, 3])
2023-12-02_19-06-08: conv5_x.0.sequence.1.weight: torch.Size([512])
2023-12-02_19-06-08: conv5_x.0.sequence.1.bias: torch.Size([512])
2023-12-02_19-06-08: conv5_x.0.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_19-06-08: conv5_x.0.sequence.4.weight: torch.Size([512])
2023-12-02_19-06-08: conv5_x.0.sequence.4.bias: torch.Size([512])
2023-12-02_19-06-08: conv5_x.0.shortcut.0.weight: torch.Size([512, 256, 1, 1])
2023-12-02_19-06-08: conv5_x.0.shortcut.1.weight: torch.Size([512])
2023-12-02_19-06-08: conv5_x.0.shortcut.1.bias: torch.Size([512])
2023-12-02_19-06-08: conv5_x.1.sequence.0.weight: torch.Size([512, 512, 3, 3])
2023-12-02_19-06-08: conv5_x.1.sequence.1.weight: torch.Size([512])
2023-12-02_19-06-08: conv5_x.1.sequence.1.bias: torch.Size([512])
2023-12-02_19-06-08: conv5_x.1.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_19-06-08: conv5_x.1.sequence.4.weight: torch.Size([512])
2023-12-02_19-06-08: conv5_x.1.sequence.4.bias: torch.Size([512])
2023-12-02_19-06-08: conv5_x.2.sequence.0.weight: torch.Size([512, 512, 3, 3])
2023-12-02_19-06-08: conv5_x.2.sequence.1.weight: torch.Size([512])
2023-12-02_19-06-08: conv5_x.2.sequence.1.bias: torch.Size([512])
2023-12-02_19-06-08: conv5_x.2.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_19-06-08: conv5_x.2.sequence.4.weight: torch.Size([512])
2023-12-02_19-06-08: conv5_x.2.sequence.4.bias: torch.Size([512])
2023-12-02_19-06-08: conv5_x.3.sequence.0.weight: torch.Size([512, 512, 3, 3])
2023-12-02_19-06-08: conv5_x.3.sequence.1.weight: torch.Size([512])
2023-12-02_19-06-08: conv5_x.3.sequence.1.bias: torch.Size([512])
2023-12-02_19-06-08: conv5_x.3.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_19-06-08: conv5_x.3.sequence.4.weight: torch.Size([512])
2023-12-02_19-06-08: conv5_x.3.sequence.4.bias: torch.Size([512])
2023-12-02_19-06-08: fc.weight: torch.Size([2, 512])
2023-12-02_19-06-08: fc.bias: torch.Size([2])
2023-12-02_19-06-08: 
Total parameters: 21,865,794;	Trainable: 21,865,794
2023-12-02_19-07-33: Epoch: 2 | Train loss: 0.44125979459164916 | Train acc: {'40X': 78.01, '100X': 78.63, '200X': 82.93, '400X': 81.16, 'avg_acc': 80.18, 'all_acc': 80.15} | Valid loss: 0.47241874754428864 | Valid acc: {'40X': 75.69, '100X': 84.17, '200X': 84.83, '400X': 81.87, 'avg_acc': 81.64, 'all_acc': 81.67}| Runtime: 1.4 mins
2023-12-02_19-08-57: Epoch: 3 | Train loss: 0.3677851160031718 | Train acc: {'40X': 83.19, '100X': 83.28, '200X': 86.33, '400X': 85.12, 'avg_acc': 84.48, 'all_acc': 84.46} | Valid loss: 0.3163500152528286 | Valid acc: {'40X': 84.71, '100X': 85.61, '200X': 88.06, '400X': 85.16, 'avg_acc': 85.88, 'all_acc': 85.9}| Runtime: 1.4 mins
2023-12-02_19-10-21: Epoch: 4 | Train loss: 0.35104337722264434 | Train acc: {'40X': 81.34, '100X': 84.1, '200X': 87.55, '400X': 85.33, 'avg_acc': 84.58, 'all_acc': 84.57} | Valid loss: 0.39801955670118333 | Valid acc: {'40X': 83.21, '100X': 84.89, '200X': 85.32, '400X': 84.89, 'avg_acc': 84.58, 'all_acc': 84.58}| Runtime: 1.4 mins
2023-12-02_19-11-45: Epoch: 5 | Train loss: 0.34444387287304207 | Train acc: {'40X': 84.16, '100X': 84.44, '200X': 87.89, '400X': 85.96, 'avg_acc': 85.61, 'all_acc': 85.6} | Valid loss: 0.28878704488277435 | Valid acc: {'40X': 85.96, '100X': 88.49, '200X': 91.04, '400X': 88.19, 'avg_acc': 88.42, 'all_acc': 88.43}| Runtime: 1.4 mins
2023-12-02_19-13-09: Epoch: 6 | Train loss: 0.3001480037598191 | Train acc: {'40X': 84.91, '100X': 86.62, '200X': 88.54, '400X': 87.81, 'avg_acc': 86.97, 'all_acc': 86.95} | Valid loss: 0.3561045050621033 | Valid acc: {'40X': 86.22, '100X': 88.01, '200X': 87.31, '400X': 85.99, 'avg_acc': 86.88, 'all_acc': 86.92}| Runtime: 1.4 mins
2023-12-02_19-14-39: Epoch: 7 | Train loss: 0.2967943302984979 | Train acc: {'40X': 85.52, '100X': 86.83, '200X': 89.23, '400X': 87.88, 'avg_acc': 87.36, 'all_acc': 87.35} | Valid loss: 0.29804818257689475 | Valid acc: {'40X': 87.97, '100X': 89.21, '200X': 89.3, '400X': 87.36, 'avg_acc': 88.46, 'all_acc': 88.5}| Runtime: 1.5 mins
2023-12-02_19-16-03: Epoch: 8 | Train loss: 0.2923420804577905 | Train acc: {'40X': 85.69, '100X': 87.0, '200X': 88.38, '400X': 88.9, 'avg_acc': 87.49, 'all_acc': 87.46} | Valid loss: 0.42200090557336806 | Valid acc: {'40X': 85.71, '100X': 88.97, '200X': 87.31, '400X': 84.62, 'avg_acc': 86.65, 'all_acc': 86.73}| Runtime: 1.4 mins
2023-12-02_19-17-28: Epoch: 9 | Train loss: 0.2792051319737692 | Train acc: {'40X': 86.04, '100X': 88.11, '200X': 89.87, '400X': 87.72, 'avg_acc': 87.94, 'all_acc': 87.94} | Valid loss: 0.22559599682688714 | Valid acc: {'40X': 89.22, '100X': 93.53, '200X': 92.79, '400X': 88.46, 'avg_acc': 91.0, 'all_acc': 91.09}| Runtime: 1.4 mins
2023-12-02_19-18-52: Epoch: 10 | Train loss: 0.2702676313551697 | Train acc: {'40X': 87.43, '100X': 88.29, '200X': 90.89, '400X': 87.97, 'avg_acc': 88.65, 'all_acc': 88.66} | Valid loss: 0.24880243346095085 | Valid acc: {'40X': 85.46, '100X': 90.41, '200X': 90.3, '400X': 91.21, 'avg_acc': 89.34, 'all_acc': 89.32}| Runtime: 1.4 mins
2023-12-02_19-20-17: Epoch: 11 | Train loss: 0.2530153946497956 | Train acc: {'40X': 86.78, '100X': 89.98, '200X': 88.72, '400X': 90.07, 'avg_acc': 88.89, 'all_acc': 88.87} | Valid loss: 0.22257807217538356 | Valid acc: {'40X': 90.98, '100X': 92.09, '200X': 93.03, '400X': 89.01, 'avg_acc': 91.28, 'all_acc': 91.34}| Runtime: 1.4 mins
2023-12-02_19-20-17: Train summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  78.01  78.63  82.93  81.16    80.18    80.15
1      2  83.19  83.28  86.33  85.12    84.48    84.46
2      3  81.34  84.10  87.55  85.33    84.58    84.57
3      4  84.16  84.44  87.89  85.96    85.61    85.60
4      5  84.91  86.62  88.54  87.81    86.97    86.95
5      6  85.52  86.83  89.23  87.88    87.36    87.35
6      7  85.69  87.00  88.38  88.90    87.49    87.46
7      8  86.04  88.11  89.87  87.72    87.94    87.94
8      9  87.43  88.29  90.89  87.97    88.65    88.66
9     10  86.78  89.98  88.72  90.07    88.89    88.87
2023-12-02_19-20-17: Eval summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  75.69  84.17  84.83  81.87    81.64    81.67
1      2  84.71  85.61  88.06  85.16    85.88    85.90
2      3  83.21  84.89  85.32  84.89    84.58    84.58
3      4  85.96  88.49  91.04  88.19    88.42    88.43
4      5  86.22  88.01  87.31  85.99    86.88    86.92
5      6  87.97  89.21  89.30  87.36    88.46    88.50
6      7  85.71  88.97  87.31  84.62    86.65    86.73
7      8  89.22  93.53  92.79  88.46    91.00    91.09
8      9  85.46  90.41  90.30  91.21    89.34    89.32
9     10  90.98  92.09  93.03  89.01    91.28    91.34
2023-12-02_19-20-17: Final test accuracy: {'40X': 90.48, '100X': 90.87, '200X': 93.55, '400X': 89.01, 'avg_acc': 90.98, 'all_acc': 91.02}
