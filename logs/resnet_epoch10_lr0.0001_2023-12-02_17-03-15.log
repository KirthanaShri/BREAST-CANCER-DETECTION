2023-12-02_17-03-15: config: {'n_epochs': 10, 'batch_size': 32, 'h': 224, 'w': 224, 'lr': 0.0001, 'optimizer': 'adam', 'momentum': 0.9, 'device': 'cuda', 'n_gpus': 2, 'kernel_size': 3, 'flatten': False, 'model': 'resnet', 'num_blocks_list': [3, 4, 6, 3], 'is_batchnorm': False}
2023-12-02_17-03-15: conv1.0.weight: torch.Size([64, 3, 3, 3])
2023-12-02_17-03-15: conv1.1.weight: torch.Size([64])
2023-12-02_17-03-15: conv1.1.bias: torch.Size([64])
2023-12-02_17-03-15: conv2_x.0.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_17-03-15: conv2_x.0.sequence.1.weight: torch.Size([64])
2023-12-02_17-03-15: conv2_x.0.sequence.1.bias: torch.Size([64])
2023-12-02_17-03-15: conv2_x.0.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_17-03-15: conv2_x.0.sequence.4.weight: torch.Size([64])
2023-12-02_17-03-15: conv2_x.0.sequence.4.bias: torch.Size([64])
2023-12-02_17-03-15: conv2_x.1.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_17-03-15: conv2_x.1.sequence.1.weight: torch.Size([64])
2023-12-02_17-03-15: conv2_x.1.sequence.1.bias: torch.Size([64])
2023-12-02_17-03-15: conv2_x.1.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_17-03-15: conv2_x.1.sequence.4.weight: torch.Size([64])
2023-12-02_17-03-15: conv2_x.1.sequence.4.bias: torch.Size([64])
2023-12-02_17-03-15: conv2_x.2.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_17-03-15: conv2_x.2.sequence.1.weight: torch.Size([64])
2023-12-02_17-03-15: conv2_x.2.sequence.1.bias: torch.Size([64])
2023-12-02_17-03-15: conv2_x.2.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_17-03-15: conv2_x.2.sequence.4.weight: torch.Size([64])
2023-12-02_17-03-15: conv2_x.2.sequence.4.bias: torch.Size([64])
2023-12-02_17-03-15: conv3_x.0.sequence.0.weight: torch.Size([128, 64, 3, 3])
2023-12-02_17-03-15: conv3_x.0.sequence.1.weight: torch.Size([128])
2023-12-02_17-03-15: conv3_x.0.sequence.1.bias: torch.Size([128])
2023-12-02_17-03-15: conv3_x.0.sequence.3.weight: torch.Size([128, 128, 3, 3])
2023-12-02_17-03-15: conv3_x.0.sequence.4.weight: torch.Size([128])
2023-12-02_17-03-15: conv3_x.0.sequence.4.bias: torch.Size([128])
2023-12-02_17-03-15: conv3_x.0.shortcut.0.weight: torch.Size([128, 64, 1, 1])
2023-12-02_17-03-15: conv3_x.0.shortcut.1.weight: torch.Size([128])
2023-12-02_17-03-15: conv3_x.0.shortcut.1.bias: torch.Size([128])
2023-12-02_17-03-15: conv3_x.1.sequence.0.weight: torch.Size([128, 128, 3, 3])
2023-12-02_17-03-15: conv3_x.1.sequence.1.weight: torch.Size([128])
2023-12-02_17-03-15: conv3_x.1.sequence.1.bias: torch.Size([128])
2023-12-02_17-03-15: conv3_x.1.sequence.3.weight: torch.Size([128, 128, 3, 3])
2023-12-02_17-03-15: conv3_x.1.sequence.4.weight: torch.Size([128])
2023-12-02_17-03-15: conv3_x.1.sequence.4.bias: torch.Size([128])
2023-12-02_17-03-15: conv3_x.2.sequence.0.weight: torch.Size([128, 128, 3, 3])
2023-12-02_17-03-15: conv3_x.2.sequence.1.weight: torch.Size([128])
2023-12-02_17-03-15: conv3_x.2.sequence.1.bias: torch.Size([128])
2023-12-02_17-03-15: conv3_x.2.sequence.3.weight: torch.Size([128, 128, 3, 3])
2023-12-02_17-03-15: conv3_x.2.sequence.4.weight: torch.Size([128])
2023-12-02_17-03-15: conv3_x.2.sequence.4.bias: torch.Size([128])
2023-12-02_17-03-15: conv3_x.3.sequence.0.weight: torch.Size([128, 128, 3, 3])
2023-12-02_17-03-15: conv3_x.3.sequence.1.weight: torch.Size([128])
2023-12-02_17-03-15: conv3_x.3.sequence.1.bias: torch.Size([128])
2023-12-02_17-03-15: conv3_x.3.sequence.3.weight: torch.Size([128, 128, 3, 3])
2023-12-02_17-03-15: conv3_x.3.sequence.4.weight: torch.Size([128])
2023-12-02_17-03-15: conv3_x.3.sequence.4.bias: torch.Size([128])
2023-12-02_17-03-15: conv4_x.0.sequence.0.weight: torch.Size([256, 128, 3, 3])
2023-12-02_17-03-15: conv4_x.0.sequence.1.weight: torch.Size([256])
2023-12-02_17-03-15: conv4_x.0.sequence.1.bias: torch.Size([256])
2023-12-02_17-03-15: conv4_x.0.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_17-03-15: conv4_x.0.sequence.4.weight: torch.Size([256])
2023-12-02_17-03-15: conv4_x.0.sequence.4.bias: torch.Size([256])
2023-12-02_17-03-15: conv4_x.0.shortcut.0.weight: torch.Size([256, 128, 1, 1])
2023-12-02_17-03-15: conv4_x.0.shortcut.1.weight: torch.Size([256])
2023-12-02_17-03-15: conv4_x.0.shortcut.1.bias: torch.Size([256])
2023-12-02_17-03-15: conv4_x.1.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_17-03-15: conv4_x.1.sequence.1.weight: torch.Size([256])
2023-12-02_17-03-15: conv4_x.1.sequence.1.bias: torch.Size([256])
2023-12-02_17-03-15: conv4_x.1.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_17-03-15: conv4_x.1.sequence.4.weight: torch.Size([256])
2023-12-02_17-03-15: conv4_x.1.sequence.4.bias: torch.Size([256])
2023-12-02_17-03-15: conv4_x.2.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_17-03-15: conv4_x.2.sequence.1.weight: torch.Size([256])
2023-12-02_17-03-15: conv4_x.2.sequence.1.bias: torch.Size([256])
2023-12-02_17-03-15: conv4_x.2.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_17-03-15: conv4_x.2.sequence.4.weight: torch.Size([256])
2023-12-02_17-03-15: conv4_x.2.sequence.4.bias: torch.Size([256])
2023-12-02_17-03-15: conv4_x.3.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_17-03-15: conv4_x.3.sequence.1.weight: torch.Size([256])
2023-12-02_17-03-15: conv4_x.3.sequence.1.bias: torch.Size([256])
2023-12-02_17-03-15: conv4_x.3.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_17-03-15: conv4_x.3.sequence.4.weight: torch.Size([256])
2023-12-02_17-03-15: conv4_x.3.sequence.4.bias: torch.Size([256])
2023-12-02_17-03-15: conv4_x.4.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_17-03-15: conv4_x.4.sequence.1.weight: torch.Size([256])
2023-12-02_17-03-15: conv4_x.4.sequence.1.bias: torch.Size([256])
2023-12-02_17-03-15: conv4_x.4.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_17-03-15: conv4_x.4.sequence.4.weight: torch.Size([256])
2023-12-02_17-03-15: conv4_x.4.sequence.4.bias: torch.Size([256])
2023-12-02_17-03-15: conv4_x.5.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_17-03-15: conv4_x.5.sequence.1.weight: torch.Size([256])
2023-12-02_17-03-15: conv4_x.5.sequence.1.bias: torch.Size([256])
2023-12-02_17-03-15: conv4_x.5.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_17-03-15: conv4_x.5.sequence.4.weight: torch.Size([256])
2023-12-02_17-03-15: conv4_x.5.sequence.4.bias: torch.Size([256])
2023-12-02_17-03-15: conv5_x.0.sequence.0.weight: torch.Size([512, 256, 3, 3])
2023-12-02_17-03-15: conv5_x.0.sequence.1.weight: torch.Size([512])
2023-12-02_17-03-15: conv5_x.0.sequence.1.bias: torch.Size([512])
2023-12-02_17-03-15: conv5_x.0.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_17-03-15: conv5_x.0.sequence.4.weight: torch.Size([512])
2023-12-02_17-03-15: conv5_x.0.sequence.4.bias: torch.Size([512])
2023-12-02_17-03-15: conv5_x.0.shortcut.0.weight: torch.Size([512, 256, 1, 1])
2023-12-02_17-03-15: conv5_x.0.shortcut.1.weight: torch.Size([512])
2023-12-02_17-03-15: conv5_x.0.shortcut.1.bias: torch.Size([512])
2023-12-02_17-03-15: conv5_x.1.sequence.0.weight: torch.Size([512, 512, 3, 3])
2023-12-02_17-03-15: conv5_x.1.sequence.1.weight: torch.Size([512])
2023-12-02_17-03-15: conv5_x.1.sequence.1.bias: torch.Size([512])
2023-12-02_17-03-15: conv5_x.1.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_17-03-15: conv5_x.1.sequence.4.weight: torch.Size([512])
2023-12-02_17-03-15: conv5_x.1.sequence.4.bias: torch.Size([512])
2023-12-02_17-03-15: conv5_x.2.sequence.0.weight: torch.Size([512, 512, 3, 3])
2023-12-02_17-03-15: conv5_x.2.sequence.1.weight: torch.Size([512])
2023-12-02_17-03-15: conv5_x.2.sequence.1.bias: torch.Size([512])
2023-12-02_17-03-15: conv5_x.2.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_17-03-15: conv5_x.2.sequence.4.weight: torch.Size([512])
2023-12-02_17-03-15: conv5_x.2.sequence.4.bias: torch.Size([512])
2023-12-02_17-03-15: fc.weight: torch.Size([2, 512])
2023-12-02_17-03-15: fc.bias: torch.Size([2])
2023-12-02_17-03-15: 
Total parameters: 21,278,018;	Trainable: 21,278,018
2023-12-02_17-04-55: Epoch: 2 | Train loss: 0.4189629405736923 | Train acc: {'40X': 78.21, '100X': 81.23, '200X': 83.73, '400X': 81.12, 'avg_acc': 81.07, 'all_acc': 81.08} | Valid loss: 0.30657692581415175 | Valid acc: {'40X': 86.22, '100X': 87.77, '200X': 87.81, '400X': 89.01, 'avg_acc': 87.7, 'all_acc': 87.67}| Runtime: 1.7 mins
2023-12-02_17-06-36: Epoch: 3 | Train loss: 0.35663938502202164 | Train acc: {'40X': 82.41, '100X': 85.63, '200X': 86.64, '400X': 85.61, 'avg_acc': 85.07, 'all_acc': 85.07} | Valid loss: 0.3349499276280403 | Valid acc: {'40X': 83.71, '100X': 87.29, '200X': 88.31, '400X': 86.54, 'avg_acc': 86.46, 'all_acc': 86.47}| Runtime: 1.7 mins
2023-12-02_17-08-15: Epoch: 4 | Train loss: 0.3229485910788581 | Train acc: {'40X': 84.36, '100X': 85.69, '200X': 88.13, '400X': 86.89, 'avg_acc': 86.27, 'all_acc': 86.25} | Valid loss: 0.32108245968818666 | Valid acc: {'40X': 85.46, '100X': 85.61, '200X': 90.05, '400X': 84.07, 'avg_acc': 86.3, 'all_acc': 86.35}| Runtime: 1.6 mins
2023-12-02_17-09-53: Epoch: 5 | Train loss: 0.30026961178392975 | Train acc: {'40X': 86.93, '100X': 87.07, '200X': 88.65, '400X': 88.17, 'avg_acc': 87.7, 'all_acc': 87.69} | Valid loss: 0.3261953108012676 | Valid acc: {'40X': 82.21, '100X': 84.17, '200X': 89.55, '400X': 85.99, 'avg_acc': 85.48, 'all_acc': 85.46}| Runtime: 1.6 mins
2023-12-02_17-11-32: Epoch: 6 | Train loss: 0.27398205770028605 | Train acc: {'40X': 86.71, '100X': 87.88, '200X': 89.7, '400X': 88.9, 'avg_acc': 88.3, 'all_acc': 88.28} | Valid loss: 0.21523424550890924 | Valid acc: {'40X': 90.48, '100X': 91.85, '200X': 93.53, '400X': 90.11, 'avg_acc': 91.49, 'all_acc': 91.53}| Runtime: 1.7 mins
2023-12-02_17-13-12: Epoch: 7 | Train loss: 0.2643371632171644 | Train acc: {'40X': 87.78, '100X': 88.21, '200X': 90.77, '400X': 88.63, 'avg_acc': 88.85, 'all_acc': 88.85} | Valid loss: 0.237780874222517 | Valid acc: {'40X': 89.47, '100X': 91.37, '200X': 90.8, '400X': 89.56, 'avg_acc': 90.3, 'all_acc': 90.33}| Runtime: 1.7 mins
2023-12-02_17-14-51: Epoch: 8 | Train loss: 0.24832613514484586 | Train acc: {'40X': 88.77, '100X': 89.25, '200X': 91.79, '400X': 89.92, 'avg_acc': 89.93, 'all_acc': 89.93} | Valid loss: 0.2088846407458186 | Valid acc: {'40X': 89.72, '100X': 90.41, '200X': 92.79, '400X': 90.38, 'avg_acc': 90.82, 'all_acc': 90.83}| Runtime: 1.7 mins
2023-12-02_17-16-31: Epoch: 9 | Train loss: 0.22283519593042297 | Train acc: {'40X': 90.21, '100X': 90.61, '200X': 92.77, '400X': 90.1, 'avg_acc': 90.92, 'all_acc': 90.94} | Valid loss: 0.19430893868207932 | Valid acc: {'40X': 93.23, '100X': 92.81, '200X': 93.03, '400X': 89.01, 'avg_acc': 92.02, 'all_acc': 92.1}| Runtime: 1.7 mins
2023-12-02_17-18-10: Epoch: 10 | Train loss: 0.2177599866471782 | Train acc: {'40X': 90.68, '100X': 91.1, '200X': 92.79, '400X': 90.56, 'avg_acc': 91.28, 'all_acc': 91.3} | Valid loss: 0.2576251048222184 | Valid acc: {'40X': 86.47, '100X': 86.81, '200X': 90.05, '400X': 87.91, 'avg_acc': 87.81, 'all_acc': 87.8}| Runtime: 1.6 mins
2023-12-02_17-19-52: Epoch: 11 | Train loss: 0.21043318651012471 | Train acc: {'40X': 91.52, '100X': 91.42, '200X': 92.8, '400X': 91.19, 'avg_acc': 91.73, 'all_acc': 91.74} | Valid loss: 0.15798271395266056 | Valid acc: {'40X': 93.48, '100X': 93.76, '200X': 93.78, '400X': 93.41, 'avg_acc': 93.61, 'all_acc': 93.62}| Runtime: 1.7 mins
2023-12-02_17-19-52: Train summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  78.21  81.23  83.73  81.12    81.07    81.08
1      2  82.41  85.63  86.64  85.61    85.07    85.07
2      3  84.36  85.69  88.13  86.89    86.27    86.25
3      4  86.93  87.07  88.65  88.17    87.70    87.69
4      5  86.71  87.88  89.70  88.90    88.30    88.28
5      6  87.78  88.21  90.77  88.63    88.85    88.85
6      7  88.77  89.25  91.79  89.92    89.93    89.93
7      8  90.21  90.61  92.77  90.10    90.92    90.94
8      9  90.68  91.10  92.79  90.56    91.28    91.30
9     10  91.52  91.42  92.80  91.19    91.73    91.74
2023-12-02_17-19-52: Eval summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  86.22  87.77  87.81  89.01    87.70    87.67
1      2  83.71  87.29  88.31  86.54    86.46    86.47
2      3  85.46  85.61  90.05  84.07    86.30    86.35
3      4  82.21  84.17  89.55  85.99    85.48    85.46
4      5  90.48  91.85  93.53  90.11    91.49    91.53
5      6  89.47  91.37  90.80  89.56    90.30    90.33
6      7  89.72  90.41  92.79  90.38    90.82    90.83
7      8  93.23  92.81  93.03  89.01    92.02    92.10
8      9  86.47  86.81  90.05  87.91    87.81    87.80
9     10  93.48  93.76  93.78  93.41    93.61    93.62
2023-12-02_17-19-52: Final test accuracy: {'40X': 93.23, '100X': 92.79, '200X': 96.53, '400X': 93.68, 'avg_acc': 94.06, 'all_acc': 94.06}
