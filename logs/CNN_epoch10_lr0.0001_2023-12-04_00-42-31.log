2023-12-04_00-42-31: config: {'n_epochs': 10, 'batch_size': 32, 'h': 224, 'w': 224, 'lr': 0.0001, 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0, 'device': 'cuda:1', 'n_gpus': 1, 'kernel_size': 3, 'model': 'CNN', 'use_pooling': False, 'num_kernel_conv_list': [32, 64, 64, 64]}
2023-12-04_00-42-31: conv1.weight: torch.Size([32, 3, 3, 3])
2023-12-04_00-42-31: conv1.bias: torch.Size([32])
2023-12-04_00-42-31: conv_layers.0.weight: torch.Size([64, 32, 3, 3])
2023-12-04_00-42-31: conv_layers.0.bias: torch.Size([64])
2023-12-04_00-42-31: conv_layers.2.weight: torch.Size([64, 64, 3, 3])
2023-12-04_00-42-31: conv_layers.2.bias: torch.Size([64])
2023-12-04_00-42-31: conv_layers.4.weight: torch.Size([64, 64, 3, 3])
2023-12-04_00-42-31: conv_layers.4.bias: torch.Size([64])
2023-12-04_00-42-31: linear.weight: torch.Size([2, 3211264])
2023-12-04_00-42-31: linear.bias: torch.Size([2])
2023-12-04_00-42-31: 
Total parameters: 6,515,778;	Trainable: 6,515,778
2023-12-04_00-43-31: Epoch: 1 | Train loss: 0.47218853114424525 | Train acc: {'40X': 77.95, '100X': 79.53, '200X': 81.09, '400X': 78.64, 'avg_acc': 79.3, 'all_acc': 79.33} | Valid loss: 0.3877462548017502 | Valid acc: {'40X': 81.2, '100X': 82.25, '200X': 84.08, '400X': 80.77, 'avg_acc': 82.07, 'all_acc': 82.11}| Runtime: 1.0 mins
2023-12-04_00-44-30: Epoch: 2 | Train loss: 0.35417757727004384 | Train acc: {'40X': 83.04, '100X': 84.88, '200X': 86.47, '400X': 86.62, 'avg_acc': 85.25, 'all_acc': 85.22} | Valid loss: 0.34817150235176086 | Valid acc: {'40X': 83.96, '100X': 84.41, '200X': 86.32, '400X': 82.69, 'avg_acc': 84.34, 'all_acc': 84.39}| Runtime: 1.0 mins
2023-12-04_00-45-29: Epoch: 3 | Train loss: 0.2954924229431797 | Train acc: {'40X': 85.94, '100X': 86.51, '200X': 89.14, '400X': 88.81, 'avg_acc': 87.6, 'all_acc': 87.56} | Valid loss: 0.3407424533367157 | Valid acc: {'40X': 85.46, '100X': 87.29, '200X': 87.06, '400X': 85.16, 'avg_acc': 86.24, 'all_acc': 86.28}| Runtime: 1.0 mins
2023-12-04_00-46-30: Epoch: 4 | Train loss: 0.26938012740700634 | Train acc: {'40X': 85.79, '100X': 88.19, '200X': 90.31, '400X': 91.08, 'avg_acc': 88.84, 'all_acc': 88.79} | Valid loss: 0.3510952876508236 | Valid acc: {'40X': 83.96, '100X': 83.21, '200X': 87.56, '400X': 83.24, 'avg_acc': 84.49, 'all_acc': 84.51}| Runtime: 1.0 mins
2023-12-04_00-47-29: Epoch: 5 | Train loss: 0.2490646569058299 | Train acc: {'40X': 88.11, '100X': 89.66, '200X': 92.12, '400X': 89.99, 'avg_acc': 89.97, 'all_acc': 89.97} | Valid loss: 0.36846009761095044 | Valid acc: {'40X': 85.71, '100X': 85.13, '200X': 86.57, '400X': 81.04, 'avg_acc': 84.61, 'all_acc': 84.7}| Runtime: 1.0 mins
2023-12-04_00-48-29: Epoch: 6 | Train loss: 0.216128272533014 | Train acc: {'40X': 88.97, '100X': 92.13, '200X': 92.36, '400X': 92.66, 'avg_acc': 91.53, 'all_acc': 91.51} | Valid loss: 0.3496833974123001 | Valid acc: {'40X': 83.71, '100X': 84.41, '200X': 85.82, '400X': 82.69, 'avg_acc': 84.16, 'all_acc': 84.2}| Runtime: 1.0 mins
2023-12-04_00-49-30: Epoch: 7 | Train loss: 0.1713375908800879 | Train acc: {'40X': 91.21, '100X': 94.53, '200X': 94.36, '400X': 95.15, 'avg_acc': 93.81, 'all_acc': 93.79} | Valid loss: 0.4502351266145706 | Valid acc: {'40X': 84.21, '100X': 82.49, '200X': 85.07, '400X': 80.49, 'avg_acc': 83.06, 'all_acc': 83.12}| Runtime: 1.0 mins
2023-12-04_00-50-31: Epoch: 8 | Train loss: 0.14539808555934075 | Train acc: {'40X': 92.64, '100X': 95.5, '200X': 96.43, '400X': 95.6, 'avg_acc': 95.04, 'all_acc': 95.04} | Valid loss: 0.45424958914518354 | Valid acc: {'40X': 84.46, '100X': 84.41, '200X': 86.82, '400X': 80.77, 'avg_acc': 84.12, 'all_acc': 84.2}| Runtime: 1.0 mins
2023-12-04_00-51-33: Epoch: 9 | Train loss: 0.12461842763917269 | Train acc: {'40X': 93.72, '100X': 96.79, '200X': 96.02, '400X': 97.06, 'avg_acc': 95.9, 'all_acc': 95.88} | Valid loss: 0.4017247715592384 | Valid acc: {'40X': 85.21, '100X': 83.69, '200X': 86.07, '400X': 81.59, 'avg_acc': 84.14, 'all_acc': 84.2}| Runtime: 1.0 mins
2023-12-04_00-52-35: Epoch: 10 | Train loss: 0.10951278690953513 | Train acc: {'40X': 94.9, '100X': 97.12, '200X': 96.43, '400X': 97.52, 'avg_acc': 96.49, 'all_acc': 96.47} | Valid loss: 0.4192750073224306 | Valid acc: {'40X': 86.47, '100X': 83.69, '200X': 85.57, '400X': 80.77, 'avg_acc': 84.12, 'all_acc': 84.2}| Runtime: 1.0 mins
2023-12-04_00-52-35: Train summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  77.95  79.53  81.09  78.64    79.30    79.33
1      2  83.04  84.88  86.47  86.62    85.25    85.22
2      3  85.94  86.51  89.14  88.81    87.60    87.56
3      4  85.79  88.19  90.31  91.08    88.84    88.79
4      5  88.11  89.66  92.12  89.99    89.97    89.97
5      6  88.97  92.13  92.36  92.66    91.53    91.51
6      7  91.21  94.53  94.36  95.15    93.81    93.79
7      8  92.64  95.50  96.43  95.60    95.04    95.04
8      9  93.72  96.79  96.02  97.06    95.90    95.88
9     10  94.90  97.12  96.43  97.52    96.49    96.47
2023-12-04_00-52-35: Eval summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  81.20  82.25  84.08  80.77    82.07    82.11
1      2  83.96  84.41  86.32  82.69    84.34    84.39
2      3  85.46  87.29  87.06  85.16    86.24    86.28
3      4  83.96  83.21  87.56  83.24    84.49    84.51
4      5  85.71  85.13  86.57  81.04    84.61    84.70
5      6  83.71  84.41  85.82  82.69    84.16    84.20
6      7  84.21  82.49  85.07  80.49    83.06    83.12
7      8  84.46  84.41  86.82  80.77    84.12    84.20
8      9  85.21  83.69  86.07  81.59    84.14    84.20
9     10  86.47  83.69  85.57  80.77    84.12    84.20
2023-12-04_00-52-35: Final test accuracy: {'40X': 82.96, '100X': 84.13, '200X': 90.82, '400X': 86.54, 'avg_acc': 86.11, 'all_acc': 86.09}
