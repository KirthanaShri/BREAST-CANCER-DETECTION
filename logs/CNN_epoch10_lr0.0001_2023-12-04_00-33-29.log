2023-12-04_00-33-29: config: {'n_epochs': 10, 'batch_size': 32, 'h': 224, 'w': 224, 'lr': 0.0001, 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0, 'device': 'cuda:1', 'n_gpus': 1, 'kernel_size': 3, 'model': 'CNN', 'use_pooling': True, 'num_kernel_conv_list': [32, 64, 64, 64]}
2023-12-04_00-33-29: conv1.weight: torch.Size([32, 3, 3, 3])
2023-12-04_00-33-29: conv1.bias: torch.Size([32])
2023-12-04_00-33-29: conv_layers.0.weight: torch.Size([64, 32, 3, 3])
2023-12-04_00-33-29: conv_layers.0.bias: torch.Size([64])
2023-12-04_00-33-29: conv_layers.3.weight: torch.Size([64, 64, 3, 3])
2023-12-04_00-33-29: conv_layers.3.bias: torch.Size([64])
2023-12-04_00-33-29: conv_layers.6.weight: torch.Size([64, 64, 3, 3])
2023-12-04_00-33-29: conv_layers.6.bias: torch.Size([64])
2023-12-04_00-33-29: linear.weight: torch.Size([2, 50176])
2023-12-04_00-33-29: linear.bias: torch.Size([2])
2023-12-04_00-33-29: 
Total parameters: 193,602;	Trainable: 193,602
2023-12-04_00-34-23: Epoch: 1 | Train loss: 0.5539907289517892 | Train acc: {'40X': 73.72, '100X': 74.72, '200X': 77.11, '400X': 74.47, 'avg_acc': 75.0, 'all_acc': 75.02} | Valid loss: 0.47849335610866545 | Valid acc: {'40X': 80.7, '100X': 80.58, '200X': 85.57, '400X': 83.24, 'avg_acc': 82.52, 'all_acc': 82.49}| Runtime: 0.9 mins
2023-12-04_00-35-19: Epoch: 2 | Train loss: 0.45122824699894803 | Train acc: {'40X': 79.35, '100X': 81.01, '200X': 85.75, '400X': 85.23, 'avg_acc': 82.84, 'all_acc': 82.77} | Valid loss: 0.4472535929083824 | Valid acc: {'40X': 83.21, '100X': 81.53, '200X': 85.82, '400X': 84.34, 'avg_acc': 83.72, 'all_acc': 83.69}| Runtime: 0.9 mins
2023-12-04_00-36-13: Epoch: 3 | Train loss: 0.425658782994425 | Train acc: {'40X': 81.41, '100X': 81.96, '200X': 87.29, '400X': 86.07, 'avg_acc': 84.18, 'all_acc': 84.12} | Valid loss: 0.42384201407432553 | Valid acc: {'40X': 80.45, '100X': 82.01, '200X': 82.09, '400X': 83.52, 'avg_acc': 82.02, 'all_acc': 81.98}| Runtime: 0.9 mins
2023-12-04_00-37-08: Epoch: 4 | Train loss: 0.40139352912838394 | Train acc: {'40X': 82.85, '100X': 82.76, '200X': 87.14, '400X': 86.5, 'avg_acc': 84.81, 'all_acc': 84.76} | Valid loss: 0.40573789417743683 | Valid acc: {'40X': 84.46, '100X': 83.21, '200X': 85.57, '400X': 83.24, 'avg_acc': 84.12, 'all_acc': 84.13}| Runtime: 0.9 mins
2023-12-04_00-38-02: Epoch: 5 | Train loss: 0.3835254248130966 | Train acc: {'40X': 82.83, '100X': 82.68, '200X': 87.61, '400X': 86.26, 'avg_acc': 84.84, 'all_acc': 84.8} | Valid loss: 0.38176470071077345 | Valid acc: {'40X': 82.71, '100X': 84.41, '200X': 84.08, '400X': 85.99, 'avg_acc': 84.3, 'all_acc': 84.26}| Runtime: 0.9 mins
2023-12-04_00-38-56: Epoch: 6 | Train loss: 0.36205964540508956 | Train acc: {'40X': 83.71, '100X': 83.68, '200X': 87.54, '400X': 85.61, 'avg_acc': 85.14, 'all_acc': 85.11} | Valid loss: 0.3799855440855026 | Valid acc: {'40X': 83.21, '100X': 82.25, '200X': 86.32, '400X': 83.79, 'avg_acc': 83.89, 'all_acc': 83.88}| Runtime: 0.9 mins
2023-12-04_00-39-49: Epoch: 7 | Train loss: 0.3487198983092566 | Train acc: {'40X': 83.51, '100X': 84.75, '200X': 87.55, '400X': 86.61, 'avg_acc': 85.6, 'all_acc': 85.58} | Valid loss: 0.3516941332817078 | Valid acc: {'40X': 83.96, '100X': 83.93, '200X': 85.07, '400X': 83.24, 'avg_acc': 84.05, 'all_acc': 84.07}| Runtime: 0.9 mins
2023-12-04_00-40-43: Epoch: 8 | Train loss: 0.3353223840932588 | Train acc: {'40X': 84.0, '100X': 84.99, '200X': 87.23, '400X': 87.43, 'avg_acc': 85.91, 'all_acc': 85.87} | Valid loss: 0.341917764544487 | Valid acc: {'40X': 84.46, '100X': 85.37, '200X': 85.82, '400X': 82.69, 'avg_acc': 84.58, 'all_acc': 84.64}| Runtime: 0.9 mins
2023-12-04_00-41-37: Epoch: 9 | Train loss: 0.33165946698470694 | Train acc: {'40X': 83.61, '100X': 85.37, '200X': 87.82, '400X': 86.04, 'avg_acc': 85.71, 'all_acc': 85.71} | Valid loss: 0.35553856611251833 | Valid acc: {'40X': 83.96, '100X': 84.41, '200X': 84.83, '400X': 81.32, 'avg_acc': 83.63, 'all_acc': 83.69}| Runtime: 0.9 mins
2023-12-04_00-42-31: Epoch: 10 | Train loss: 0.32681592674674215 | Train acc: {'40X': 84.1, '100X': 84.59, '200X': 87.46, '400X': 86.98, 'avg_acc': 85.78, 'all_acc': 85.75} | Valid loss: 0.35170951917767523 | Valid acc: {'40X': 84.96, '100X': 84.65, '200X': 85.32, '400X': 82.14, 'avg_acc': 84.27, 'all_acc': 84.32}| Runtime: 0.9 mins
2023-12-04_00-42-31: Train summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  73.72  74.72  77.11  74.47    75.00    75.02
1      2  79.35  81.01  85.75  85.23    82.84    82.77
2      3  81.41  81.96  87.29  86.07    84.18    84.12
3      4  82.85  82.76  87.14  86.50    84.81    84.76
4      5  82.83  82.68  87.61  86.26    84.84    84.80
5      6  83.71  83.68  87.54  85.61    85.14    85.11
6      7  83.51  84.75  87.55  86.61    85.60    85.58
7      8  84.00  84.99  87.23  87.43    85.91    85.87
8      9  83.61  85.37  87.82  86.04    85.71    85.71
9     10  84.10  84.59  87.46  86.98    85.78    85.75
2023-12-04_00-42-31: Eval summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  80.70  80.58  85.57  83.24    82.52    82.49
1      2  83.21  81.53  85.82  84.34    83.72    83.69
2      3  80.45  82.01  82.09  83.52    82.02    81.98
3      4  84.46  83.21  85.57  83.24    84.12    84.13
4      5  82.71  84.41  84.08  85.99    84.30    84.26
5      6  83.21  82.25  86.32  83.79    83.89    83.88
6      7  83.96  83.93  85.07  83.24    84.05    84.07
7      8  84.46  85.37  85.82  82.69    84.58    84.64
8      9  83.96  84.41  84.83  81.32    83.63    83.69
9     10  84.96  84.65  85.32  82.14    84.27    84.32
2023-12-04_00-42-31: Final test accuracy: {'40X': 82.21, '100X': 82.45, '200X': 90.32, '400X': 86.26, 'avg_acc': 85.31, 'all_acc': 85.27}
