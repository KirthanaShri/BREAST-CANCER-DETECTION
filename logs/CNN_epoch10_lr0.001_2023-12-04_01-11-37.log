2023-12-04_01-11-37: config: {'n_epochs': 10, 'batch_size': 32, 'h': 224, 'w': 224, 'lr': 0.001, 'optimizer': 'sgd', 'momentum': 0.9, 'weight_decay': 0, 'device': 'cuda:1', 'n_gpus': 1, 'kernel_size': 3, 'model': 'CNN', 'use_pooling': True, 'num_kernel_conv_list': [32, 64, 64, 64]}
2023-12-04_01-11-37: conv1.weight: torch.Size([32, 3, 3, 3])
2023-12-04_01-11-37: conv1.bias: torch.Size([32])
2023-12-04_01-11-37: conv_layers.0.weight: torch.Size([64, 32, 3, 3])
2023-12-04_01-11-37: conv_layers.0.bias: torch.Size([64])
2023-12-04_01-11-37: conv_layers.3.weight: torch.Size([64, 64, 3, 3])
2023-12-04_01-11-37: conv_layers.3.bias: torch.Size([64])
2023-12-04_01-11-37: conv_layers.6.weight: torch.Size([64, 64, 3, 3])
2023-12-04_01-11-37: conv_layers.6.bias: torch.Size([64])
2023-12-04_01-11-37: linear.weight: torch.Size([2, 50176])
2023-12-04_01-11-37: linear.bias: torch.Size([2])
2023-12-04_01-11-37: 
Total parameters: 193,602;	Trainable: 193,602
2023-12-04_01-12-31: Epoch: 1 | Train loss: 0.4453241281412743 | Train acc: {'40X': 80.2, '100X': 79.74, '200X': 83.73, '400X': 83.58, 'avg_acc': 81.81, 'all_acc': 81.76} | Valid loss: 0.39454525351524355 | Valid acc: {'40X': 83.21, '100X': 86.33, '200X': 85.57, '400X': 85.16, 'avg_acc': 85.07, 'all_acc': 85.08}| Runtime: 0.9 mins
2023-12-04_01-13-26: Epoch: 2 | Train loss: 0.3576292012994354 | Train acc: {'40X': 82.68, '100X': 84.19, '200X': 88.13, '400X': 86.06, 'avg_acc': 85.26, 'all_acc': 85.24} | Valid loss: 0.3288016477227211 | Valid acc: {'40X': 84.96, '100X': 85.37, '200X': 85.32, '400X': 86.26, 'avg_acc': 85.48, 'all_acc': 85.46}| Runtime: 0.9 mins
2023-12-04_01-14-20: Epoch: 3 | Train loss: 0.3394935226218926 | Train acc: {'40X': 83.6, '100X': 84.19, '200X': 87.8, '400X': 86.24, 'avg_acc': 85.46, 'all_acc': 85.43} | Valid loss: 0.32779781639575956 | Valid acc: {'40X': 84.96, '100X': 86.57, '200X': 87.31, '400X': 87.64, 'avg_acc': 86.62, 'all_acc': 86.6}| Runtime: 0.9 mins
2023-12-04_01-15-14: Epoch: 4 | Train loss: 0.3116926884631047 | Train acc: {'40X': 84.69, '100X': 86.37, '200X': 87.98, '400X': 85.75, 'avg_acc': 86.2, 'all_acc': 86.21} | Valid loss: 0.3155655390024185 | Valid acc: {'40X': 84.71, '100X': 85.61, '200X': 88.81, '400X': 83.52, 'avg_acc': 85.66, 'all_acc': 85.71}| Runtime: 0.9 mins
2023-12-04_01-16-09: Epoch: 5 | Train loss: 0.2940180179335781 | Train acc: {'40X': 86.28, '100X': 86.13, '200X': 89.71, '400X': 87.51, 'avg_acc': 87.41, 'all_acc': 87.39} | Valid loss: 0.30360563889145853 | Valid acc: {'40X': 86.22, '100X': 87.77, '200X': 87.31, '400X': 85.44, 'avg_acc': 86.68, 'all_acc': 86.73}| Runtime: 0.9 mins
2023-12-04_01-17-03: Epoch: 6 | Train loss: 0.27663873785452264 | Train acc: {'40X': 86.43, '100X': 87.63, '200X': 90.55, '400X': 88.82, 'avg_acc': 88.36, 'all_acc': 88.34} | Valid loss: 0.32335348695516586 | Valid acc: {'40X': 84.46, '100X': 86.09, '200X': 87.56, '400X': 81.04, 'avg_acc': 84.79, 'all_acc': 84.89}| Runtime: 0.9 mins
2023-12-04_01-17-58: Epoch: 7 | Train loss: 0.2587937952296154 | Train acc: {'40X': 87.29, '100X': 87.72, '200X': 90.61, '400X': 88.35, 'avg_acc': 88.49, 'all_acc': 88.49} | Valid loss: 0.2814769092202187 | Valid acc: {'40X': 86.47, '100X': 89.21, '200X': 89.8, '400X': 85.99, 'avg_acc': 87.87, 'all_acc': 87.93}| Runtime: 0.9 mins
2023-12-04_01-18-52: Epoch: 8 | Train loss: 0.2392810545861721 | Train acc: {'40X': 88.77, '100X': 89.0, '200X': 90.96, '400X': 89.09, 'avg_acc': 89.45, 'all_acc': 89.46} | Valid loss: 0.2776893091201782 | Valid acc: {'40X': 88.22, '100X': 88.25, '200X': 89.8, '400X': 87.64, 'avg_acc': 88.48, 'all_acc': 88.5}| Runtime: 0.9 mins
2023-12-04_01-19-46: Epoch: 9 | Train loss: 0.20978803192642895 | Train acc: {'40X': 90.61, '100X': 90.11, '200X': 92.3, '400X': 92.3, 'avg_acc': 91.33, 'all_acc': 91.3} | Valid loss: 0.29702347435057164 | Valid acc: {'40X': 86.72, '100X': 87.77, '200X': 89.3, '400X': 86.81, 'avg_acc': 87.65, 'all_acc': 87.67}| Runtime: 0.9 mins
2023-12-04_01-20-40: Epoch: 10 | Train loss: 0.19799582103921756 | Train acc: {'40X': 90.44, '100X': 90.69, '200X': 93.04, '400X': 92.57, 'avg_acc': 91.68, 'all_acc': 91.66} | Valid loss: 0.33711394891142843 | Valid acc: {'40X': 85.96, '100X': 86.09, '200X': 89.3, '400X': 81.59, 'avg_acc': 85.74, 'all_acc': 85.84}| Runtime: 0.9 mins
2023-12-04_01-20-40: Train summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  80.20  79.74  83.73  83.58    81.81    81.76
1      2  82.68  84.19  88.13  86.06    85.26    85.24
2      3  83.60  84.19  87.80  86.24    85.46    85.43
3      4  84.69  86.37  87.98  85.75    86.20    86.21
4      5  86.28  86.13  89.71  87.51    87.41    87.39
5      6  86.43  87.63  90.55  88.82    88.36    88.34
6      7  87.29  87.72  90.61  88.35    88.49    88.49
7      8  88.77  89.00  90.96  89.09    89.45    89.46
8      9  90.61  90.11  92.30  92.30    91.33    91.30
9     10  90.44  90.69  93.04  92.57    91.68    91.66
2023-12-04_01-20-40: Eval summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  83.21  86.33  85.57  85.16    85.07    85.08
1      2  84.96  85.37  85.32  86.26    85.48    85.46
2      3  84.96  86.57  87.31  87.64    86.62    86.60
3      4  84.71  85.61  88.81  83.52    85.66    85.71
4      5  86.22  87.77  87.31  85.44    86.68    86.73
5      6  84.46  86.09  87.56  81.04    84.79    84.89
6      7  86.47  89.21  89.80  85.99    87.87    87.93
7      8  88.22  88.25  89.80  87.64    88.48    88.50
8      9  86.72  87.77  89.30  86.81    87.65    87.67
9     10  85.96  86.09  89.30  81.59    85.74    85.84
2023-12-04_01-20-40: Final test accuracy: {'40X': 87.97, '100X': 86.3, '200X': 92.31, '400X': 88.74, 'avg_acc': 88.83, 'all_acc': 88.81}
