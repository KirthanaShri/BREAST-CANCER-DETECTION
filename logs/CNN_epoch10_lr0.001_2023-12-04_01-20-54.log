2023-12-04_01-20-54: config: {'n_epochs': 10, 'batch_size': 32, 'h': 224, 'w': 224, 'lr': 0.001, 'optimizer': 'adam', 'momentum': 0.9, 'weight_decay': 0, 'device': 'cuda:1', 'n_gpus': 1, 'kernel_size': 3, 'model': 'CNN', 'use_pooling': False, 'num_kernel_conv_list': [32, 64, 64, 64]}
2023-12-04_01-20-54: conv1.weight: torch.Size([32, 3, 3, 3])
2023-12-04_01-20-54: conv1.bias: torch.Size([32])
2023-12-04_01-20-54: conv_layers.0.weight: torch.Size([64, 32, 3, 3])
2023-12-04_01-20-54: conv_layers.0.bias: torch.Size([64])
2023-12-04_01-20-54: conv_layers.2.weight: torch.Size([64, 64, 3, 3])
2023-12-04_01-20-54: conv_layers.2.bias: torch.Size([64])
2023-12-04_01-20-54: conv_layers.4.weight: torch.Size([64, 64, 3, 3])
2023-12-04_01-20-54: conv_layers.4.bias: torch.Size([64])
2023-12-04_01-20-54: linear.weight: torch.Size([2, 3211264])
2023-12-04_01-20-54: linear.bias: torch.Size([2])
2023-12-04_01-20-54: 
Total parameters: 6,515,778;	Trainable: 6,515,778
2023-12-04_01-21-57: Epoch: 1 | Train loss: 0.9550164757749519 | Train acc: {'40X': 77.05, '100X': 79.12, '200X': 83.67, '400X': 80.48, 'avg_acc': 80.08, 'all_acc': 80.07} | Valid loss: 0.4598802907764912 | Valid acc: {'40X': 73.68, '100X': 81.29, '200X': 83.08, '400X': 81.87, 'avg_acc': 79.98, 'all_acc': 79.96}| Runtime: 1.0 mins
2023-12-04_01-22-58: Epoch: 2 | Train loss: 0.3913745041433218 | Train acc: {'40X': 81.2, '100X': 81.93, '200X': 84.08, '400X': 84.65, 'avg_acc': 82.96, 'all_acc': 82.92} | Valid loss: 0.4359726184606552 | Valid acc: {'40X': 80.95, '100X': 83.45, '200X': 85.57, '400X': 80.77, 'avg_acc': 82.68, 'all_acc': 82.74}| Runtime: 1.0 mins
2023-12-04_01-24-01: Epoch: 3 | Train loss: 0.27644579480024606 | Train acc: {'40X': 86.59, '100X': 89.18, '200X': 89.55, '400X': 88.43, 'avg_acc': 88.44, 'all_acc': 88.45} | Valid loss: 0.41153750956058505 | Valid acc: {'40X': 81.7, '100X': 83.45, '200X': 83.58, '400X': 78.57, 'avg_acc': 81.82, 'all_acc': 81.92}| Runtime: 1.0 mins
2023-12-04_01-25-03: Epoch: 4 | Train loss: 0.1530900638097444 | Train acc: {'40X': 93.39, '100X': 94.45, '200X': 95.53, '400X': 94.86, 'avg_acc': 94.56, 'all_acc': 94.55} | Valid loss: 0.5273166826367378 | Valid acc: {'40X': 79.95, '100X': 82.73, '200X': 85.32, '400X': 79.67, 'avg_acc': 81.92, 'all_acc': 81.98}| Runtime: 1.0 mins
2023-12-04_01-26-05: Epoch: 5 | Train loss: 0.08628878949329609 | Train acc: {'40X': 95.74, '100X': 97.51, '200X': 97.84, '400X': 96.51, 'avg_acc': 96.9, 'all_acc': 96.92} | Valid loss: 0.9062905895709992 | Valid acc: {'40X': 76.69, '100X': 77.94, '200X': 79.1, '400X': 75.82, 'avg_acc': 77.39, 'all_acc': 77.43}| Runtime: 1.0 mins
2023-12-04_01-27-08: Epoch: 6 | Train loss: 0.06634601295258649 | Train acc: {'40X': 97.07, '100X': 98.15, '200X': 98.59, '400X': 97.71, 'avg_acc': 97.88, 'all_acc': 97.89} | Valid loss: 1.2419265127182006 | Valid acc: {'40X': 80.95, '100X': 81.29, '200X': 84.33, '400X': 80.49, 'avg_acc': 81.76, 'all_acc': 81.8}| Runtime: 1.0 mins
2023-12-04_01-28-11: Epoch: 7 | Train loss: 0.02585609389894376 | Train acc: {'40X': 99.16, '100X': 99.04, '200X': 99.34, '400X': 98.72, 'avg_acc': 99.06, 'all_acc': 99.07} | Valid loss: 1.3246256098151208 | Valid acc: {'40X': 77.19, '100X': 80.34, '200X': 82.34, '400X': 79.12, 'avg_acc': 79.75, 'all_acc': 79.77}| Runtime: 1.0 mins
2023-12-04_01-29-15: Epoch: 8 | Train loss: 0.013558722444375578 | Train acc: {'40X': 99.41, '100X': 99.28, '200X': 99.75, '400X': 99.63, 'avg_acc': 99.52, 'all_acc': 99.51} | Valid loss: 1.5568027323484421 | Valid acc: {'40X': 75.94, '100X': 79.62, '200X': 82.09, '400X': 79.4, 'avg_acc': 79.26, 'all_acc': 79.27}| Runtime: 1.1 mins
2023-12-04_01-30-18: Epoch: 9 | Train loss: 0.04591632412405955 | Train acc: {'40X': 98.33, '100X': 98.71, '200X': 99.0, '400X': 98.9, 'avg_acc': 98.73, 'all_acc': 98.73} | Valid loss: 1.0391775947809219 | Valid acc: {'40X': 78.7, '100X': 77.94, '200X': 79.35, '400X': 77.75, 'avg_acc': 78.44, 'all_acc': 78.45}| Runtime: 1.1 mins
2023-12-04_01-31-20: Epoch: 10 | Train loss: 0.014232812124720187 | Train acc: {'40X': 99.16, '100X': 99.44, '200X': 99.67, '400X': 99.63, 'avg_acc': 99.48, 'all_acc': 99.47} | Valid loss: 1.8922750098258256 | Valid acc: {'40X': 76.69, '100X': 77.7, '200X': 81.09, '400X': 76.92, 'avg_acc': 78.1, 'all_acc': 78.13}| Runtime: 1.0 mins
2023-12-04_01-31-20: Train summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  77.05  79.12  83.67  80.48    80.08    80.07
1      2  81.20  81.93  84.08  84.65    82.96    82.92
2      3  86.59  89.18  89.55  88.43    88.44    88.45
3      4  93.39  94.45  95.53  94.86    94.56    94.55
4      5  95.74  97.51  97.84  96.51    96.90    96.92
5      6  97.07  98.15  98.59  97.71    97.88    97.89
6      7  99.16  99.04  99.34  98.72    99.06    99.07
7      8  99.41  99.28  99.75  99.63    99.52    99.51
8      9  98.33  98.71  99.00  98.90    98.73    98.73
9     10  99.16  99.44  99.67  99.63    99.48    99.47
2023-12-04_01-31-20: Eval summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  73.68  81.29  83.08  81.87    79.98    79.96
1      2  80.95  83.45  85.57  80.77    82.68    82.74
2      3  81.70  83.45  83.58  78.57    81.82    81.92
3      4  79.95  82.73  85.32  79.67    81.92    81.98
4      5  76.69  77.94  79.10  75.82    77.39    77.43
5      6  80.95  81.29  84.33  80.49    81.76    81.80
6      7  77.19  80.34  82.34  79.12    79.75    79.77
7      8  75.94  79.62  82.09  79.40    79.26    79.27
8      9  78.70  77.94  79.35  77.75    78.44    78.45
9     10  76.69  77.70  81.09  76.92    78.10    78.13
2023-12-04_01-31-20: Final test accuracy: {'40X': 81.2, '100X': 83.17, '200X': 88.09, '400X': 84.62, 'avg_acc': 84.27, 'all_acc': 84.26}
