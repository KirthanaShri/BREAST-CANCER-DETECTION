2023-12-02_18-54-58: config: {'n_epochs': 10, 'batch_size': 32, 'h': 224, 'w': 224, 'lr': 0.001, 'optimizer': 'sgd', 'momentum': 0.9, 'device': 'cuda', 'n_gpus': 2, 'kernel_size': 3, 'flatten': False, 'model': 'resnet', 'num_blocks_list': [2, 2, 2, 2], 'is_batchnorm': False}
2023-12-02_18-54-58: conv1.0.weight: torch.Size([64, 3, 3, 3])
2023-12-02_18-54-58: conv1.1.weight: torch.Size([64])
2023-12-02_18-54-58: conv1.1.bias: torch.Size([64])
2023-12-02_18-54-58: conv2_x.0.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_18-54-58: conv2_x.0.sequence.1.weight: torch.Size([64])
2023-12-02_18-54-58: conv2_x.0.sequence.1.bias: torch.Size([64])
2023-12-02_18-54-58: conv2_x.0.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_18-54-58: conv2_x.0.sequence.4.weight: torch.Size([64])
2023-12-02_18-54-58: conv2_x.0.sequence.4.bias: torch.Size([64])
2023-12-02_18-54-58: conv2_x.1.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_18-54-58: conv2_x.1.sequence.1.weight: torch.Size([64])
2023-12-02_18-54-58: conv2_x.1.sequence.1.bias: torch.Size([64])
2023-12-02_18-54-58: conv2_x.1.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_18-54-58: conv2_x.1.sequence.4.weight: torch.Size([64])
2023-12-02_18-54-58: conv2_x.1.sequence.4.bias: torch.Size([64])
2023-12-02_18-54-58: conv3_x.0.sequence.0.weight: torch.Size([128, 64, 3, 3])
2023-12-02_18-54-58: conv3_x.0.sequence.1.weight: torch.Size([128])
2023-12-02_18-54-58: conv3_x.0.sequence.1.bias: torch.Size([128])
2023-12-02_18-54-58: conv3_x.0.sequence.3.weight: torch.Size([128, 128, 3, 3])
2023-12-02_18-54-58: conv3_x.0.sequence.4.weight: torch.Size([128])
2023-12-02_18-54-58: conv3_x.0.sequence.4.bias: torch.Size([128])
2023-12-02_18-54-58: conv3_x.0.shortcut.0.weight: torch.Size([128, 64, 1, 1])
2023-12-02_18-54-58: conv3_x.0.shortcut.1.weight: torch.Size([128])
2023-12-02_18-54-58: conv3_x.0.shortcut.1.bias: torch.Size([128])
2023-12-02_18-54-58: conv3_x.1.sequence.0.weight: torch.Size([128, 128, 3, 3])
2023-12-02_18-54-58: conv3_x.1.sequence.1.weight: torch.Size([128])
2023-12-02_18-54-58: conv3_x.1.sequence.1.bias: torch.Size([128])
2023-12-02_18-54-58: conv3_x.1.sequence.3.weight: torch.Size([128, 128, 3, 3])
2023-12-02_18-54-58: conv3_x.1.sequence.4.weight: torch.Size([128])
2023-12-02_18-54-58: conv3_x.1.sequence.4.bias: torch.Size([128])
2023-12-02_18-54-58: conv4_x.0.sequence.0.weight: torch.Size([256, 128, 3, 3])
2023-12-02_18-54-58: conv4_x.0.sequence.1.weight: torch.Size([256])
2023-12-02_18-54-58: conv4_x.0.sequence.1.bias: torch.Size([256])
2023-12-02_18-54-58: conv4_x.0.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_18-54-58: conv4_x.0.sequence.4.weight: torch.Size([256])
2023-12-02_18-54-58: conv4_x.0.sequence.4.bias: torch.Size([256])
2023-12-02_18-54-58: conv4_x.0.shortcut.0.weight: torch.Size([256, 128, 1, 1])
2023-12-02_18-54-58: conv4_x.0.shortcut.1.weight: torch.Size([256])
2023-12-02_18-54-58: conv4_x.0.shortcut.1.bias: torch.Size([256])
2023-12-02_18-54-58: conv4_x.1.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_18-54-58: conv4_x.1.sequence.1.weight: torch.Size([256])
2023-12-02_18-54-58: conv4_x.1.sequence.1.bias: torch.Size([256])
2023-12-02_18-54-58: conv4_x.1.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_18-54-58: conv4_x.1.sequence.4.weight: torch.Size([256])
2023-12-02_18-54-58: conv4_x.1.sequence.4.bias: torch.Size([256])
2023-12-02_18-54-58: conv5_x.0.sequence.0.weight: torch.Size([512, 256, 3, 3])
2023-12-02_18-54-58: conv5_x.0.sequence.1.weight: torch.Size([512])
2023-12-02_18-54-58: conv5_x.0.sequence.1.bias: torch.Size([512])
2023-12-02_18-54-58: conv5_x.0.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_18-54-58: conv5_x.0.sequence.4.weight: torch.Size([512])
2023-12-02_18-54-58: conv5_x.0.sequence.4.bias: torch.Size([512])
2023-12-02_18-54-58: conv5_x.0.shortcut.0.weight: torch.Size([512, 256, 1, 1])
2023-12-02_18-54-58: conv5_x.0.shortcut.1.weight: torch.Size([512])
2023-12-02_18-54-58: conv5_x.0.shortcut.1.bias: torch.Size([512])
2023-12-02_18-54-58: conv5_x.1.sequence.0.weight: torch.Size([512, 512, 3, 3])
2023-12-02_18-54-58: conv5_x.1.sequence.1.weight: torch.Size([512])
2023-12-02_18-54-58: conv5_x.1.sequence.1.bias: torch.Size([512])
2023-12-02_18-54-58: conv5_x.1.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_18-54-58: conv5_x.1.sequence.4.weight: torch.Size([512])
2023-12-02_18-54-58: conv5_x.1.sequence.4.bias: torch.Size([512])
2023-12-02_18-54-58: fc.weight: torch.Size([2, 512])
2023-12-02_18-54-58: fc.bias: torch.Size([2])
2023-12-02_18-54-58: 
Total parameters: 11,169,858;	Trainable: 11,169,858
2023-12-02_18-56-06: Epoch: 2 | Train loss: 0.4259047116580847 | Train acc: {'40X': 79.41, '100X': 79.2, '200X': 83.0, '400X': 81.1, 'avg_acc': 80.68, 'all_acc': 80.66} | Valid loss: 0.4495638203620911 | Valid acc: {'40X': 80.7, '100X': 81.06, '200X': 84.83, '400X': 81.32, 'avg_acc': 81.98, 'all_acc': 81.98}| Runtime: 1.1 mins
2023-12-02_18-57-12: Epoch: 3 | Train loss: 0.35893724566778623 | Train acc: {'40X': 80.43, '100X': 85.3, '200X': 86.31, '400X': 84.68, 'avg_acc': 84.18, 'all_acc': 84.18} | Valid loss: 1.0255801087617875 | Valid acc: {'40X': 65.16, '100X': 71.94, '200X': 70.4, '400X': 64.01, 'avg_acc': 67.88, 'all_acc': 68.02}| Runtime: 1.1 mins
2023-12-02_18-58-19: Epoch: 4 | Train loss: 0.3460503964609391 | Train acc: {'40X': 83.25, '100X': 83.88, '200X': 87.13, '400X': 86.07, 'avg_acc': 85.08, 'all_acc': 85.05} | Valid loss: 0.42737985521554944 | Valid acc: {'40X': 76.19, '100X': 79.86, '200X': 84.58, '400X': 80.49, 'avg_acc': 80.28, 'all_acc': 80.28}| Runtime: 1.1 mins
2023-12-02_18-59-26: Epoch: 5 | Train loss: 0.30912043848955956 | Train acc: {'40X': 84.29, '100X': 86.59, '200X': 89.37, '400X': 86.88, 'avg_acc': 86.78, 'all_acc': 86.78} | Valid loss: 0.3196364060044289 | Valid acc: {'40X': 85.96, '100X': 87.53, '200X': 87.31, '400X': 87.91, 'avg_acc': 87.18, 'all_acc': 87.17}| Runtime: 1.1 mins
2023-12-02_19-00-34: Epoch: 6 | Train loss: 0.32103007749931234 | Train acc: {'40X': 84.24, '100X': 85.38, '200X': 88.57, '400X': 87.17, 'avg_acc': 86.34, 'all_acc': 86.32} | Valid loss: 0.2633630274236202 | Valid acc: {'40X': 86.22, '100X': 90.65, '200X': 91.54, '400X': 87.91, 'avg_acc': 89.08, 'all_acc': 89.13}| Runtime: 1.1 mins
2023-12-02_19-01-41: Epoch: 7 | Train loss: 0.2917181333476627 | Train acc: {'40X': 84.52, '100X': 87.74, '200X': 88.36, '400X': 88.17, 'avg_acc': 87.2, 'all_acc': 87.18} | Valid loss: 0.30885335385799406 | Valid acc: {'40X': 88.22, '100X': 90.17, '200X': 91.04, '400X': 85.16, 'avg_acc': 88.65, 'all_acc': 88.75}| Runtime: 1.1 mins
2023-12-02_19-02-47: Epoch: 8 | Train loss: 0.27896066483210874 | Train acc: {'40X': 86.92, '100X': 87.24, '200X': 91.45, '400X': 87.64, 'avg_acc': 88.31, 'all_acc': 88.32} | Valid loss: 0.36583094283938405 | Valid acc: {'40X': 82.46, '100X': 85.61, '200X': 89.55, '400X': 82.42, 'avg_acc': 85.01, 'all_acc': 85.08}| Runtime: 1.1 mins
2023-12-02_19-03-54: Epoch: 9 | Train loss: 0.26879520296446374 | Train acc: {'40X': 86.86, '100X': 88.19, '200X': 90.88, '400X': 88.9, 'avg_acc': 88.71, 'all_acc': 88.7} | Valid loss: 0.298743300139904 | Valid acc: {'40X': 86.22, '100X': 88.97, '200X': 92.54, '400X': 88.19, 'avg_acc': 88.98, 'all_acc': 89.0}| Runtime: 1.1 mins
2023-12-02_19-05-01: Epoch: 10 | Train loss: 0.2692065436292339 | Train acc: {'40X': 86.36, '100X': 87.86, '200X': 91.21, '400X': 88.45, 'avg_acc': 88.47, 'all_acc': 88.47} | Valid loss: 0.32803061965852975 | Valid acc: {'40X': 83.96, '100X': 86.81, '200X': 89.55, '400X': 88.19, 'avg_acc': 87.13, 'all_acc': 87.1}| Runtime: 1.1 mins
2023-12-02_19-06-07: Epoch: 11 | Train loss: 0.24532325467648539 | Train acc: {'40X': 87.95, '100X': 89.73, '200X': 92.03, '400X': 89.18, 'avg_acc': 89.72, 'all_acc': 89.74} | Valid loss: 0.24608374610543252 | Valid acc: {'40X': 84.96, '100X': 90.65, '200X': 89.8, '400X': 89.29, 'avg_acc': 88.68, 'all_acc': 88.69}| Runtime: 1.1 mins
2023-12-02_19-06-07: Train summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  79.41  79.20  83.00  81.10    80.68    80.66
1      2  80.43  85.30  86.31  84.68    84.18    84.18
2      3  83.25  83.88  87.13  86.07    85.08    85.05
3      4  84.29  86.59  89.37  86.88    86.78    86.78
4      5  84.24  85.38  88.57  87.17    86.34    86.32
5      6  84.52  87.74  88.36  88.17    87.20    87.18
6      7  86.92  87.24  91.45  87.64    88.31    88.32
7      8  86.86  88.19  90.88  88.90    88.71    88.70
8      9  86.36  87.86  91.21  88.45    88.47    88.47
9     10  87.95  89.73  92.03  89.18    89.72    89.74
2023-12-02_19-06-07: Eval summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  80.70  81.06  84.83  81.32    81.98    81.98
1      2  65.16  71.94  70.40  64.01    67.88    68.02
2      3  76.19  79.86  84.58  80.49    80.28    80.28
3      4  85.96  87.53  87.31  87.91    87.18    87.17
4      5  86.22  90.65  91.54  87.91    89.08    89.13
5      6  88.22  90.17  91.04  85.16    88.65    88.75
6      7  82.46  85.61  89.55  82.42    85.01    85.08
7      8  86.22  88.97  92.54  88.19    88.98    89.00
8      9  83.96  86.81  89.55  88.19    87.13    87.10
9     10  84.96  90.65  89.80  89.29    88.68    88.69
2023-12-02_19-06-07: Final test accuracy: {'40X': 86.72, '100X': 86.54, '200X': 91.07, '400X': 88.19, 'avg_acc': 88.13, 'all_acc': 88.12}
