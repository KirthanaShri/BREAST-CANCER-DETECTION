2023-12-02_16-32-36: config: {'n_epochs': 10, 'batch_size': 32, 'h': 224, 'w': 224, 'lr': 0.0001, 'optimizer': 'adam', 'momentum': 0.9, 'device': 'cuda', 'n_gpus': 2, 'kernel_size': 3, 'flatten': False, 'model': 'resnet', 'num_blocks_list': [3, 2, 3, 4], 'is_batchnorm': False}
2023-12-02_16-32-36: conv1.0.weight: torch.Size([64, 3, 3, 3])
2023-12-02_16-32-36: conv1.1.weight: torch.Size([64])
2023-12-02_16-32-36: conv1.1.bias: torch.Size([64])
2023-12-02_16-32-36: conv2_x.0.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_16-32-36: conv2_x.0.sequence.1.weight: torch.Size([64])
2023-12-02_16-32-36: conv2_x.0.sequence.1.bias: torch.Size([64])
2023-12-02_16-32-36: conv2_x.0.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_16-32-36: conv2_x.0.sequence.4.weight: torch.Size([64])
2023-12-02_16-32-36: conv2_x.0.sequence.4.bias: torch.Size([64])
2023-12-02_16-32-36: conv2_x.1.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_16-32-36: conv2_x.1.sequence.1.weight: torch.Size([64])
2023-12-02_16-32-36: conv2_x.1.sequence.1.bias: torch.Size([64])
2023-12-02_16-32-36: conv2_x.1.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_16-32-36: conv2_x.1.sequence.4.weight: torch.Size([64])
2023-12-02_16-32-36: conv2_x.1.sequence.4.bias: torch.Size([64])
2023-12-02_16-32-36: conv2_x.2.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_16-32-36: conv2_x.2.sequence.1.weight: torch.Size([64])
2023-12-02_16-32-36: conv2_x.2.sequence.1.bias: torch.Size([64])
2023-12-02_16-32-36: conv2_x.2.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_16-32-36: conv2_x.2.sequence.4.weight: torch.Size([64])
2023-12-02_16-32-36: conv2_x.2.sequence.4.bias: torch.Size([64])
2023-12-02_16-32-36: conv3_x.0.sequence.0.weight: torch.Size([128, 64, 3, 3])
2023-12-02_16-32-36: conv3_x.0.sequence.1.weight: torch.Size([128])
2023-12-02_16-32-36: conv3_x.0.sequence.1.bias: torch.Size([128])
2023-12-02_16-32-36: conv3_x.0.sequence.3.weight: torch.Size([128, 128, 3, 3])
2023-12-02_16-32-36: conv3_x.0.sequence.4.weight: torch.Size([128])
2023-12-02_16-32-36: conv3_x.0.sequence.4.bias: torch.Size([128])
2023-12-02_16-32-36: conv3_x.0.shortcut.0.weight: torch.Size([128, 64, 1, 1])
2023-12-02_16-32-36: conv3_x.0.shortcut.1.weight: torch.Size([128])
2023-12-02_16-32-36: conv3_x.0.shortcut.1.bias: torch.Size([128])
2023-12-02_16-32-36: conv3_x.1.sequence.0.weight: torch.Size([128, 128, 3, 3])
2023-12-02_16-32-36: conv3_x.1.sequence.1.weight: torch.Size([128])
2023-12-02_16-32-36: conv3_x.1.sequence.1.bias: torch.Size([128])
2023-12-02_16-32-36: conv3_x.1.sequence.3.weight: torch.Size([128, 128, 3, 3])
2023-12-02_16-32-36: conv3_x.1.sequence.4.weight: torch.Size([128])
2023-12-02_16-32-36: conv3_x.1.sequence.4.bias: torch.Size([128])
2023-12-02_16-32-36: conv4_x.0.sequence.0.weight: torch.Size([256, 128, 3, 3])
2023-12-02_16-32-36: conv4_x.0.sequence.1.weight: torch.Size([256])
2023-12-02_16-32-36: conv4_x.0.sequence.1.bias: torch.Size([256])
2023-12-02_16-32-36: conv4_x.0.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_16-32-36: conv4_x.0.sequence.4.weight: torch.Size([256])
2023-12-02_16-32-36: conv4_x.0.sequence.4.bias: torch.Size([256])
2023-12-02_16-32-36: conv4_x.0.shortcut.0.weight: torch.Size([256, 128, 1, 1])
2023-12-02_16-32-36: conv4_x.0.shortcut.1.weight: torch.Size([256])
2023-12-02_16-32-36: conv4_x.0.shortcut.1.bias: torch.Size([256])
2023-12-02_16-32-36: conv4_x.1.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_16-32-36: conv4_x.1.sequence.1.weight: torch.Size([256])
2023-12-02_16-32-36: conv4_x.1.sequence.1.bias: torch.Size([256])
2023-12-02_16-32-36: conv4_x.1.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_16-32-36: conv4_x.1.sequence.4.weight: torch.Size([256])
2023-12-02_16-32-36: conv4_x.1.sequence.4.bias: torch.Size([256])
2023-12-02_16-32-36: conv4_x.2.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_16-32-36: conv4_x.2.sequence.1.weight: torch.Size([256])
2023-12-02_16-32-36: conv4_x.2.sequence.1.bias: torch.Size([256])
2023-12-02_16-32-36: conv4_x.2.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_16-32-36: conv4_x.2.sequence.4.weight: torch.Size([256])
2023-12-02_16-32-36: conv4_x.2.sequence.4.bias: torch.Size([256])
2023-12-02_16-32-36: conv5_x.0.sequence.0.weight: torch.Size([512, 256, 3, 3])
2023-12-02_16-32-36: conv5_x.0.sequence.1.weight: torch.Size([512])
2023-12-02_16-32-36: conv5_x.0.sequence.1.bias: torch.Size([512])
2023-12-02_16-32-36: conv5_x.0.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_16-32-36: conv5_x.0.sequence.4.weight: torch.Size([512])
2023-12-02_16-32-36: conv5_x.0.sequence.4.bias: torch.Size([512])
2023-12-02_16-32-36: conv5_x.0.shortcut.0.weight: torch.Size([512, 256, 1, 1])
2023-12-02_16-32-36: conv5_x.0.shortcut.1.weight: torch.Size([512])
2023-12-02_16-32-36: conv5_x.0.shortcut.1.bias: torch.Size([512])
2023-12-02_16-32-36: conv5_x.1.sequence.0.weight: torch.Size([512, 512, 3, 3])
2023-12-02_16-32-36: conv5_x.1.sequence.1.weight: torch.Size([512])
2023-12-02_16-32-36: conv5_x.1.sequence.1.bias: torch.Size([512])
2023-12-02_16-32-36: conv5_x.1.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_16-32-36: conv5_x.1.sequence.4.weight: torch.Size([512])
2023-12-02_16-32-36: conv5_x.1.sequence.4.bias: torch.Size([512])
2023-12-02_16-32-36: conv5_x.2.sequence.0.weight: torch.Size([512, 512, 3, 3])
2023-12-02_16-32-36: conv5_x.2.sequence.1.weight: torch.Size([512])
2023-12-02_16-32-36: conv5_x.2.sequence.1.bias: torch.Size([512])
2023-12-02_16-32-36: conv5_x.2.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_16-32-36: conv5_x.2.sequence.4.weight: torch.Size([512])
2023-12-02_16-32-36: conv5_x.2.sequence.4.bias: torch.Size([512])
2023-12-02_16-32-36: conv5_x.3.sequence.0.weight: torch.Size([512, 512, 3, 3])
2023-12-02_16-32-36: conv5_x.3.sequence.1.weight: torch.Size([512])
2023-12-02_16-32-36: conv5_x.3.sequence.1.bias: torch.Size([512])
2023-12-02_16-32-36: conv5_x.3.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_16-32-36: conv5_x.3.sequence.4.weight: torch.Size([512])
2023-12-02_16-32-36: conv5_x.3.sequence.4.bias: torch.Size([512])
2023-12-02_16-32-36: fc.weight: torch.Size([2, 512])
2023-12-02_16-32-36: fc.bias: torch.Size([2])
2023-12-02_16-32-36: 
Total parameters: 21,865,794;	Trainable: 21,865,794
2023-12-02_16-34-00: Epoch: 2 | Train loss: 0.40395949307728457 | Train acc: {'40X': 80.35, '100X': 81.06, '200X': 83.58, '400X': 84.47, 'avg_acc': 82.36, 'all_acc': 82.31} | Valid loss: 0.691618046760559 | Valid acc: {'40X': 69.67, '100X': 70.02, '200X': 67.41, '400X': 64.84, 'avg_acc': 67.98, 'all_acc': 68.08}| Runtime: 1.4 mins
2023-12-02_16-35-24: Epoch: 3 | Train loss: 0.3523346497803121 | Train acc: {'40X': 82.61, '100X': 85.37, '200X': 87.65, '400X': 85.96, 'avg_acc': 85.4, 'all_acc': 85.39} | Valid loss: 0.3421089732646942 | Valid acc: {'40X': 86.97, '100X': 89.69, '200X': 88.06, '400X': 84.89, 'avg_acc': 87.4, 'all_acc': 87.48}| Runtime: 1.4 mins
2023-12-02_16-36-48: Epoch: 4 | Train loss: 0.3313686678538451 | Train acc: {'40X': 84.84, '100X': 86.61, '200X': 87.47, '400X': 85.87, 'avg_acc': 86.2, 'all_acc': 86.21} | Valid loss: 0.26476809695363046 | Valid acc: {'40X': 86.72, '100X': 88.73, '200X': 90.05, '400X': 87.91, 'avg_acc': 88.35, 'all_acc': 88.37}| Runtime: 1.4 mins
2023-12-02_16-38-14: Epoch: 5 | Train loss: 0.2844315857903377 | Train acc: {'40X': 87.12, '100X': 87.64, '200X': 89.55, '400X': 86.03, 'avg_acc': 87.58, 'all_acc': 87.63} | Valid loss: 0.2997126616537571 | Valid acc: {'40X': 89.22, '100X': 92.09, '200X': 89.55, '400X': 87.09, 'avg_acc': 89.49, 'all_acc': 89.57}| Runtime: 1.4 mins
2023-12-02_16-39-38: Epoch: 6 | Train loss: 0.2676644551794271 | Train acc: {'40X': 89.46, '100X': 88.28, '200X': 89.37, '400X': 87.63, 'avg_acc': 88.68, 'all_acc': 88.7} | Valid loss: 0.23826676666736601 | Valid acc: {'40X': 90.23, '100X': 91.37, '200X': 90.8, '400X': 89.84, 'avg_acc': 90.56, 'all_acc': 90.58}| Runtime: 1.4 mins
2023-12-02_16-41-02: Epoch: 7 | Train loss: 0.2404090711796606 | Train acc: {'40X': 89.36, '100X': 89.25, '200X': 91.04, '400X': 89.62, 'avg_acc': 89.82, 'all_acc': 89.82} | Valid loss: 0.23944244995713235 | Valid acc: {'40X': 88.97, '100X': 89.93, '200X': 91.54, '400X': 88.74, 'avg_acc': 89.8, 'all_acc': 89.82}| Runtime: 1.4 mins
2023-12-02_16-42-26: Epoch: 8 | Train loss: 0.22899622769673933 | Train acc: {'40X': 90.72, '100X': 90.02, '200X': 91.21, '400X': 90.83, 'avg_acc': 90.7, 'all_acc': 90.69} | Valid loss: 0.208648417070508 | Valid acc: {'40X': 91.48, '100X': 93.05, '200X': 91.54, '400X': 90.11, 'avg_acc': 91.54, 'all_acc': 91.59}| Runtime: 1.4 mins
2023-12-02_16-43-51: Epoch: 9 | Train loss: 0.2257457879195745 | Train acc: {'40X': 90.8, '100X': 91.08, '200X': 91.71, '400X': 89.9, 'avg_acc': 90.87, 'all_acc': 90.9} | Valid loss: 0.1668631725013256 | Valid acc: {'40X': 93.23, '100X': 95.2, '200X': 92.04, '400X': 91.21, 'avg_acc': 92.92, 'all_acc': 92.98}| Runtime: 1.4 mins
2023-12-02_16-45-15: Epoch: 10 | Train loss: 0.1972593255592762 | Train acc: {'40X': 91.71, '100X': 92.04, '200X': 93.29, '400X': 91.2, 'avg_acc': 92.06, 'all_acc': 92.08} | Valid loss: 0.1664477194286883 | Valid acc: {'40X': 94.24, '100X': 94.0, '200X': 93.78, '400X': 92.03, 'avg_acc': 93.51, 'all_acc': 93.55}| Runtime: 1.4 mins
2023-12-02_16-46-40: Epoch: 11 | Train loss: 0.19084754203622406 | Train acc: {'40X': 92.64, '100X': 93.01, '200X': 92.61, '400X': 91.48, 'avg_acc': 92.44, 'all_acc': 92.46} | Valid loss: 0.16826948896050453 | Valid acc: {'40X': 91.48, '100X': 94.72, '200X': 94.53, '400X': 93.68, 'avg_acc': 93.6, 'all_acc': 93.62}| Runtime: 1.4 mins
2023-12-02_16-46-40: Train summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  80.35  81.06  83.58  84.47    82.36    82.31
1      2  82.61  85.37  87.65  85.96    85.40    85.39
2      3  84.84  86.61  87.47  85.87    86.20    86.21
3      4  87.12  87.64  89.55  86.03    87.58    87.63
4      5  89.46  88.28  89.37  87.63    88.68    88.70
5      6  89.36  89.25  91.04  89.62    89.82    89.82
6      7  90.72  90.02  91.21  90.83    90.70    90.69
7      8  90.80  91.08  91.71  89.90    90.87    90.90
8      9  91.71  92.04  93.29  91.20    92.06    92.08
9     10  92.64  93.01  92.61  91.48    92.44    92.46
2023-12-02_16-46-40: Eval summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  69.67  70.02  67.41  64.84    67.98    68.08
1      2  86.97  89.69  88.06  84.89    87.40    87.48
2      3  86.72  88.73  90.05  87.91    88.35    88.37
3      4  89.22  92.09  89.55  87.09    89.49    89.57
4      5  90.23  91.37  90.80  89.84    90.56    90.58
5      6  88.97  89.93  91.54  88.74    89.80    89.82
6      7  91.48  93.05  91.54  90.11    91.54    91.59
7      8  93.23  95.20  92.04  91.21    92.92    92.98
8      9  94.24  94.00  93.78  92.03    93.51    93.55
9     10  91.48  94.72  94.53  93.68    93.60    93.62
2023-12-02_16-46-40: Final test accuracy: {'40X': 89.22, '100X': 91.11, '200X': 94.79, '400X': 91.76, 'avg_acc': 91.72, 'all_acc': 91.72}
