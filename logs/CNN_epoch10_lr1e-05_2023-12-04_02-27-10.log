2023-12-04_02-27-10: config: {'n_epochs': 10, 'batch_size': 32, 'h': 224, 'w': 224, 'lr': 1e-05, 'optimizer': 'adam', 'momentum': 0.9, 'weight_decay': 0, 'device': 'cuda:1', 'n_gpus': 1, 'kernel_size': 3, 'model': 'CNN', 'use_pooling': True, 'num_kernel_conv_list': [32, 64, 64, 64]}
2023-12-04_02-27-10: conv1.weight: torch.Size([32, 3, 3, 3])
2023-12-04_02-27-10: conv1.bias: torch.Size([32])
2023-12-04_02-27-10: conv_layers.0.weight: torch.Size([64, 32, 3, 3])
2023-12-04_02-27-10: conv_layers.0.bias: torch.Size([64])
2023-12-04_02-27-10: conv_layers.3.weight: torch.Size([64, 64, 3, 3])
2023-12-04_02-27-10: conv_layers.3.bias: torch.Size([64])
2023-12-04_02-27-10: conv_layers.6.weight: torch.Size([64, 64, 3, 3])
2023-12-04_02-27-10: conv_layers.6.bias: torch.Size([64])
2023-12-04_02-27-10: linear.weight: torch.Size([2, 50176])
2023-12-04_02-27-10: linear.bias: torch.Size([2])
2023-12-04_02-27-10: 
Total parameters: 193,602;	Trainable: 193,602
2023-12-04_02-28-14: Epoch: 1 | Train loss: 0.5573162599592596 | Train acc: {'40X': 72.3, '100X': 72.85, '200X': 73.75, '400X': 73.63, 'avg_acc': 73.13, 'all_acc': 73.12} | Valid loss: 0.4791390997171402 | Valid acc: {'40X': 79.95, '100X': 80.34, '200X': 83.83, '400X': 82.42, 'avg_acc': 81.64, 'all_acc': 81.61}| Runtime: 1.1 mins
2023-12-04_02-29-16: Epoch: 2 | Train loss: 0.44420359978401985 | Train acc: {'40X': 80.59, '100X': 80.21, '200X': 86.21, '400X': 84.66, 'avg_acc': 82.92, 'all_acc': 82.85} | Valid loss: 0.42193655043840406 | Valid acc: {'40X': 82.71, '100X': 84.17, '200X': 84.83, '400X': 85.44, 'avg_acc': 84.29, 'all_acc': 84.26}| Runtime: 1.0 mins
2023-12-04_02-30-19: Epoch: 3 | Train loss: 0.40210647498433655 | Train acc: {'40X': 82.76, '100X': 81.64, '200X': 86.62, '400X': 86.71, 'avg_acc': 84.43, 'all_acc': 84.35} | Valid loss: 0.392739899456501 | Valid acc: {'40X': 84.96, '100X': 85.85, '200X': 86.07, '400X': 85.71, 'avg_acc': 85.65, 'all_acc': 85.65}| Runtime: 1.0 mins
2023-12-04_02-31-22: Epoch: 4 | Train loss: 0.37800686534594846 | Train acc: {'40X': 83.58, '100X': 83.21, '200X': 87.25, '400X': 86.04, 'avg_acc': 85.02, 'all_acc': 84.99} | Valid loss: 0.37591394990682603 | Valid acc: {'40X': 85.21, '100X': 85.37, '200X': 85.57, '400X': 85.16, 'avg_acc': 85.33, 'all_acc': 85.34}| Runtime: 1.1 mins
2023-12-04_02-32-24: Epoch: 5 | Train loss: 0.36217276741926735 | Train acc: {'40X': 83.4, '100X': 83.94, '200X': 88.15, '400X': 86.8, 'avg_acc': 85.57, 'all_acc': 85.54} | Valid loss: 0.3727955928444862 | Valid acc: {'40X': 83.71, '100X': 83.45, '200X': 85.57, '400X': 83.79, 'avg_acc': 84.13, 'all_acc': 84.13}| Runtime: 1.0 mins
2023-12-04_02-33-26: Epoch: 6 | Train loss: 0.34480778550779495 | Train acc: {'40X': 84.0, '100X': 83.72, '200X': 87.41, '400X': 86.67, 'avg_acc': 85.45, 'all_acc': 85.41} | Valid loss: 0.34699122846126557 | Valid acc: {'40X': 85.21, '100X': 85.61, '200X': 86.32, '400X': 85.16, 'avg_acc': 85.57, 'all_acc': 85.59}| Runtime: 1.0 mins
2023-12-04_02-34-28: Epoch: 7 | Train loss: 0.33398919794205073 | Train acc: {'40X': 83.6, '100X': 84.02, '200X': 87.56, '400X': 86.61, 'avg_acc': 85.45, 'all_acc': 85.41} | Valid loss: 0.3392185637354851 | Valid acc: {'40X': 85.21, '100X': 86.33, '200X': 87.06, '400X': 85.71, 'avg_acc': 86.08, 'all_acc': 86.09}| Runtime: 1.0 mins
2023-12-04_02-35-30: Epoch: 8 | Train loss: 0.3255678746547248 | Train acc: {'40X': 83.86, '100X': 85.31, '200X': 87.82, '400X': 86.94, 'avg_acc': 85.98, 'all_acc': 85.96} | Valid loss: 0.34076395839452744 | Valid acc: {'40X': 84.71, '100X': 85.37, '200X': 85.32, '400X': 84.34, 'avg_acc': 84.94, 'all_acc': 84.96}| Runtime: 1.0 mins
2023-12-04_02-36-32: Epoch: 9 | Train loss: 0.3217761644439117 | Train acc: {'40X': 84.0, '100X': 85.32, '200X': 87.13, '400X': 86.62, 'avg_acc': 85.77, 'all_acc': 85.75} | Valid loss: 0.3297788116335869 | Valid acc: {'40X': 85.21, '100X': 86.09, '200X': 87.31, '400X': 86.26, 'avg_acc': 86.22, 'all_acc': 86.22}| Runtime: 1.0 mins
2023-12-04_02-37-36: Epoch: 10 | Train loss: 0.3129152884153095 | Train acc: {'40X': 83.91, '100X': 85.54, '200X': 88.57, '400X': 87.08, 'avg_acc': 86.28, 'all_acc': 86.25} | Valid loss: 0.31879970580339434 | Valid acc: {'40X': 85.71, '100X': 86.57, '200X': 87.56, '400X': 85.99, 'avg_acc': 86.46, 'all_acc': 86.47}| Runtime: 1.1 mins
2023-12-04_02-37-36: Train summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  72.30  72.85  73.75  73.63    73.13    73.12
1      2  80.59  80.21  86.21  84.66    82.92    82.85
2      3  82.76  81.64  86.62  86.71    84.43    84.35
3      4  83.58  83.21  87.25  86.04    85.02    84.99
4      5  83.40  83.94  88.15  86.80    85.57    85.54
5      6  84.00  83.72  87.41  86.67    85.45    85.41
6      7  83.60  84.02  87.56  86.61    85.45    85.41
7      8  83.86  85.31  87.82  86.94    85.98    85.96
8      9  84.00  85.32  87.13  86.62    85.77    85.75
9     10  83.91  85.54  88.57  87.08    86.28    86.25
2023-12-04_02-37-36: Eval summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  79.95  80.34  83.83  82.42    81.64    81.61
1      2  82.71  84.17  84.83  85.44    84.29    84.26
2      3  84.96  85.85  86.07  85.71    85.65    85.65
3      4  85.21  85.37  85.57  85.16    85.33    85.34
4      5  83.71  83.45  85.57  83.79    84.13    84.13
5      6  85.21  85.61  86.32  85.16    85.57    85.59
6      7  85.21  86.33  87.06  85.71    86.08    86.09
7      8  84.71  85.37  85.32  84.34    84.94    84.96
8      9  85.21  86.09  87.31  86.26    86.22    86.22
9     10  85.71  86.57  87.56  85.99    86.46    86.47
2023-12-04_02-37-36: Final test accuracy: {'40X': 83.46, '100X': 83.65, '200X': 92.06, '400X': 87.36, 'avg_acc': 86.63, 'all_acc': 86.6}
