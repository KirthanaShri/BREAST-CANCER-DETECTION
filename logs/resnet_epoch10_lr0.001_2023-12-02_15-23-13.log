2023-12-02_15-23-13: config: {'n_epochs': 10, 'batch_size': 32, 'h': 224, 'w': 224, 'lr': 0.001, 'optimizer': 'adam', 'momentum': 0.9, 'device': 'cuda', 'n_gpus': 2, 'kernel_size': 3, 'flatten': False, 'model': 'resnet', 'num_blocks_list': [3, 4, 6, 3], 'is_batchnorm': True}
2023-12-02_15-23-13: conv1.0.weight: torch.Size([64, 3, 3, 3])
2023-12-02_15-23-13: conv1.1.weight: torch.Size([64])
2023-12-02_15-23-13: conv1.1.bias: torch.Size([64])
2023-12-02_15-23-13: conv2_x.0.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_15-23-13: conv2_x.0.sequence.1.weight: torch.Size([64])
2023-12-02_15-23-13: conv2_x.0.sequence.1.bias: torch.Size([64])
2023-12-02_15-23-13: conv2_x.0.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_15-23-13: conv2_x.0.sequence.4.weight: torch.Size([64])
2023-12-02_15-23-13: conv2_x.0.sequence.4.bias: torch.Size([64])
2023-12-02_15-23-13: conv2_x.1.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_15-23-13: conv2_x.1.sequence.1.weight: torch.Size([64])
2023-12-02_15-23-13: conv2_x.1.sequence.1.bias: torch.Size([64])
2023-12-02_15-23-13: conv2_x.1.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_15-23-13: conv2_x.1.sequence.4.weight: torch.Size([64])
2023-12-02_15-23-13: conv2_x.1.sequence.4.bias: torch.Size([64])
2023-12-02_15-23-13: conv2_x.2.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_15-23-13: conv2_x.2.sequence.1.weight: torch.Size([64])
2023-12-02_15-23-13: conv2_x.2.sequence.1.bias: torch.Size([64])
2023-12-02_15-23-13: conv2_x.2.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_15-23-13: conv2_x.2.sequence.4.weight: torch.Size([64])
2023-12-02_15-23-13: conv2_x.2.sequence.4.bias: torch.Size([64])
2023-12-02_15-23-13: conv3_x.0.sequence.0.weight: torch.Size([128, 64, 3, 3])
2023-12-02_15-23-13: conv3_x.0.sequence.1.weight: torch.Size([128])
2023-12-02_15-23-13: conv3_x.0.sequence.1.bias: torch.Size([128])
2023-12-02_15-23-13: conv3_x.0.sequence.3.weight: torch.Size([128, 128, 3, 3])
2023-12-02_15-23-13: conv3_x.0.sequence.4.weight: torch.Size([128])
2023-12-02_15-23-13: conv3_x.0.sequence.4.bias: torch.Size([128])
2023-12-02_15-23-13: conv3_x.0.shortcut.0.weight: torch.Size([128, 64, 1, 1])
2023-12-02_15-23-13: conv3_x.0.shortcut.1.weight: torch.Size([128])
2023-12-02_15-23-13: conv3_x.0.shortcut.1.bias: torch.Size([128])
2023-12-02_15-23-13: conv3_x.1.sequence.0.weight: torch.Size([128, 128, 3, 3])
2023-12-02_15-23-13: conv3_x.1.sequence.1.weight: torch.Size([128])
2023-12-02_15-23-13: conv3_x.1.sequence.1.bias: torch.Size([128])
2023-12-02_15-23-13: conv3_x.1.sequence.3.weight: torch.Size([128, 128, 3, 3])
2023-12-02_15-23-13: conv3_x.1.sequence.4.weight: torch.Size([128])
2023-12-02_15-23-13: conv3_x.1.sequence.4.bias: torch.Size([128])
2023-12-02_15-23-13: conv3_x.2.sequence.0.weight: torch.Size([128, 128, 3, 3])
2023-12-02_15-23-13: conv3_x.2.sequence.1.weight: torch.Size([128])
2023-12-02_15-23-13: conv3_x.2.sequence.1.bias: torch.Size([128])
2023-12-02_15-23-13: conv3_x.2.sequence.3.weight: torch.Size([128, 128, 3, 3])
2023-12-02_15-23-13: conv3_x.2.sequence.4.weight: torch.Size([128])
2023-12-02_15-23-13: conv3_x.2.sequence.4.bias: torch.Size([128])
2023-12-02_15-23-13: conv3_x.3.sequence.0.weight: torch.Size([128, 128, 3, 3])
2023-12-02_15-23-13: conv3_x.3.sequence.1.weight: torch.Size([128])
2023-12-02_15-23-13: conv3_x.3.sequence.1.bias: torch.Size([128])
2023-12-02_15-23-13: conv3_x.3.sequence.3.weight: torch.Size([128, 128, 3, 3])
2023-12-02_15-23-13: conv3_x.3.sequence.4.weight: torch.Size([128])
2023-12-02_15-23-13: conv3_x.3.sequence.4.bias: torch.Size([128])
2023-12-02_15-23-13: conv4_x.0.sequence.0.weight: torch.Size([256, 128, 3, 3])
2023-12-02_15-23-13: conv4_x.0.sequence.1.weight: torch.Size([256])
2023-12-02_15-23-13: conv4_x.0.sequence.1.bias: torch.Size([256])
2023-12-02_15-23-13: conv4_x.0.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_15-23-13: conv4_x.0.sequence.4.weight: torch.Size([256])
2023-12-02_15-23-13: conv4_x.0.sequence.4.bias: torch.Size([256])
2023-12-02_15-23-13: conv4_x.0.shortcut.0.weight: torch.Size([256, 128, 1, 1])
2023-12-02_15-23-13: conv4_x.0.shortcut.1.weight: torch.Size([256])
2023-12-02_15-23-13: conv4_x.0.shortcut.1.bias: torch.Size([256])
2023-12-02_15-23-13: conv4_x.1.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_15-23-13: conv4_x.1.sequence.1.weight: torch.Size([256])
2023-12-02_15-23-13: conv4_x.1.sequence.1.bias: torch.Size([256])
2023-12-02_15-23-13: conv4_x.1.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_15-23-13: conv4_x.1.sequence.4.weight: torch.Size([256])
2023-12-02_15-23-13: conv4_x.1.sequence.4.bias: torch.Size([256])
2023-12-02_15-23-13: conv4_x.2.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_15-23-13: conv4_x.2.sequence.1.weight: torch.Size([256])
2023-12-02_15-23-13: conv4_x.2.sequence.1.bias: torch.Size([256])
2023-12-02_15-23-13: conv4_x.2.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_15-23-13: conv4_x.2.sequence.4.weight: torch.Size([256])
2023-12-02_15-23-13: conv4_x.2.sequence.4.bias: torch.Size([256])
2023-12-02_15-23-13: conv4_x.3.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_15-23-13: conv4_x.3.sequence.1.weight: torch.Size([256])
2023-12-02_15-23-13: conv4_x.3.sequence.1.bias: torch.Size([256])
2023-12-02_15-23-13: conv4_x.3.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_15-23-13: conv4_x.3.sequence.4.weight: torch.Size([256])
2023-12-02_15-23-13: conv4_x.3.sequence.4.bias: torch.Size([256])
2023-12-02_15-23-13: conv4_x.4.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_15-23-13: conv4_x.4.sequence.1.weight: torch.Size([256])
2023-12-02_15-23-13: conv4_x.4.sequence.1.bias: torch.Size([256])
2023-12-02_15-23-13: conv4_x.4.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_15-23-13: conv4_x.4.sequence.4.weight: torch.Size([256])
2023-12-02_15-23-13: conv4_x.4.sequence.4.bias: torch.Size([256])
2023-12-02_15-23-13: conv4_x.5.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_15-23-13: conv4_x.5.sequence.1.weight: torch.Size([256])
2023-12-02_15-23-13: conv4_x.5.sequence.1.bias: torch.Size([256])
2023-12-02_15-23-13: conv4_x.5.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_15-23-13: conv4_x.5.sequence.4.weight: torch.Size([256])
2023-12-02_15-23-13: conv4_x.5.sequence.4.bias: torch.Size([256])
2023-12-02_15-23-13: conv5_x.0.sequence.0.weight: torch.Size([512, 256, 3, 3])
2023-12-02_15-23-13: conv5_x.0.sequence.1.weight: torch.Size([512])
2023-12-02_15-23-13: conv5_x.0.sequence.1.bias: torch.Size([512])
2023-12-02_15-23-13: conv5_x.0.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_15-23-13: conv5_x.0.sequence.4.weight: torch.Size([512])
2023-12-02_15-23-13: conv5_x.0.sequence.4.bias: torch.Size([512])
2023-12-02_15-23-13: conv5_x.0.shortcut.0.weight: torch.Size([512, 256, 1, 1])
2023-12-02_15-23-13: conv5_x.0.shortcut.1.weight: torch.Size([512])
2023-12-02_15-23-13: conv5_x.0.shortcut.1.bias: torch.Size([512])
2023-12-02_15-23-13: conv5_x.1.sequence.0.weight: torch.Size([512, 512, 3, 3])
2023-12-02_15-23-13: conv5_x.1.sequence.1.weight: torch.Size([512])
2023-12-02_15-23-13: conv5_x.1.sequence.1.bias: torch.Size([512])
2023-12-02_15-23-13: conv5_x.1.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_15-23-13: conv5_x.1.sequence.4.weight: torch.Size([512])
2023-12-02_15-23-13: conv5_x.1.sequence.4.bias: torch.Size([512])
2023-12-02_15-23-13: conv5_x.2.sequence.0.weight: torch.Size([512, 512, 3, 3])
2023-12-02_15-23-13: conv5_x.2.sequence.1.weight: torch.Size([512])
2023-12-02_15-23-13: conv5_x.2.sequence.1.bias: torch.Size([512])
2023-12-02_15-23-13: conv5_x.2.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_15-23-13: conv5_x.2.sequence.4.weight: torch.Size([512])
2023-12-02_15-23-13: conv5_x.2.sequence.4.bias: torch.Size([512])
2023-12-02_15-23-13: fc.weight: torch.Size([2, 512])
2023-12-02_15-23-13: fc.bias: torch.Size([2])
2023-12-02_15-23-13: 
Total parameters: 21,278,018;	Trainable: 21,278,018
2023-12-02_15-24-52: Epoch: 2 | Train loss: 0.46059990855487615 | Train acc: {'40X': 79.65, '100X': 80.43, '200X': 82.75, '400X': 82.37, 'avg_acc': 81.3, 'all_acc': 81.27} | Valid loss: 0.3623452831804752 | Valid acc: {'40X': 83.46, '100X': 85.61, '200X': 85.82, '400X': 85.44, 'avg_acc': 85.08, 'all_acc': 85.08}| Runtime: 1.6 mins
2023-12-02_15-26-31: Epoch: 3 | Train loss: 0.3923171457608004 | Train acc: {'40X': 81.34, '100X': 82.66, '200X': 85.82, '400X': 83.01, 'avg_acc': 83.21, 'all_acc': 83.21} | Valid loss: 0.39717343568801877 | Valid acc: {'40X': 82.71, '100X': 85.61, '200X': 83.58, '400X': 78.85, 'avg_acc': 82.69, 'all_acc': 82.81}| Runtime: 1.7 mins
2023-12-02_15-28-10: Epoch: 4 | Train loss: 0.3874695397712089 | Train acc: {'40X': 81.77, '100X': 82.81, '200X': 84.81, '400X': 83.12, 'avg_acc': 83.13, 'all_acc': 83.13} | Valid loss: 0.34933056324720385 | Valid acc: {'40X': 83.46, '100X': 85.37, '200X': 87.06, '400X': 83.79, 'avg_acc': 84.92, 'all_acc': 84.96}| Runtime: 1.7 mins
2023-12-02_15-29-49: Epoch: 5 | Train loss: 0.3567721723402674 | Train acc: {'40X': 83.86, '100X': 85.65, '200X': 87.46, '400X': 85.03, 'avg_acc': 85.5, 'all_acc': 85.52} | Valid loss: 0.3615402948856354 | Valid acc: {'40X': 83.46, '100X': 84.41, '200X': 87.56, '400X': 82.14, 'avg_acc': 84.39, 'all_acc': 84.45}| Runtime: 1.6 mins
2023-12-02_15-31-29: Epoch: 6 | Train loss: 0.35256528240200635 | Train acc: {'40X': 83.67, '100X': 84.59, '200X': 86.39, '400X': 83.87, 'avg_acc': 84.63, 'all_acc': 84.65} | Valid loss: 0.37719495564699174 | Valid acc: {'40X': 77.69, '100X': 83.69, '200X': 82.59, '400X': 85.16, 'avg_acc': 82.28, 'all_acc': 82.24}| Runtime: 1.7 mins
2023-12-02_15-33-08: Epoch: 7 | Train loss: 0.3245330752452483 | Train acc: {'40X': 84.02, '100X': 86.04, '200X': 88.38, '400X': 85.87, 'avg_acc': 86.08, 'all_acc': 86.09} | Valid loss: 0.473929318189621 | Valid acc: {'40X': 74.94, '100X': 81.77, '200X': 84.33, '400X': 81.04, 'avg_acc': 80.52, 'all_acc': 80.53}| Runtime: 1.6 mins
2023-12-02_15-34-48: Epoch: 8 | Train loss: 0.3170603600808898 | Train acc: {'40X': 86.04, '100X': 87.14, '200X': 88.46, '400X': 87.17, 'avg_acc': 87.2, 'all_acc': 87.2} | Valid loss: 0.3252358500659466 | Valid acc: {'40X': 83.96, '100X': 87.77, '200X': 84.83, '400X': 85.99, 'avg_acc': 85.64, 'all_acc': 85.65}| Runtime: 1.7 mins
2023-12-02_15-36-26: Epoch: 9 | Train loss: 0.3052489670950013 | Train acc: {'40X': 86.12, '100X': 87.57, '200X': 88.13, '400X': 87.5, 'avg_acc': 87.33, 'all_acc': 87.33} | Valid loss: 0.5452098804712295 | Valid acc: {'40X': 67.92, '100X': 69.78, '200X': 75.37, '400X': 78.3, 'avg_acc': 72.84, 'all_acc': 72.69}| Runtime: 1.6 mins
2023-12-02_15-38-07: Epoch: 10 | Train loss: 0.28387716679355585 | Train acc: {'40X': 86.24, '100X': 87.57, '200X': 90.46, '400X': 87.27, 'avg_acc': 87.88, 'all_acc': 87.9} | Valid loss: 0.29756156280636786 | Valid acc: {'40X': 86.22, '100X': 86.33, '200X': 87.56, '400X': 87.36, 'avg_acc': 86.87, 'all_acc': 86.85}| Runtime: 1.7 mins
2023-12-02_15-39-45: Epoch: 11 | Train loss: 0.29020273554566745 | Train acc: {'40X': 87.03, '100X': 87.87, '200X': 90.62, '400X': 88.73, 'avg_acc': 88.56, 'all_acc': 88.56} | Valid loss: 1.0946563413739205 | Valid acc: {'40X': 75.44, '100X': 68.82, '200X': 73.38, '400X': 73.35, 'avg_acc': 72.75, 'all_acc': 72.69}| Runtime: 1.6 mins
2023-12-02_15-39-45: Train summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  79.65  80.43  82.75  82.37    81.30    81.27
1      2  81.34  82.66  85.82  83.01    83.21    83.21
2      3  81.77  82.81  84.81  83.12    83.13    83.13
3      4  83.86  85.65  87.46  85.03    85.50    85.52
4      5  83.67  84.59  86.39  83.87    84.63    84.65
5      6  84.02  86.04  88.38  85.87    86.08    86.09
6      7  86.04  87.14  88.46  87.17    87.20    87.20
7      8  86.12  87.57  88.13  87.50    87.33    87.33
8      9  86.24  87.57  90.46  87.27    87.88    87.90
9     10  87.03  87.87  90.62  88.73    88.56    88.56
2023-12-02_15-39-45: Eval summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  83.46  85.61  85.82  85.44    85.08    85.08
1      2  82.71  85.61  83.58  78.85    82.69    82.81
2      3  83.46  85.37  87.06  83.79    84.92    84.96
3      4  83.46  84.41  87.56  82.14    84.39    84.45
4      5  77.69  83.69  82.59  85.16    82.28    82.24
5      6  74.94  81.77  84.33  81.04    80.52    80.53
6      7  83.96  87.77  84.83  85.99    85.64    85.65
7      8  67.92  69.78  75.37  78.30    72.84    72.69
8      9  86.22  86.33  87.56  87.36    86.87    86.85
9     10  75.44  68.82  73.38  73.35    72.75    72.69
2023-12-02_15-39-45: Final test accuracy: {'40X': 85.96, '100X': 85.1, '200X': 91.07, '400X': 83.52, 'avg_acc': 86.41, 'all_acc': 86.47}
