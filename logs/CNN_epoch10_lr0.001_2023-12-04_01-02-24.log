2023-12-04_01-02-24: config: {'n_epochs': 10, 'batch_size': 32, 'h': 224, 'w': 224, 'lr': 0.001, 'optimizer': 'adam', 'momentum': 0.9, 'weight_decay': 0, 'device': 'cuda:1', 'n_gpus': 1, 'kernel_size': 3, 'model': 'CNN', 'use_pooling': False, 'num_kernel_conv_list': [32, 64, 64]}
2023-12-04_01-02-24: conv1.weight: torch.Size([32, 3, 3, 3])
2023-12-04_01-02-24: conv1.bias: torch.Size([32])
2023-12-04_01-02-24: conv_layers.0.weight: torch.Size([64, 32, 3, 3])
2023-12-04_01-02-24: conv_layers.0.bias: torch.Size([64])
2023-12-04_01-02-24: conv_layers.2.weight: torch.Size([64, 64, 3, 3])
2023-12-04_01-02-24: conv_layers.2.bias: torch.Size([64])
2023-12-04_01-02-24: linear.weight: torch.Size([2, 3211264])
2023-12-04_01-02-24: linear.bias: torch.Size([2])
2023-12-04_01-02-24: 
Total parameters: 6,478,850;	Trainable: 6,478,850
2023-12-04_01-03-20: Epoch: 1 | Train loss: 1.5168983774209344 | Train acc: {'40X': 78.73, '100X': 79.36, '200X': 83.18, '400X': 81.65, 'avg_acc': 80.73, 'all_acc': 80.7} | Valid loss: 0.3866694810986519 | Valid acc: {'40X': 83.46, '100X': 86.09, '200X': 86.82, '400X': 82.69, 'avg_acc': 84.76, 'all_acc': 84.83}| Runtime: 0.9 mins
2023-12-04_01-04-19: Epoch: 2 | Train loss: 0.30155876042270985 | Train acc: {'40X': 83.53, '100X': 87.04, '200X': 89.16, '400X': 85.78, 'avg_acc': 86.38, 'all_acc': 86.4} | Valid loss: 0.4223656803369522 | Valid acc: {'40X': 82.46, '100X': 83.93, '200X': 85.07, '400X': 80.49, 'avg_acc': 82.99, 'all_acc': 83.06}| Runtime: 1.0 mins
2023-12-04_01-05-20: Epoch: 3 | Train loss: 0.10315988292112141 | Train acc: {'40X': 96.9, '100X': 97.68, '200X': 97.67, '400X': 95.14, 'avg_acc': 96.85, 'all_acc': 96.9} | Valid loss: 0.7531481713056565 | Valid acc: {'40X': 79.7, '100X': 80.82, '200X': 84.58, '400X': 79.4, 'avg_acc': 81.12, 'all_acc': 81.16}| Runtime: 1.0 mins
2023-12-04_01-06-19: Epoch: 4 | Train loss: 0.03176651800655433 | Train acc: {'40X': 98.91, '100X': 99.04, '200X': 99.34, '400X': 99.17, 'avg_acc': 99.12, 'all_acc': 99.11} | Valid loss: 0.9117656783014536 | Valid acc: {'40X': 79.45, '100X': 82.49, '200X': 83.58, '400X': 80.22, 'avg_acc': 81.44, 'all_acc': 81.48}| Runtime: 1.0 mins
2023-12-04_01-07-14: Epoch: 5 | Train loss: 0.025210150881714466 | Train acc: {'40X': 99.33, '100X': 99.6, '200X': 99.34, '400X': 98.9, 'avg_acc': 99.29, 'all_acc': 99.3} | Valid loss: 0.8887094111740589 | Valid acc: {'40X': 82.71, '100X': 83.45, '200X': 84.08, '400X': 82.14, 'avg_acc': 83.1, 'all_acc': 83.12}| Runtime: 0.9 mins
2023-12-04_01-08-10: Epoch: 6 | Train loss: 0.012258741266614871 | Train acc: {'40X': 99.66, '100X': 99.68, '200X': 99.83, '400X': 99.63, 'avg_acc': 99.7, 'all_acc': 99.7} | Valid loss: 0.9413893718272448 | Valid acc: {'40X': 80.95, '100X': 82.01, '200X': 81.84, '400X': 82.97, 'avg_acc': 81.94, 'all_acc': 81.92}| Runtime: 0.9 mins
2023-12-04_01-09-05: Epoch: 7 | Train loss: 0.0030126576108601955 | Train acc: {'40X': 100.0, '100X': 99.92, '200X': 99.92, '400X': 99.82, 'avg_acc': 99.92, 'all_acc': 99.92} | Valid loss: 1.0881410920247436 | Valid acc: {'40X': 81.2, '100X': 83.93, '200X': 84.08, '400X': 85.44, 'avg_acc': 83.66, 'all_acc': 83.63}| Runtime: 0.9 mins
2023-12-04_01-09-59: Epoch: 8 | Train loss: 0.0004741668424906714 | Train acc: {'40X': 100.0, '100X': 100.0, '200X': 100.0, '400X': 100.0, 'avg_acc': 100.0, 'all_acc': 100.0} | Valid loss: 1.1624992769956588 | Valid acc: {'40X': 80.95, '100X': 82.49, '200X': 83.33, '400X': 83.79, 'avg_acc': 82.64, 'all_acc': 82.62}| Runtime: 0.9 mins
2023-12-04_01-10-54: Epoch: 9 | Train loss: 0.00017254103488232577 | Train acc: {'40X': 100.0, '100X': 100.0, '200X': 100.0, '400X': 100.0, 'avg_acc': 100.0, 'all_acc': 100.0} | Valid loss: 1.2658940935134888 | Valid acc: {'40X': 81.2, '100X': 82.01, '200X': 83.33, '400X': 84.07, 'avg_acc': 82.65, 'all_acc': 82.62}| Runtime: 0.9 mins
2023-12-04_01-11-50: Epoch: 10 | Train loss: 0.00011181658440032275 | Train acc: {'40X': 100.0, '100X': 100.0, '200X': 100.0, '400X': 100.0, 'avg_acc': 100.0, 'all_acc': 100.0} | Valid loss: 1.294050410091877 | Valid acc: {'40X': 81.2, '100X': 82.73, '200X': 83.58, '400X': 83.79, 'avg_acc': 82.82, 'all_acc': 82.81}| Runtime: 0.9 mins
2023-12-04_01-11-50: Train summary:    epoch     40X    100X    200X    400X  avg_acc  all_acc
0      1   78.73   79.36   83.18   81.65    80.73    80.70
1      2   83.53   87.04   89.16   85.78    86.38    86.40
2      3   96.90   97.68   97.67   95.14    96.85    96.90
3      4   98.91   99.04   99.34   99.17    99.12    99.11
4      5   99.33   99.60   99.34   98.90    99.29    99.30
5      6   99.66   99.68   99.83   99.63    99.70    99.70
6      7  100.00   99.92   99.92   99.82    99.92    99.92
7      8  100.00  100.00  100.00  100.00   100.00   100.00
8      9  100.00  100.00  100.00  100.00   100.00   100.00
9     10  100.00  100.00  100.00  100.00   100.00   100.00
2023-12-04_01-11-50: Eval summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  83.46  86.09  86.82  82.69    84.76    84.83
1      2  82.46  83.93  85.07  80.49    82.99    83.06
2      3  79.70  80.82  84.58  79.40    81.12    81.16
3      4  79.45  82.49  83.58  80.22    81.44    81.48
4      5  82.71  83.45  84.08  82.14    83.10    83.12
5      6  80.95  82.01  81.84  82.97    81.94    81.92
6      7  81.20  83.93  84.08  85.44    83.66    83.63
7      8  80.95  82.49  83.33  83.79    82.64    82.62
8      9  81.20  82.01  83.33  84.07    82.65    82.62
9     10  81.20  82.73  83.58  83.79    82.82    82.81
2023-12-04_01-11-50: Final test accuracy: {'40X': 81.95, '100X': 81.49, '200X': 90.82, '400X': 87.64, 'avg_acc': 85.48, 'all_acc': 85.4}
