2023-12-02_17-19-53: config: {'n_epochs': 10, 'batch_size': 32, 'h': 224, 'w': 224, 'lr': 1e-05, 'optimizer': 'adam', 'momentum': 0.9, 'device': 'cuda', 'n_gpus': 2, 'kernel_size': 3, 'flatten': False, 'model': 'resnet', 'num_blocks_list': [2, 2, 2, 2], 'is_batchnorm': True}
2023-12-02_17-19-53: conv1.0.weight: torch.Size([64, 3, 3, 3])
2023-12-02_17-19-53: conv1.1.weight: torch.Size([64])
2023-12-02_17-19-53: conv1.1.bias: torch.Size([64])
2023-12-02_17-19-53: conv2_x.0.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_17-19-53: conv2_x.0.sequence.1.weight: torch.Size([64])
2023-12-02_17-19-53: conv2_x.0.sequence.1.bias: torch.Size([64])
2023-12-02_17-19-53: conv2_x.0.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_17-19-53: conv2_x.0.sequence.4.weight: torch.Size([64])
2023-12-02_17-19-53: conv2_x.0.sequence.4.bias: torch.Size([64])
2023-12-02_17-19-53: conv2_x.1.sequence.0.weight: torch.Size([64, 64, 3, 3])
2023-12-02_17-19-53: conv2_x.1.sequence.1.weight: torch.Size([64])
2023-12-02_17-19-53: conv2_x.1.sequence.1.bias: torch.Size([64])
2023-12-02_17-19-53: conv2_x.1.sequence.3.weight: torch.Size([64, 64, 3, 3])
2023-12-02_17-19-53: conv2_x.1.sequence.4.weight: torch.Size([64])
2023-12-02_17-19-53: conv2_x.1.sequence.4.bias: torch.Size([64])
2023-12-02_17-19-53: conv3_x.0.sequence.0.weight: torch.Size([128, 64, 3, 3])
2023-12-02_17-19-53: conv3_x.0.sequence.1.weight: torch.Size([128])
2023-12-02_17-19-53: conv3_x.0.sequence.1.bias: torch.Size([128])
2023-12-02_17-19-53: conv3_x.0.sequence.3.weight: torch.Size([128, 128, 3, 3])
2023-12-02_17-19-53: conv3_x.0.sequence.4.weight: torch.Size([128])
2023-12-02_17-19-53: conv3_x.0.sequence.4.bias: torch.Size([128])
2023-12-02_17-19-53: conv3_x.0.shortcut.0.weight: torch.Size([128, 64, 1, 1])
2023-12-02_17-19-53: conv3_x.0.shortcut.1.weight: torch.Size([128])
2023-12-02_17-19-53: conv3_x.0.shortcut.1.bias: torch.Size([128])
2023-12-02_17-19-53: conv3_x.1.sequence.0.weight: torch.Size([128, 128, 3, 3])
2023-12-02_17-19-53: conv3_x.1.sequence.1.weight: torch.Size([128])
2023-12-02_17-19-53: conv3_x.1.sequence.1.bias: torch.Size([128])
2023-12-02_17-19-53: conv3_x.1.sequence.3.weight: torch.Size([128, 128, 3, 3])
2023-12-02_17-19-53: conv3_x.1.sequence.4.weight: torch.Size([128])
2023-12-02_17-19-53: conv3_x.1.sequence.4.bias: torch.Size([128])
2023-12-02_17-19-53: conv4_x.0.sequence.0.weight: torch.Size([256, 128, 3, 3])
2023-12-02_17-19-53: conv4_x.0.sequence.1.weight: torch.Size([256])
2023-12-02_17-19-53: conv4_x.0.sequence.1.bias: torch.Size([256])
2023-12-02_17-19-53: conv4_x.0.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_17-19-53: conv4_x.0.sequence.4.weight: torch.Size([256])
2023-12-02_17-19-53: conv4_x.0.sequence.4.bias: torch.Size([256])
2023-12-02_17-19-53: conv4_x.0.shortcut.0.weight: torch.Size([256, 128, 1, 1])
2023-12-02_17-19-53: conv4_x.0.shortcut.1.weight: torch.Size([256])
2023-12-02_17-19-53: conv4_x.0.shortcut.1.bias: torch.Size([256])
2023-12-02_17-19-53: conv4_x.1.sequence.0.weight: torch.Size([256, 256, 3, 3])
2023-12-02_17-19-53: conv4_x.1.sequence.1.weight: torch.Size([256])
2023-12-02_17-19-53: conv4_x.1.sequence.1.bias: torch.Size([256])
2023-12-02_17-19-53: conv4_x.1.sequence.3.weight: torch.Size([256, 256, 3, 3])
2023-12-02_17-19-53: conv4_x.1.sequence.4.weight: torch.Size([256])
2023-12-02_17-19-53: conv4_x.1.sequence.4.bias: torch.Size([256])
2023-12-02_17-19-53: conv5_x.0.sequence.0.weight: torch.Size([512, 256, 3, 3])
2023-12-02_17-19-53: conv5_x.0.sequence.1.weight: torch.Size([512])
2023-12-02_17-19-53: conv5_x.0.sequence.1.bias: torch.Size([512])
2023-12-02_17-19-53: conv5_x.0.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_17-19-53: conv5_x.0.sequence.4.weight: torch.Size([512])
2023-12-02_17-19-53: conv5_x.0.sequence.4.bias: torch.Size([512])
2023-12-02_17-19-53: conv5_x.0.shortcut.0.weight: torch.Size([512, 256, 1, 1])
2023-12-02_17-19-53: conv5_x.0.shortcut.1.weight: torch.Size([512])
2023-12-02_17-19-53: conv5_x.0.shortcut.1.bias: torch.Size([512])
2023-12-02_17-19-53: conv5_x.1.sequence.0.weight: torch.Size([512, 512, 3, 3])
2023-12-02_17-19-53: conv5_x.1.sequence.1.weight: torch.Size([512])
2023-12-02_17-19-53: conv5_x.1.sequence.1.bias: torch.Size([512])
2023-12-02_17-19-53: conv5_x.1.sequence.3.weight: torch.Size([512, 512, 3, 3])
2023-12-02_17-19-53: conv5_x.1.sequence.4.weight: torch.Size([512])
2023-12-02_17-19-53: conv5_x.1.sequence.4.bias: torch.Size([512])
2023-12-02_17-19-53: fc.weight: torch.Size([2, 512])
2023-12-02_17-19-53: fc.bias: torch.Size([2])
2023-12-02_17-19-53: 
Total parameters: 11,169,858;	Trainable: 11,169,858
2023-12-02_17-21-00: Epoch: 2 | Train loss: 0.4336562729566484 | Train acc: {'40X': 79.18, '100X': 80.16, '200X': 83.33, '400X': 82.46, 'avg_acc': 81.28, 'all_acc': 81.25} | Valid loss: 0.33100784301757813 | Valid acc: {'40X': 85.21, '100X': 87.29, '200X': 87.06, '400X': 86.54, 'avg_acc': 86.52, 'all_acc': 86.54}| Runtime: 1.1 mins
2023-12-02_17-22-06: Epoch: 3 | Train loss: 0.3525540814609141 | Train acc: {'40X': 84.1, '100X': 83.21, '200X': 87.15, '400X': 86.15, 'avg_acc': 85.15, 'all_acc': 85.11} | Valid loss: 0.3332009196281433 | Valid acc: {'40X': 85.96, '100X': 84.89, '200X': 87.31, '400X': 85.99, 'avg_acc': 86.04, 'all_acc': 86.03}| Runtime: 1.1 mins
2023-12-02_17-23-13: Epoch: 4 | Train loss: 0.3286431554604221 | Train acc: {'40X': 83.18, '100X': 85.29, '200X': 88.05, '400X': 86.45, 'avg_acc': 85.74, 'all_acc': 85.73} | Valid loss: 0.3131342034041882 | Valid acc: {'40X': 86.22, '100X': 87.77, '200X': 87.81, '400X': 86.26, 'avg_acc': 87.02, 'all_acc': 87.04}| Runtime: 1.1 mins
2023-12-02_17-24-20: Epoch: 5 | Train loss: 0.3268231195775238 | Train acc: {'40X': 84.45, '100X': 84.1, '200X': 87.9, '400X': 86.21, 'avg_acc': 85.66, 'all_acc': 85.64} | Valid loss: 0.3139554414153099 | Valid acc: {'40X': 84.96, '100X': 86.09, '200X': 87.31, '400X': 84.89, 'avg_acc': 85.81, 'all_acc': 85.84}| Runtime: 1.1 mins
2023-12-02_17-25-27: Epoch: 6 | Train loss: 0.3067948850425514 | Train acc: {'40X': 84.07, '100X': 85.38, '200X': 89.81, '400X': 86.25, 'avg_acc': 86.38, 'all_acc': 86.38} | Valid loss: 0.25918801307678224 | Valid acc: {'40X': 86.47, '100X': 89.45, '200X': 90.3, '400X': 87.36, 'avg_acc': 88.4, 'all_acc': 88.43}| Runtime: 1.1 mins
2023-12-02_17-26-34: Epoch: 7 | Train loss: 0.2992882421491919 | Train acc: {'40X': 85.19, '100X': 86.67, '200X': 88.89, '400X': 86.33, 'avg_acc': 86.77, 'all_acc': 86.78} | Valid loss: 0.3553114548325539 | Valid acc: {'40X': 83.96, '100X': 84.41, '200X': 87.56, '400X': 85.99, 'avg_acc': 85.48, 'all_acc': 85.46}| Runtime: 1.1 mins
2023-12-02_17-27-41: Epoch: 8 | Train loss: 0.28145965133365747 | Train acc: {'40X': 86.19, '100X': 87.8, '200X': 90.38, '400X': 88.34, 'avg_acc': 88.18, 'all_acc': 88.18} | Valid loss: 0.2635995003581047 | Valid acc: {'40X': 87.22, '100X': 89.69, '200X': 91.29, '400X': 87.91, 'avg_acc': 89.03, 'all_acc': 89.06}| Runtime: 1.1 mins
2023-12-02_17-28-48: Epoch: 9 | Train loss: 0.2761118005759813 | Train acc: {'40X': 86.35, '100X': 86.84, '200X': 90.21, '400X': 88.63, 'avg_acc': 88.01, 'all_acc': 87.99} | Valid loss: 0.24705182552337646 | Valid acc: {'40X': 86.22, '100X': 91.37, '200X': 92.04, '400X': 90.11, 'avg_acc': 89.94, 'all_acc': 89.95}| Runtime: 1.1 mins
2023-12-02_17-29-55: Epoch: 10 | Train loss: 0.2614143770188093 | Train acc: {'40X': 87.21, '100X': 88.03, '200X': 91.63, '400X': 89.53, 'avg_acc': 89.1, 'all_acc': 89.08} | Valid loss: 0.26443305805325507 | Valid acc: {'40X': 85.71, '100X': 90.41, '200X': 90.3, '400X': 88.74, 'avg_acc': 88.79, 'all_acc': 88.81}| Runtime: 1.1 mins
2023-12-02_17-31-02: Epoch: 11 | Train loss: 0.24430047881764336 | Train acc: {'40X': 86.69, '100X': 89.46, '200X': 91.31, '400X': 89.91, 'avg_acc': 89.34, 'all_acc': 89.34} | Valid loss: 0.2131424614787102 | Valid acc: {'40X': 88.97, '100X': 92.33, '200X': 93.03, '400X': 89.84, 'avg_acc': 91.04, 'all_acc': 91.09}| Runtime: 1.1 mins
2023-12-02_17-31-02: Train summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  79.18  80.16  83.33  82.46    81.28    81.25
1      2  84.10  83.21  87.15  86.15    85.15    85.11
2      3  83.18  85.29  88.05  86.45    85.74    85.73
3      4  84.45  84.10  87.90  86.21    85.66    85.64
4      5  84.07  85.38  89.81  86.25    86.38    86.38
5      6  85.19  86.67  88.89  86.33    86.77    86.78
6      7  86.19  87.80  90.38  88.34    88.18    88.18
7      8  86.35  86.84  90.21  88.63    88.01    87.99
8      9  87.21  88.03  91.63  89.53    89.10    89.08
9     10  86.69  89.46  91.31  89.91    89.34    89.34
2023-12-02_17-31-02: Eval summary:    epoch    40X   100X   200X   400X  avg_acc  all_acc
0      1  85.21  87.29  87.06  86.54    86.52    86.54
1      2  85.96  84.89  87.31  85.99    86.04    86.03
2      3  86.22  87.77  87.81  86.26    87.02    87.04
3      4  84.96  86.09  87.31  84.89    85.81    85.84
4      5  86.47  89.45  90.30  87.36    88.40    88.43
5      6  83.96  84.41  87.56  85.99    85.48    85.46
6      7  87.22  89.69  91.29  87.91    89.03    89.06
7      8  86.22  91.37  92.04  90.11    89.94    89.95
8      9  85.71  90.41  90.30  88.74    88.79    88.81
9     10  88.97  92.33  93.03  89.84    91.04    91.09
2023-12-02_17-31-02: Final test accuracy: {'40X': 89.97, '100X': 88.22, '200X': 96.03, '400X': 90.93, 'avg_acc': 91.29, 'all_acc': 91.28}
